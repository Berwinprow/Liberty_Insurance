{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2112217 records from 'basiccleaned_appended_base_and_pr'.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database Connection\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query = \"SELECT * FROM basiccleaned_appended_base_and_pr;\"\n",
    "df = pd.read_sql(query, con=engine)\n",
    "print(f\"Loaded {len(df)} records from 'basiccleaned_appended_base_and_pr'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid records for cleaning: 1645945\n",
      "Invalid records (unchanged): 466272\n",
      "Creating lookup dictionaries for chassis & engine numbers (valid records only)...\n",
      "Total records in final output: 2112217\n"
     ]
    }
   ],
   "source": [
    "# Separate Data into Valid and Invalid Groups\n",
    "REG_NO_COLUMN = \"Cleaned Reg no\"\n",
    "CHASSIS_COLUMN = \"Cleaned Chassis Number\"\n",
    "ENGINE_COLUMN = \"Cleaned Engine Number\"\n",
    "MODEL_COLUMN = \"model\"\n",
    "\n",
    "# Separate rows where Cleaned Reg no is NOT null and does NOT contain 'new' (valid rows)\n",
    "valid_df = df[df[REG_NO_COLUMN].notnull() & ~df[REG_NO_COLUMN].str.contains(\"new\", case=False, na=False)].copy()\n",
    "\n",
    "# The invalid rows (where Cleaned Reg no is null or contains 'new') remain unchanged\n",
    "invalid_df = df[~(df[REG_NO_COLUMN].notnull() & ~df[REG_NO_COLUMN].str.contains(\"new\", case=False, na=False))].copy()\n",
    "\n",
    "print(f\"Valid records for cleaning: {len(valid_df)}\")\n",
    "print(f\"Invalid records (unchanged): {len(invalid_df)}\")\n",
    "\n",
    "# Clean Valid Data\n",
    "# Ensure chassis & engine columns in the valid subset are strings and fill NaNs with empty strings.\n",
    "valid_df[CHASSIS_COLUMN] = valid_df[CHASSIS_COLUMN].astype(str).fillna(\"\")\n",
    "valid_df[ENGINE_COLUMN] = valid_df[ENGINE_COLUMN].astype(str).fillna(\"\")\n",
    "\n",
    "print(\"Creating lookup dictionaries for chassis & engine numbers (valid records only)...\")\n",
    "\n",
    "# Create lookup dictionaries for valid rows by grouping on Cleaned Reg no and model.\n",
    "chassis_lookup = (\n",
    "    valid_df.groupby([REG_NO_COLUMN, MODEL_COLUMN])[CHASSIS_COLUMN]\n",
    "      .apply(lambda x: max(x, key=len))  # Get the longest chassis number in each group.\n",
    "      .to_dict()\n",
    ")\n",
    "engine_lookup = (\n",
    "    valid_df.groupby([REG_NO_COLUMN, MODEL_COLUMN])[ENGINE_COLUMN]\n",
    "      .apply(lambda x: max(x, key=len))  # Get the longest engine number in each group.\n",
    "      .to_dict()\n",
    ")\n",
    "\n",
    "# Update the chassis and engine numbers in the valid subset using the lookup dictionaries.\n",
    "valid_df[CHASSIS_COLUMN] = valid_df[[REG_NO_COLUMN, MODEL_COLUMN]].apply(\n",
    "    lambda x: chassis_lookup.get(tuple(x), \"\"), axis=1\n",
    ")\n",
    "valid_df[ENGINE_COLUMN] = valid_df[[REG_NO_COLUMN, MODEL_COLUMN]].apply(\n",
    "    lambda x: engine_lookup.get(tuple(x), \"\"), axis=1\n",
    ")\n",
    "\n",
    "# Combine Cleaned Valid Data with Unchanged Invalid Data\n",
    "final_df = pd.concat([valid_df, invalid_df], ignore_index=True)\n",
    "print(f\"Total records in final output: {len(final_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned data into 'cleanchassisengine_basiccleaned_appended_base_and_pr'...\n",
      "Cleaned data successfully loaded into 'cleanchassisengine_basiccleaned_appended_base_and_pr'.\n"
     ]
    }
   ],
   "source": [
    "# Load Cleaned Data\n",
    "TARGET_TABLE = \"cleanchassisengine_basiccleaned_appended_base_and_pr\"\n",
    "print(f\"Loading cleaned data into '{TARGET_TABLE}'...\")\n",
    "final_df.to_sql(name=TARGET_TABLE, con=engine, if_exists=\"replace\", index=False, chunksize=10000)\n",
    "print(f\"Cleaned data successfully loaded into '{TARGET_TABLE}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 224371 records from 'public.samechassisno_differregno'.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database Connection\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query = \"SELECT * FROM public.samechassisno_differregno;\"\n",
    "df = pd.read_sql(query, con=engine)\n",
    "print(f\"Loaded {len(df)} records from 'public.samechassisno_differregno'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid records for cleaning: 125956\n",
      "Invalid records (unchanged): 98415\n",
      "Creating lookup dictionaries for chassis & engine numbers (valid records only)...\n",
      "Total records in final output: 224371\n"
     ]
    }
   ],
   "source": [
    "# Separate Data into Valid and Invalid Groups\n",
    "REG_NO_COLUMN = \"Cleaned Reg no\"\n",
    "CHASSIS_COLUMN = \"Cleaned Chassis Number\"\n",
    "ENGINE_COLUMN = \"Cleaned Engine Number\"\n",
    "MODEL_COLUMN = \"model\"\n",
    "\n",
    "# Separate rows where Cleaned Reg no is NOT null and does NOT contain 'new' (valid rows)\n",
    "valid_df = df[df[REG_NO_COLUMN].notnull() & ~df[REG_NO_COLUMN].str.contains(\"new\", case=False, na=False)].copy()\n",
    "\n",
    "# The invalid rows (where Cleaned Reg no is null or contains 'new') remain unchanged\n",
    "invalid_df = df[~(df[REG_NO_COLUMN].notnull() & ~df[REG_NO_COLUMN].str.contains(\"new\", case=False, na=False))].copy()\n",
    "\n",
    "print(f\"Valid records for cleaning: {len(valid_df)}\")\n",
    "print(f\"Invalid records (unchanged): {len(invalid_df)}\")\n",
    "\n",
    "# Ensure chassis & engine columns in the valid subset are strings and fill NaNs with empty strings.\n",
    "valid_df[CHASSIS_COLUMN] = valid_df[CHASSIS_COLUMN].astype(str).fillna(\"\")\n",
    "valid_df[ENGINE_COLUMN] = valid_df[ENGINE_COLUMN].astype(str).fillna(\"\")\n",
    "\n",
    "print(\"Creating lookup dictionaries for chassis & engine numbers (valid records only)...\")\n",
    "\n",
    "# Create lookup dictionaries for valid rows by grouping on Cleaned Reg no and model.\n",
    "chassis_lookup = (\n",
    "    valid_df.groupby([REG_NO_COLUMN, MODEL_COLUMN])[CHASSIS_COLUMN]\n",
    "      .apply(lambda x: max(x, key=len))  # Get the longest chassis number in each group.\n",
    "      .to_dict()\n",
    ")\n",
    "engine_lookup = (\n",
    "    valid_df.groupby([REG_NO_COLUMN, MODEL_COLUMN])[ENGINE_COLUMN]\n",
    "      .apply(lambda x: max(x, key=len))  # Get the longest engine number in each group.\n",
    "      .to_dict()\n",
    ")\n",
    "\n",
    "# Update the chassis and engine numbers in the valid subset using the lookup dictionaries.\n",
    "valid_df[CHASSIS_COLUMN] = valid_df[[REG_NO_COLUMN, MODEL_COLUMN]].apply(\n",
    "    lambda x: chassis_lookup.get(tuple(x), \"\"), axis=1\n",
    ")\n",
    "valid_df[ENGINE_COLUMN] = valid_df[[REG_NO_COLUMN, MODEL_COLUMN]].apply(\n",
    "    lambda x: engine_lookup.get(tuple(x), \"\"), axis=1\n",
    ")\n",
    "\n",
    "# Combine Cleaned Valid Data with Unchanged Invalid Data\n",
    "final_df = pd.concat([valid_df, invalid_df], ignore_index=True)\n",
    "print(f\"Total records in final output: {len(final_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned data into 'cleanchassisengine_samechassisno_differregno'...\n",
      "Cleaned data successfully loaded into 'cleanchassisengine_samechassisno_differregno'.\n"
     ]
    }
   ],
   "source": [
    "# Load Cleaned Data\n",
    "TARGET_TABLE = \"cleanchassisengine_samechassisno_differregno\"\n",
    "print(f\"Loading cleaned data into '{TARGET_TABLE}'...\")\n",
    "final_df.to_sql(name=TARGET_TABLE, con=engine, if_exists=\"replace\", index=False, chunksize=10000)\n",
    "print(f\"Cleaned data successfully loaded into '{TARGET_TABLE}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
