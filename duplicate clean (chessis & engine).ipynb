{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# ---------------------------\n",
    "# Step 0: Database Connection\n",
    "# ---------------------------\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Load Data\n",
    "# ---------------------------\n",
    "query = \"SELECT * FROM cleanchassisengine_basiccleaned_appended_base_and_pr;\"\n",
    "df = pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15496\\3540765457.py:48: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(assign_trim_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2086538\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a helper function to determine if a value is valid (not null, empty, or 'blank')\n",
    "def is_valid_value(val):\n",
    "    if pd.isna(val):\n",
    "        return False\n",
    "    val_str = str(val).strip().lower()\n",
    "    return val_str != \"\" and val_str != \"blank\"\n",
    "\n",
    "# Create mask for rows with valid chassis and engine numbers in both columns\n",
    "mask_valid = (\n",
    "    df['Cleaned Chassis Number'].apply(is_valid_value) &\n",
    "    df['Cleaned Engine Number'].apply(is_valid_value)\n",
    ")\n",
    "\n",
    "# Filter out rows that do not have valid values in both columns\n",
    "df_valid = df[mask_valid].copy()\n",
    "\n",
    "# Convert date columns to datetime\n",
    "df_valid['policy start date'] = pd.to_datetime(df_valid['policy start date'], errors='coerce')\n",
    "df_valid['policy end date'] = pd.to_datetime(df_valid['policy end date'], errors='coerce')\n",
    "\n",
    "# ---------------------------\n",
    "# Step 5: Handle Duplicates based on grouping columns\n",
    "# ---------------------------\n",
    "def prioritize_trim_group(group):\n",
    "    base_values = ['2022_base', '2023_base', '2024_base']\n",
    "    base_rows = group[group['data'].isin(base_values)]\n",
    "    if not base_rows.empty:\n",
    "        # Choose the record with the highest total premium payable among base records\n",
    "        selected = base_rows.sort_values(by='total premium payable', ascending=False).iloc[0]\n",
    "    else:\n",
    "        # Otherwise choose the record with the latest policy issue date, then highest total premium payable\n",
    "        selected = group.sort_values(by=['policy issue date', 'total premium payable'], ascending=[False, False]).iloc[0]\n",
    "    return selected\n",
    "\n",
    "def assign_trim_group(group):\n",
    "    if len(group) > 1:\n",
    "        selected_row = prioritize_trim_group(group)\n",
    "    else:\n",
    "        selected_row = group.iloc[0]\n",
    "    return selected_row\n",
    "\n",
    "# Group by the relevant columns and apply duplicate handling\n",
    "df_final = (\n",
    "    df_valid\n",
    "    .groupby(['Cleaned Chassis Number', 'Cleaned Engine Number', 'policy start date', 'policy end date'], group_keys=False)\n",
    "    .apply(assign_trim_group)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(len(df_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Final DataFrame ready for analysis or export\n",
    "# ---------------------------\n",
    "df_final.to_sql('dupclean_cleanchassisengine_basiccleaned_appended_base_and_pr', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# ---------------------------\n",
    "# Step 0: Database Connection\n",
    "# ---------------------------\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Load Data\n",
    "# ---------------------------\n",
    "query = \"SELECT * FROM cleanchassisengine_samechassisno_differregno;\"\n",
    "df = pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15496\\3540765457.py:48: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(assign_trim_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220420\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a helper function to determine if a value is valid (not null, empty, or 'blank')\n",
    "def is_valid_value(val):\n",
    "    if pd.isna(val):\n",
    "        return False\n",
    "    val_str = str(val).strip().lower()\n",
    "    return val_str != \"\" and val_str != \"blank\"\n",
    "\n",
    "# Create mask for rows with valid chassis and engine numbers in both columns\n",
    "mask_valid = (\n",
    "    df['Cleaned Chassis Number'].apply(is_valid_value) &\n",
    "    df['Cleaned Engine Number'].apply(is_valid_value)\n",
    ")\n",
    "\n",
    "# Filter out rows that do not have valid values in both columns\n",
    "df_valid = df[mask_valid].copy()\n",
    "\n",
    "# Convert date columns to datetime\n",
    "df_valid['policy start date'] = pd.to_datetime(df_valid['policy start date'], errors='coerce')\n",
    "df_valid['policy end date'] = pd.to_datetime(df_valid['policy end date'], errors='coerce')\n",
    "\n",
    "# ---------------------------\n",
    "# Step 5: Handle Duplicates based on grouping columns\n",
    "# ---------------------------\n",
    "def prioritize_trim_group(group):\n",
    "    base_values = ['2022_base', '2023_base', '2024_base']\n",
    "    base_rows = group[group['data'].isin(base_values)]\n",
    "    if not base_rows.empty:\n",
    "        # Choose the record with the highest total premium payable among base records\n",
    "        selected = base_rows.sort_values(by='total premium payable', ascending=False).iloc[0]\n",
    "    else:\n",
    "        # Otherwise choose the record with the latest policy issue date, then highest total premium payable\n",
    "        selected = group.sort_values(by=['policy issue date', 'total premium payable'], ascending=[False, False]).iloc[0]\n",
    "    return selected\n",
    "\n",
    "def assign_trim_group(group):\n",
    "    if len(group) > 1:\n",
    "        selected_row = prioritize_trim_group(group)\n",
    "    else:\n",
    "        selected_row = group.iloc[0]\n",
    "    return selected_row\n",
    "\n",
    "# Group by the relevant columns and apply duplicate handling\n",
    "df_final = (\n",
    "    df_valid\n",
    "    .groupby(['Cleaned Chassis Number', 'Cleaned Engine Number', 'policy start date', 'policy end date'], group_keys=False)\n",
    "    .apply(assign_trim_group)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(len(df_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Final DataFrame ready for analysis or export\n",
    "# ---------------------------\n",
    "df_final.to_sql('dupclean_cleanchassisengine_samechassisno_differregno', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
