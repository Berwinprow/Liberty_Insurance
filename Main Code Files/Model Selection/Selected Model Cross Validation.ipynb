{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, classification_report, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Load Data from PostgreSQL\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'Liberty',\n",
    "    'user': 'postgres',\n",
    "    'password': 'abc',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query = 'SELECT * FROM public.policydata_with_fb_cc_pc_newfea_opti_correct;'\n",
    "data = pd.read_sql(query, con=engine)\n",
    "\n",
    "selected_columns = ['rto_risk_factor', 'ncb % previous year', 'state_risk_score', 'retention_rate_pct', 'total od premium_max', 'applicable discount with ncb', \n",
    "                    'policy_wise_purchase', 'manufacturer_risk_rate', 'days_between_renewals', 'retention_streak', 'total od premium_mean', 'total od premium', \n",
    "                    'firstpolicyyear', 'lag_1_tp_premium', 'total od premium_min', 'avg_premium_hist', 'lag_1_ncb', 'age', 'total tp premium_max', 'total tp premium_mean', \n",
    "                    'total tp premium', 'total tp premium_min', 'lag_1_premium', 'previous_year_premium_ratio', 'total premium payable', 'total_revenue', 'gst', \n",
    "                    'fuel_type_risk_factor', 'lag_1_od_premium', 'Customer_APV', 'segment_risk_score', 'vehicle idv', 'Policy Tenure', 'Number of claims', 'approved', \n",
    "                    'claim_approval_rate', 'Customer Tenure', 'before gst add-on gwp', 'od_tp_ratio', 'add_on_adoption', 'CLV', 'idv_premium_ratio', 'Customer_APF', \n",
    "                    'days_gap_prev_end_to_curr_start', 'customerid', 'Claim Happaned/Not', 'Cleaned Branch Name 2', 'Cleaned Chassis Number', 'Cleaned Engine Number', \n",
    "                    'Cleaned Reg no', 'Cleaned State2', 'Cleaned Zone 2', 'biztype', 'corrected_name', 'make_clean', 'model_clean', 'product name', 'policy no', \n",
    "                    'policy end date', 'policy start date', 'decline', 'tie up', 'variant', 'Policy Status']\n",
    "\n",
    "data = data[selected_columns]\n",
    "\n",
    "# Remove rows where 'Status' contains 'Open'\n",
    "data = data[data['Policy Status'].isin(['Renewed', 'Not Renewed'])]\n",
    "\n",
    "\n",
    "data['Policy Status'] = data['Policy Status'].apply(lambda x: 1 if x == 'Not Renewed' else 0)\n",
    "\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        data[column] = data[column].fillna('none')\n",
    "    else:\n",
    "        data[column] = data[column].fillna(0)\n",
    "\n",
    "date_columns = ['policy start date', 'policy end date']\n",
    "\n",
    "for col in date_columns:\n",
    "    data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "\n",
    "# Extract year, month, and day as separate features for all date columns\n",
    "new_date_cols = {}\n",
    "for col in date_columns:\n",
    "    new_date_cols[f'{col}_YEAR'] = data[col].dt.year\n",
    "    new_date_cols[f'{col}_MONTH'] = data[col].dt.month\n",
    "    new_date_cols[f'{col}_DAY'] = data[col].dt.day\n",
    "\n",
    "data = pd.concat([data, pd.DataFrame(new_date_cols)], axis=1)\n",
    "\n",
    "# Drop date columns after splitting\n",
    "data = data.drop(columns=date_columns)\n",
    "\n",
    "# Define features and target\n",
    "features = [col for col in data.columns if col not in ['Policy Status']]\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = data[features]\n",
    "y = data['Policy Status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, log_loss, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Apply Random Oversampling to the training data\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to categorical features for both train and test sets\n",
    "for column in X_train.columns:\n",
    "    if X_train[column].dtype == 'object':\n",
    "        # Initialize and fit the LabelEncoder on the training data\n",
    "        label_encoder = LabelEncoder()\n",
    "        X_train[column] = label_encoder.fit_transform(X_train[column].astype(str))\n",
    "\n",
    "        # Create a mapping dictionary from the LabelEncoder\n",
    "        mapping_dict = {label: i for i, label in enumerate(label_encoder.classes_)}\n",
    "        \n",
    "        # Track the next unique integer for unseen values in the test set\n",
    "        next_unique_value = [max(mapping_dict.values()) + 1]  \n",
    "\n",
    "        # Encode the test data\n",
    "        def encode_test_value(value):\n",
    "            if value in mapping_dict:\n",
    "                return mapping_dict[value]\n",
    "            else:\n",
    "                # Update the mapping_dict with a new unique value for unseen categories\n",
    "                mapping_dict[value] = next_unique_value[0]\n",
    "                next_unique_value[0] += 1\n",
    "                return mapping_dict[value]\n",
    "\n",
    "        # Apply the encoding to the test set\n",
    "        X_test[column] = X_test[column].apply(encode_test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results:\n",
      "Mean Test Accuracy: 0.8549\n",
      "Mean Test ROC AUC: 0.9287\n",
      "Mean Test Log Loss: 0.3429\n",
      "Mean Train Accuracy: 0.8560\n",
      "Mean Train ROC AUC: 0.9299\n",
      "Mean Train Log Loss: 0.3406\n",
      "\n",
      "Test Accuracy: 0.8503\n",
      "Test Log Loss: 0.3594\n",
      "Test ROC AUC: 0.9233\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81    111075\n",
      "           1       0.91      0.85      0.88    189528\n",
      "\n",
      "    accuracy                           0.85    300603\n",
      "   macro avg       0.84      0.85      0.84    300603\n",
      "weighted avg       0.86      0.85      0.85    300603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, classification_report, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GBM model\n",
    "model = GradientBoostingClassifier(\n",
    "    max_depth=6,                    \n",
    "    learning_rate=0.1,              \n",
    "    n_estimators=100,              \n",
    "    random_state=42                 \n",
    ")\n",
    "\n",
    "# Set up stratified k-fold cross-validation (ensuring class balance in folds)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and capture metrics\n",
    "cv_results = cross_validate(model, X_train, y_train, cv=cv, scoring=['accuracy', 'roc_auc', 'neg_log_loss'], return_train_score=True)\n",
    "\n",
    "# Output the results of cross-validation\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"Mean Test Accuracy: {cv_results['test_accuracy'].mean():.4f}\")\n",
    "print(f\"Mean Test ROC AUC: {cv_results['test_roc_auc'].mean():.4f}\")\n",
    "print(f\"Mean Test Log Loss: {-cv_results['test_neg_log_loss'].mean():.4f}\")\n",
    "print(f\"Mean Train Accuracy: {cv_results['train_accuracy'].mean():.4f}\")\n",
    "print(f\"Mean Train ROC AUC: {cv_results['train_roc_auc'].mean():.4f}\")\n",
    "print(f\"Mean Train Log Loss: {-cv_results['train_neg_log_loss'].mean():.4f}\")\n",
    "\n",
    "# Now fit the model on the entire training dataset and evaluate it\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation metrics as before\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Output the evaluation metrics\n",
    "print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Log Loss: {log_loss_value:.4f}\")\n",
    "print(f\"Test ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
