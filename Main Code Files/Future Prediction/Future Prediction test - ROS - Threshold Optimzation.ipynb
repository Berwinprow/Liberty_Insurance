{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load Data from PostgreSQL\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'Liberty',\n",
    "    'user': 'postgres',\n",
    "    'password': 'abc',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query = 'SELECT * FROM public.policydata_with_fb_cc_pc_newfea_opti_correct;'\n",
    "data = pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\n",
    "                    'rto_risk_factor', 'ncb % previous year', 'state_risk_score', 'retention_rate_pct', 'total od premium_max', 'applicable discount with ncb', \n",
    "                    'policy_wise_purchase', 'manufacturer_risk_rate', 'days_between_renewals', 'retention_streak', 'total od premium_mean', 'total od premium', \n",
    "                    'firstpolicyyear', 'lag_1_tp_premium', 'total od premium_min', 'avg_premium_hist', 'lag_1_ncb', 'age', 'total tp premium_max', 'total tp premium_mean', \n",
    "                    'total tp premium', 'total tp premium_min', 'lag_1_premium', 'previous_year_premium_ratio', 'total premium payable', 'total_revenue', 'gst', \n",
    "                    'fuel_type_risk_factor', 'lag_1_od_premium', 'Customer_APV', 'segment_risk_score', 'vehicle idv', 'Policy Tenure', 'Number of claims', 'approved', \n",
    "                    'claim_approval_rate', 'Customer Tenure', 'before gst add-on gwp', 'od_tp_ratio', 'add_on_adoption', 'CLV', 'idv_premium_ratio', 'Customer_APF', \n",
    "                    'days_gap_prev_end_to_curr_start', 'customerid', 'Claim Happaned/Not', 'Cleaned Branch Name 2', 'Cleaned Chassis Number', 'Cleaned Engine Number', \n",
    "                    'Cleaned Reg no', 'Cleaned State2', 'Cleaned Zone 2', 'biztype', 'corrected_name', 'make_clean', 'model_clean', 'product name', 'policy no', \n",
    "                    'policy end date', 'policy start date', 'decline', 'tie up', 'variant', 'Policy Status'\n",
    "\n",
    "]\n",
    "\n",
    "data = data[selected_columns]\n",
    "\n",
    "# Convert Policy End Date to datetime\n",
    "data['policy end date'] = pd.to_datetime(data['policy end date'], errors='coerce')\n",
    "\n",
    "# Separate Open Customers (January to March 2025)\n",
    "open_customers = data[\n",
    "    (data['Policy Status'] == 'Open') &\n",
    "    (data['policy end date'].dt.year == 2025) &\n",
    "    (data['policy end date'].dt.month.isin([1, 2, 3, 4, 5, 6]))\n",
    "].copy()\n",
    "\n",
    "# Filter the main dataset for customers whose Policy End Date is <= December 2024\n",
    "data = data[data['Policy Status'].isin(['Renewed', 'Not Renewed'])]\n",
    "\n",
    "# Map Policy Status to binary\n",
    "data['Policy Status'] = data['Policy Status'].apply(lambda x: 1 if x == 'Not Renewed' else 0)\n",
    "\n",
    "# Handle missing values\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        data[column] = data[column].fillna('missing')\n",
    "    else:\n",
    "        data[column] = data[column].fillna(0)\n",
    "\n",
    "# Extract year, month, and day from date columns\n",
    "date_columns = ['policy start date', 'policy end date']\n",
    "for col in date_columns:\n",
    "    data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "\n",
    "# Extract date features\n",
    "for col in date_columns:\n",
    "    data[f'{col}_YEAR'] = data[col].dt.year\n",
    "    data[f'{col}_MONTH'] = data[col].dt.month\n",
    "    data[f'{col}_DAY'] = data[col].dt.day\n",
    "\n",
    "# Drop original date columns\n",
    "data.drop(columns=date_columns, inplace=True)\n",
    "\n",
    "# Separate features and target variable for training\n",
    "features = [col for col in data.columns if col != 'Policy Status']\n",
    "X = data[features]\n",
    "y = data['Policy Status']\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, log_loss, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Apply Random Oversampling to the training data\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Apply the same transformations to open_customers\n",
    "for col in date_columns:\n",
    "    open_customers[col] = pd.to_datetime(open_customers[col], errors='coerce')\n",
    "\n",
    "for col in date_columns:\n",
    "    open_customers[f'{col}_YEAR'] = open_customers[col].dt.year\n",
    "    open_customers[f'{col}_MONTH'] = open_customers[col].dt.month\n",
    "    open_customers[f'{col}_DAY'] = open_customers[col].dt.day\n",
    "\n",
    "open_customers.drop(columns=date_columns, inplace=True)\n",
    "\n",
    "for column in open_customers.columns:\n",
    "    if open_customers[column].dtype == 'object':\n",
    "        open_customers[column] = open_customers[column].fillna('missing')\n",
    "    else:\n",
    "        open_customers[column] = open_customers[column].fillna(0)\n",
    "\n",
    "open_customers_without_encoded = open_customers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to categorical features\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        label_encoder = LabelEncoder()\n",
    "        X[column] = label_encoder.fit_transform(X[column].astype(str))\n",
    "        label_encoders[column] = label_encoder\n",
    "        \n",
    "        mapping_dict = {label: i for i, label in enumerate(label_encoder.classes_)}\n",
    "        next_unique_value = max(mapping_dict.values()) + 1  \n",
    "\n",
    "        def encode_test_value(value):\n",
    "            return mapping_dict.get(value, next_unique_value)\n",
    "\n",
    "        open_customers[column] = open_customers[column].apply(encode_test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "open_customers_without_encoded.to_csv('future prediction rancat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Renewed: 106676\n",
      "Predicted Not Renewed: 252197\n",
      "Train Accuracy: 0.8548907916314036\n",
      "Train Log Loss: 0.3430168189956369\n",
      "Train ROC AUC: 0.9285334925831624\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85    947638\n",
      "           1       0.85      0.86      0.86    947638\n",
      "\n",
      "    accuracy                           0.85   1895276\n",
      "   macro avg       0.86      0.85      0.85   1895276\n",
      "weighted avg       0.86      0.85      0.85   1895276\n",
      "\n",
      "Class 0 Train Accuracy: 0.8457396178709592\n",
      "Class 1 Train Accuracy: 0.864041965391848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# XGBoost model\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict using encoded data\n",
    "X_open_customers = open_customers[features]\n",
    "y_open_pred = model.predict(X_open_customers)\n",
    "y_open_pred_proba = model.predict_proba(X_open_customers)[:, 1]  \n",
    "\n",
    "# Store prediction results in unencoded data\n",
    "open_customers_without_encoded['Predicted Status'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability'] = y_open_pred_proba\n",
    "\n",
    "print(f\"Predicted Renewed: {(y_open_pred == 0).sum()}\")\n",
    "print(f\"Predicted Not Renewed: {(y_open_pred == 1).sum()}\")\n",
    "\n",
    "# Evaluate model on training data\n",
    "y_pred = model.predict(X)\n",
    "y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "#Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y, y_pred)\n",
    "train_log_loss = log_loss(y, y_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "train_report = classification_report(y, y_pred)\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y, y_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "#Print the metrics\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Default Threshold (0.5) ===\n",
      "Threshold: 0.5000\n",
      "Train Accuracy: 0.8549\n",
      "Train ROC AUC: 0.9285\n",
      "Train Log Loss: 0.3430\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85    947638\n",
      "           1       0.85      0.86      0.86    947638\n",
      "\n",
      "    accuracy                           0.85   1895276\n",
      "   macro avg       0.86      0.85      0.85   1895276\n",
      "weighted avg       0.86      0.85      0.85   1895276\n",
      "\n",
      "\n",
      "Predicted Renewed: 106676\n",
      "Predicted Not Renewed: 252197\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, accuracy_score, classification_report,\n",
    "    log_loss, roc_auc_score, confusion_matrix\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# -------------------------------\n",
    "# Train the model\n",
    "# -------------------------------\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute thresholds\n",
    "# -------------------------------\n",
    "# Get predicted probabilities on training data\n",
    "y_pred_proba_train = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_proba_train)\n",
    "\n",
    "observed_prevalence = y.mean()\n",
    "\n",
    "# Default Threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# Training set evaluation\n",
    "y_train_pred = (y_pred_proba_train >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_train_pred)\n",
    "roc_auc = roc_auc_score(y, y_pred_proba_train)\n",
    "logloss = log_loss(y, y_pred_proba_train)\n",
    "report = classification_report(y, y_train_pred)\n",
    "\n",
    "print(\"=== Default Threshold (0.5) ===\")\n",
    "print(f\"Threshold: {threshold:.4f}\")\n",
    "print(f\"Train Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Train ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Train Log Loss: {logloss:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Predict on open_customers\n",
    "y_open_pred = (y_open_pred_proba >= threshold).astype(int)\n",
    "open_customers_without_encoded['Predicted Status Default'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability Default'] = y_open_pred_proba\n",
    "\n",
    "print(\"\\nPredicted Renewed:\", (y_open_pred == 0).sum())\n",
    "print(\"Predicted Not Renewed:\", (y_open_pred == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sensitivity = Specificity Threshold ===\n",
      "Threshold: 0.5222\n",
      "Train Accuracy: 0.8547\n",
      "Train ROC AUC: 0.9285\n",
      "Train Log Loss: 0.3430\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85    947638\n",
      "           1       0.85      0.85      0.85    947638\n",
      "\n",
      "    accuracy                           0.85   1895276\n",
      "   macro avg       0.85      0.85      0.85   1895276\n",
      "weighted avg       0.85      0.85      0.85   1895276\n",
      "\n",
      "\n",
      "Predicted Renewed: 117530\n",
      "Predicted Not Renewed: 241343\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, accuracy_score, classification_report,\n",
    "    log_loss, roc_auc_score, confusion_matrix\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# -------------------------------\n",
    "# Train the model\n",
    "# -------------------------------\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute thresholds\n",
    "# -------------------------------\n",
    "# Get predicted probabilities on training data\n",
    "y_pred_proba_train = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_proba_train)\n",
    "\n",
    "observed_prevalence = y.mean()\n",
    "\n",
    "# Sensitivity = Specificity\n",
    "sens_spec_diff = np.abs(tpr - (1 - fpr))\n",
    "threshold = thresholds[np.argmin(sens_spec_diff)]\n",
    "\n",
    "# Training set evaluation\n",
    "y_train_pred = (y_pred_proba_train >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_train_pred)\n",
    "roc_auc = roc_auc_score(y, y_pred_proba_train)\n",
    "logloss = log_loss(y, y_pred_proba_train)\n",
    "report = classification_report(y, y_train_pred)\n",
    "\n",
    "print(\"=== Sensitivity = Specificity Threshold ===\")\n",
    "print(f\"Threshold: {threshold:.4f}\")\n",
    "print(f\"Train Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Train ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Train Log Loss: {logloss:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Predict on open_customers\n",
    "y_open_pred = (y_open_pred_proba >= threshold).astype(int)\n",
    "open_customers_without_encoded['Predicted Status SensSpec'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability SensSpec'] = y_open_pred_proba\n",
    "\n",
    "print(\"\\nPredicted Renewed:\", (y_open_pred == 0).sum())\n",
    "print(\"Predicted Not Renewed:\", (y_open_pred == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Max Sensitivity + Specificity Threshold ===\n",
      "Threshold: 0.5020\n",
      "Train Accuracy: 0.8550\n",
      "Train ROC AUC: 0.9285\n",
      "Train Log Loss: 0.3430\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85    947638\n",
      "           1       0.85      0.86      0.86    947638\n",
      "\n",
      "    accuracy                           0.85   1895276\n",
      "   macro avg       0.86      0.85      0.85   1895276\n",
      "weighted avg       0.86      0.85      0.85   1895276\n",
      "\n",
      "\n",
      "Predicted Renewed: 107617\n",
      "Predicted Not Renewed: 251256\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, accuracy_score, classification_report,\n",
    "    log_loss, roc_auc_score, confusion_matrix\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# -------------------------------\n",
    "# Train the model\n",
    "# -------------------------------\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute thresholds\n",
    "# -------------------------------\n",
    "# Get predicted probabilities on training data\n",
    "y_pred_proba_train = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_proba_train)\n",
    "\n",
    "observed_prevalence = y.mean()\n",
    "\n",
    "# Max Sensitivity + Specificity\n",
    "sens_plus_spec = tpr + (1 - fpr)\n",
    "threshold = thresholds[np.argmax(sens_plus_spec)]\n",
    "\n",
    "# Training set evaluation\n",
    "y_train_pred = (y_pred_proba_train >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_train_pred)\n",
    "roc_auc = roc_auc_score(y, y_pred_proba_train)\n",
    "logloss = log_loss(y, y_pred_proba_train)\n",
    "report = classification_report(y, y_train_pred)\n",
    "\n",
    "print(\"=== Max Sensitivity + Specificity Threshold ===\")\n",
    "print(f\"Threshold: {threshold:.4f}\")\n",
    "print(f\"Train Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Train ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Train Log Loss: {logloss:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Predict on open_customers\n",
    "y_open_pred = (y_open_pred_proba >= threshold).astype(int)\n",
    "open_customers_without_encoded['Predicted Status MaxSensSpec'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability MaxSensSpec'] = y_open_pred_proba\n",
    "\n",
    "print(\"\\nPredicted Renewed:\", (y_open_pred == 0).sum())\n",
    "print(\"Predicted Not Renewed:\", (y_open_pred == 1).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Max Percent Correctly Classified Threshold ===\n",
      "Threshold: 0.5051\n",
      "Train Accuracy: 0.8549\n",
      "Train ROC AUC: 0.9285\n",
      "Train Log Loss: 0.3430\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85    947638\n",
      "           1       0.85      0.86      0.86    947638\n",
      "\n",
      "    accuracy                           0.85   1895276\n",
      "   macro avg       0.85      0.85      0.85   1895276\n",
      "weighted avg       0.85      0.85      0.85   1895276\n",
      "\n",
      "\n",
      "Predicted Renewed: 109102\n",
      "Predicted Not Renewed: 249771\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, accuracy_score, classification_report,\n",
    "    log_loss, roc_auc_score, confusion_matrix\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# -------------------------------\n",
    "# Train the model\n",
    "# -------------------------------\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute thresholds\n",
    "# -------------------------------\n",
    "# Get predicted probabilities on training data\n",
    "y_pred_proba_train = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_proba_train)\n",
    "\n",
    "observed_prevalence = y.mean()\n",
    "\n",
    "# Instead of using ALL thresholds, define a grid\n",
    "threshold_grid = np.linspace(0, 1, 100)\n",
    "\n",
    "accuracy_per_threshold = []\n",
    "for t in threshold_grid:\n",
    "    preds = (y_pred_proba_train >= t).astype(int)\n",
    "    acc = accuracy_score(y, preds)\n",
    "    accuracy_per_threshold.append(acc)\n",
    "\n",
    "# Choose threshold with max accuracy\n",
    "threshold = threshold_grid[np.argmax(accuracy_per_threshold)]\n",
    "\n",
    "# Training set evaluation\n",
    "y_train_pred = (y_pred_proba_train >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_train_pred)\n",
    "roc_auc = roc_auc_score(y, y_pred_proba_train)\n",
    "logloss = log_loss(y, y_pred_proba_train)\n",
    "report = classification_report(y, y_train_pred)\n",
    "\n",
    "print(\"=== Max Percent Correctly Classified Threshold ===\")\n",
    "print(f\"Threshold: {threshold:.4f}\")\n",
    "print(f\"Train Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Train ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Train Log Loss: {logloss:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Predict on open_customers\n",
    "y_open_pred = (y_open_pred_proba >= threshold).astype(int)\n",
    "open_customers_without_encoded['Predicted Status MaxPCC'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability MaxPCC'] = y_open_pred_proba\n",
    "\n",
    "print(\"\\nPredicted Renewed:\", (y_open_pred == 0).sum())\n",
    "print(\"Predicted Not Renewed:\", (y_open_pred == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Max Percent Correctly Classified Threshold ===\n",
      "Threshold: 0.5030\n",
      "Train Accuracy: 0.8549\n",
      "Train ROC AUC: 0.9285\n",
      "Train Log Loss: 0.3430\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85    947638\n",
      "           1       0.85      0.86      0.86    947638\n",
      "\n",
      "    accuracy                           0.85   1895276\n",
      "   macro avg       0.86      0.85      0.85   1895276\n",
      "weighted avg       0.86      0.85      0.85   1895276\n",
      "\n",
      "\n",
      "Predicted Renewed: 108045\n",
      "Predicted Not Renewed: 250828\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, accuracy_score, classification_report,\n",
    "    log_loss, roc_auc_score, confusion_matrix\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# -------------------------------\n",
    "# Train the model\n",
    "# -------------------------------\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute thresholds\n",
    "# -------------------------------\n",
    "# Get predicted probabilities on training data\n",
    "y_pred_proba_train = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_proba_train)\n",
    "\n",
    "observed_prevalence = y.mean()\n",
    "\n",
    "# Instead of using ALL thresholds, define a grid\n",
    "threshold_grid = np.linspace(0, 1, 500)\n",
    "\n",
    "accuracy_per_threshold = []\n",
    "for t in threshold_grid:\n",
    "    preds = (y_pred_proba_train >= t).astype(int)\n",
    "    acc = accuracy_score(y, preds)\n",
    "    accuracy_per_threshold.append(acc)\n",
    "\n",
    "# Choose threshold with max accuracy\n",
    "threshold = threshold_grid[np.argmax(accuracy_per_threshold)]\n",
    "\n",
    "# Training set evaluation\n",
    "y_train_pred = (y_pred_proba_train >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_train_pred)\n",
    "roc_auc = roc_auc_score(y, y_pred_proba_train)\n",
    "logloss = log_loss(y, y_pred_proba_train)\n",
    "report = classification_report(y, y_train_pred)\n",
    "\n",
    "print(\"=== Max Percent Correctly Classified Threshold ===\")\n",
    "print(f\"Threshold: {threshold:.4f}\")\n",
    "print(f\"Train Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Train ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Train Log Loss: {logloss:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Predict on open_customers\n",
    "y_open_pred = (y_open_pred_proba >= threshold).astype(int)\n",
    "open_customers_without_encoded['Predicted Status MaxPCC'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability MaxPCC'] = y_open_pred_proba\n",
    "\n",
    "print(\"\\nPredicted Renewed:\", (y_open_pred == 0).sum())\n",
    "print(\"Predicted Not Renewed:\", (y_open_pred == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Max Percent Correctly Classified Threshold ===\n",
      "Threshold: 0.4898\n",
      "Train Accuracy: 0.8548\n",
      "Train ROC AUC: 0.9285\n",
      "Train Log Loss: 0.3430\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85    947638\n",
      "           1       0.85      0.87      0.86    947638\n",
      "\n",
      "    accuracy                           0.85   1895276\n",
      "   macro avg       0.86      0.85      0.85   1895276\n",
      "weighted avg       0.86      0.85      0.85   1895276\n",
      "\n",
      "\n",
      "Predicted Renewed: 102110\n",
      "Predicted Not Renewed: 256763\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, accuracy_score, classification_report,\n",
    "    log_loss, roc_auc_score, confusion_matrix\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# -------------------------------\n",
    "# Train the model\n",
    "# -------------------------------\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute thresholds\n",
    "# -------------------------------\n",
    "# Get predicted probabilities on training data\n",
    "y_pred_proba_train = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_proba_train)\n",
    "\n",
    "observed_prevalence = y.mean()\n",
    "\n",
    "# Instead of using ALL thresholds, define a grid\n",
    "threshold_grid = np.linspace(0, 1, 50)\n",
    "\n",
    "accuracy_per_threshold = []\n",
    "for t in threshold_grid:\n",
    "    preds = (y_pred_proba_train >= t).astype(int)\n",
    "    acc = accuracy_score(y, preds)\n",
    "    accuracy_per_threshold.append(acc)\n",
    "\n",
    "# Choose threshold with max accuracy\n",
    "threshold = threshold_grid[np.argmax(accuracy_per_threshold)]\n",
    "\n",
    "# Training set evaluation\n",
    "y_train_pred = (y_pred_proba_train >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_train_pred)\n",
    "roc_auc = roc_auc_score(y, y_pred_proba_train)\n",
    "logloss = log_loss(y, y_pred_proba_train)\n",
    "report = classification_report(y, y_train_pred)\n",
    "\n",
    "print(\"=== Max Percent Correctly Classified Threshold ===\")\n",
    "print(f\"Threshold: {threshold:.4f}\")\n",
    "print(f\"Train Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Train ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Train Log Loss: {logloss:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Predict on open_customers\n",
    "y_open_pred = (y_open_pred_proba >= threshold).astype(int)\n",
    "open_customers_without_encoded['Predicted Status MaxPCC'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability MaxPCC'] = y_open_pred_proba\n",
    "\n",
    "print(\"\\nPredicted Renewed:\", (y_open_pred == 0).sum())\n",
    "print(\"Predicted Not Renewed:\", (y_open_pred == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sensitivity = Specificity Threshold ===\n",
      "Threshold: 0.5222\n",
      "Train Accuracy: 0.8547\n",
      "Train ROC AUC: 0.9285\n",
      "Train Log Loss: 0.3430\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85    947638\n",
      "           1       0.85      0.85      0.85    947638\n",
      "\n",
      "    accuracy                           0.85   1895276\n",
      "   macro avg       0.85      0.85      0.85   1895276\n",
      "weighted avg       0.85      0.85      0.85   1895276\n",
      "\n",
      "\n",
      "=== Raw Predictions ===\n",
      "Predicted Renewed: 117530\n",
      "Predicted Not Renewed: 241343\n",
      "\n",
      "Training Churn Prevalence: 0.5\n",
      "\n",
      "=== Recalibrated Probabilities ===\n",
      "Mean Raw Probability: 0.6128\n",
      "Mean Recalibrated Probability: 0.7097\n",
      "\n",
      "=== Recalibrated Predictions (Threshold = 0.5) ===\n",
      "Predicted Renewed: 58137\n",
      "Predicted Not Renewed: 300736\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, accuracy_score, classification_report,\n",
    "    log_loss, roc_auc_score, confusion_matrix\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# -------------------------------\n",
    "# Train the model\n",
    "# -------------------------------\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute thresholds\n",
    "# -------------------------------\n",
    "# Predicted probabilities on training data\n",
    "y_pred_proba_train = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_proba_train)\n",
    "\n",
    "# Sensitivity = Specificity Threshold\n",
    "sens_spec_diff = np.abs(tpr - (1 - fpr))\n",
    "threshold = thresholds[np.argmin(sens_spec_diff)]\n",
    "\n",
    "# -------------------------------\n",
    "# Training set evaluation\n",
    "# -------------------------------\n",
    "y_train_pred = (y_pred_proba_train >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_train_pred)\n",
    "roc_auc = roc_auc_score(y, y_pred_proba_train)\n",
    "logloss = log_loss(y, y_pred_proba_train)\n",
    "report = classification_report(y, y_train_pred)\n",
    "\n",
    "print(\"=== Sensitivity = Specificity Threshold ===\")\n",
    "print(f\"Threshold: {threshold:.4f}\")\n",
    "print(f\"Train Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Train ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Train Log Loss: {logloss:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# -------------------------------\n",
    "# Predict on open_customers\n",
    "# -------------------------------\n",
    "X_open_customers = open_customers[features]\n",
    "y_open_pred_proba = model.predict_proba(X_open_customers)[:, 1]\n",
    "\n",
    "# Raw predictions at selected threshold\n",
    "y_open_pred = (y_open_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Store raw predictions\n",
    "open_customers_without_encoded['Predicted Status SensSpec'] = np.where(\n",
    "    y_open_pred == 1, 'Not Renewed', 'Renewed'\n",
    ")\n",
    "open_customers_without_encoded['Churn Probability SensSpec'] = y_open_pred_proba\n",
    "\n",
    "# Raw prediction counts\n",
    "print(\"\\n=== Raw Predictions ===\")\n",
    "print(\"Predicted Renewed:\", (y_open_pred == 0).sum())\n",
    "print(\"Predicted Not Renewed:\", (y_open_pred == 1).sum())\n",
    "\n",
    "# -------------------------------\n",
    "# Recalibration\n",
    "# -------------------------------\n",
    "# Confirm training prevalence\n",
    "train_churn = y.mean()\n",
    "print(\"\\nTraining Churn Prevalence:\", train_churn)\n",
    "\n",
    "# Real churn prevalence\n",
    "real_churn = 0.63  # Use your production churn\n",
    "\n",
    "# Compute odds\n",
    "original_odds = real_churn / (1 - real_churn)\n",
    "training_odds = train_churn / (1 - train_churn)\n",
    "\n",
    "# Scoring odds\n",
    "scoring_odds = y_open_pred_proba / (1 - y_open_pred_proba)\n",
    "\n",
    "# Adjusted odds\n",
    "adjusted_odds = (scoring_odds * original_odds) / training_odds\n",
    "\n",
    "# Recalibrated probabilities\n",
    "adjusted_probs = 1 / (1 + (1 / adjusted_odds))\n",
    "\n",
    "# Store recalibrated probabilities\n",
    "open_customers_without_encoded[\"Recalibrated Probability\"] = adjusted_probs\n",
    "\n",
    "# Show recalibration summary\n",
    "print(\"\\n=== Recalibrated Probabilities ===\")\n",
    "print(\"Mean Raw Probability: {:.4f}\".format(y_open_pred_proba.mean()))\n",
    "print(\"Mean Recalibrated Probability: {:.4f}\".format(adjusted_probs.mean()))\n",
    "\n",
    "# -------------------------------\n",
    "# Binarize recalibrated probabilities (Threshold = 0.5)\n",
    "# -------------------------------\n",
    "recalibrated_pred = (adjusted_probs >= 0.5).astype(int)\n",
    "\n",
    "# Store recalibrated predicted status\n",
    "open_customers_without_encoded[\"Predicted Status Recalibrated\"] = np.where(\n",
    "    recalibrated_pred == 1, \"Not Renewed\", \"Renewed\"\n",
    ")\n",
    "\n",
    "# Recalibrated prediction counts\n",
    "print(\"\\n=== Recalibrated Predictions (Threshold = 0.5) ===\")\n",
    "print(\"Predicted Renewed:\", (recalibrated_pred == 0).sum())\n",
    "print(\"Predicted Not Renewed:\", (recalibrated_pred == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Predicted Prevalence = Observed Prevalence Threshold ===\n",
      "Threshold: 0.5253\n",
      "Train Accuracy: 0.8546\n",
      "Train ROC AUC: 0.9285\n",
      "Train Log Loss: 0.3430\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85    947638\n",
      "           1       0.86      0.85      0.85    947638\n",
      "\n",
      "    accuracy                           0.85   1895276\n",
      "   macro avg       0.85      0.85      0.85   1895276\n",
      "weighted avg       0.85      0.85      0.85   1895276\n",
      "\n",
      "\n",
      "Predicted Renewed: 119137\n",
      "Predicted Not Renewed: 239736\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, accuracy_score, classification_report,\n",
    "    log_loss, roc_auc_score, confusion_matrix\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# -------------------------------\n",
    "# Train the model\n",
    "# -------------------------------\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute thresholds\n",
    "# -------------------------------\n",
    "# Get predicted probabilities on training data\n",
    "y_pred_proba_train = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_proba_train)\n",
    "\n",
    "observed_prevalence = y.mean()\n",
    "\n",
    "# Instead of all thresholds, use a grid\n",
    "threshold_grid = np.linspace(0, 1, 100)\n",
    "\n",
    "# Compute predicted prevalence per threshold\n",
    "predicted_prevalences = [(y_pred_proba_train >= t).mean() for t in threshold_grid]\n",
    "\n",
    "# Find threshold where predicted prevalence is closest to observed prevalence\n",
    "prevalence_diff = np.abs(np.array(predicted_prevalences) - observed_prevalence)\n",
    "threshold = threshold_grid[np.argmin(prevalence_diff)]\n",
    "\n",
    "# Training set evaluation\n",
    "y_train_pred = (y_pred_proba_train >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_train_pred)\n",
    "roc_auc = roc_auc_score(y, y_pred_proba_train)\n",
    "logloss = log_loss(y, y_pred_proba_train)\n",
    "report = classification_report(y, y_train_pred)\n",
    "\n",
    "print(\"=== Predicted Prevalence = Observed Prevalence Threshold ===\")\n",
    "print(f\"Threshold: {threshold:.4f}\")\n",
    "print(f\"Train Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Train ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Train Log Loss: {logloss:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Predict on open_customers\n",
    "y_open_pred = (y_open_pred_proba >= threshold).astype(int)\n",
    "open_customers_without_encoded['Predicted Status PredPrev'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability PredPrev'] = y_open_pred_proba\n",
    "\n",
    "print(\"\\nPredicted Renewed:\", (y_open_pred == 0).sum())\n",
    "print(\"Predicted Not Renewed:\", (y_open_pred == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Predicted Prevalence = Observed Prevalence Threshold ===\n",
      "Threshold: 0.5306\n",
      "Train Accuracy: 0.8546\n",
      "Train ROC AUC: 0.9285\n",
      "Train Log Loss: 0.3430\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86    947638\n",
      "           1       0.86      0.85      0.85    947638\n",
      "\n",
      "    accuracy                           0.85   1895276\n",
      "   macro avg       0.85      0.85      0.85   1895276\n",
      "weighted avg       0.85      0.85      0.85   1895276\n",
      "\n",
      "\n",
      "Predicted Renewed: 121990\n",
      "Predicted Not Renewed: 236883\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, accuracy_score, classification_report,\n",
    "    log_loss, roc_auc_score, confusion_matrix\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# -------------------------------\n",
    "# Train the model\n",
    "# -------------------------------\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute thresholds\n",
    "# -------------------------------\n",
    "# Get predicted probabilities on training data\n",
    "y_pred_proba_train = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_proba_train)\n",
    "\n",
    "observed_prevalence = y.mean()\n",
    "\n",
    "# Instead of all thresholds, use a grid\n",
    "threshold_grid = np.linspace(0, 1, 50)\n",
    "\n",
    "# Compute predicted prevalence per threshold\n",
    "predicted_prevalences = [(y_pred_proba_train >= t).mean() for t in threshold_grid]\n",
    "\n",
    "# Find threshold where predicted prevalence is closest to observed prevalence\n",
    "prevalence_diff = np.abs(np.array(predicted_prevalences) - observed_prevalence)\n",
    "threshold = threshold_grid[np.argmin(prevalence_diff)]\n",
    "\n",
    "# Training set evaluation\n",
    "y_train_pred = (y_pred_proba_train >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_train_pred)\n",
    "roc_auc = roc_auc_score(y, y_pred_proba_train)\n",
    "logloss = log_loss(y, y_pred_proba_train)\n",
    "report = classification_report(y, y_train_pred)\n",
    "\n",
    "print(\"=== Predicted Prevalence = Observed Prevalence Threshold ===\")\n",
    "print(f\"Threshold: {threshold:.4f}\")\n",
    "print(f\"Train Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Train ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Train Log Loss: {logloss:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Predict on open_customers\n",
    "y_open_pred = (y_open_pred_proba >= threshold).astype(int)\n",
    "open_customers_without_encoded['Predicted Status PredPrev'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability PredPrev'] = y_open_pred_proba\n",
    "\n",
    "print(\"\\nPredicted Renewed:\", (y_open_pred == 0).sum())\n",
    "print(\"Predicted Not Renewed:\", (y_open_pred == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# XGBoost model\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define three XGBoost models with different parameters\n",
    "clf_xgb1 = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf_xgb2 = xgb.XGBClassifier(\n",
    "    max_depth=6,                  \n",
    "    learning_rate=0.1,            \n",
    "    n_estimators=100,            \n",
    "    scale_pos_weight=len(y[y == 0]) / len(y[y == 1]), \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create a VotingClassifier ensemble with soft voting\n",
    "model = VotingClassifier(\n",
    "    estimators=[('xgb1', clf_xgb1), ('xgb2', clf_xgb2)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict using encoded data\n",
    "X_open_customers = open_customers[features]\n",
    "y_open_pred = model.predict(X_open_customers)\n",
    "y_open_pred_proba = model.predict_proba(X_open_customers)[:, 1]  \n",
    "\n",
    "# Store prediction results in unencoded data\n",
    "open_customers_without_encoded['Predicted Status'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability'] = y_open_pred_proba\n",
    "\n",
    "print(f\"Predicted Renewed: {(y_open_pred == 0).sum()}\")\n",
    "print(f\"Predicted Not Renewed: {(y_open_pred == 1).sum()}\")\n",
    "\n",
    "# Evaluate model on training data\n",
    "y_pred = model.predict(X)\n",
    "y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "#Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y, y_pred)\n",
    "train_log_loss = log_loss(y, y_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "train_report = classification_report(y, y_pred)\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y, y_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "#Print the metrics\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "open_customers_without_encoded.to_csv('future prediction XGB test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Renewed: 125102\n",
      "Predicted Not Renewed: 233771\n",
      "Train Accuracy: 0.8557096697262034\n",
      "Train Log Loss: 0.3421041235205226\n",
      "Train ROC AUC: 0.9292134744340229\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85    947638\n",
      "           1       0.85      0.86      0.86    947638\n",
      "\n",
      "    accuracy                           0.86   1895276\n",
      "   macro avg       0.86      0.86      0.86   1895276\n",
      "weighted avg       0.86      0.86      0.86   1895276\n",
      "\n",
      "Class 0 Train Accuracy: 0.8487196587726537\n",
      "Class 1 Train Accuracy: 0.8626996806797532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# XGBoost model\n",
    "model = GradientBoostingClassifier(\n",
    "    max_depth=6,                    \n",
    "    learning_rate=0.1,              \n",
    "    n_estimators=100,              \n",
    "    random_state=42                 \n",
    ")\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict using encoded data\n",
    "X_open_customers = open_customers[features]\n",
    "y_open_pred = model.predict(X_open_customers)\n",
    "y_open_pred_proba = model.predict_proba(X_open_customers)[:, 1]  \n",
    "\n",
    "# Store prediction results in unencoded data\n",
    "open_customers_without_encoded['Predicted Status'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability'] = y_open_pred_proba\n",
    "\n",
    "print(f\"Predicted Renewed: {(y_open_pred == 0).sum()}\")\n",
    "print(f\"Predicted Not Renewed: {(y_open_pred == 1).sum()}\")\n",
    "\n",
    "# Evaluate model on training data\n",
    "y_pred = model.predict(X)\n",
    "y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "#Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y, y_pred)\n",
    "train_log_loss = log_loss(y, y_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "train_report = classification_report(y, y_pred)\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y, y_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "#Print the metrics\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "open_customers_without_encoded.to_csv('future prediction GBM1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Renewed: 56226\n",
      "Predicted Not Renewed: 302647\n",
      "Train Accuracy: 0.8511409420052805\n",
      "Train Log Loss: 0.35329877381012564\n",
      "Train ROC AUC: 0.9244575007855427\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85    947638\n",
      "           1       0.84      0.86      0.85    947638\n",
      "\n",
      "    accuracy                           0.85   1895276\n",
      "   macro avg       0.85      0.85      0.85   1895276\n",
      "weighted avg       0.85      0.85      0.85   1895276\n",
      "\n",
      "Class 0 Train Accuracy: 0.8419079859608838\n",
      "Class 1 Train Accuracy: 0.8603738980496772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# XGBoost model\n",
    "model = GradientBoostingClassifier(\n",
    "    max_depth=5,                   \n",
    "    learning_rate=0.05,             \n",
    "    n_estimators=200,               \n",
    "    subsample=0.8,                 \n",
    "    random_state=42                 \n",
    ")\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict using encoded data\n",
    "X_open_customers = open_customers[features]\n",
    "y_open_pred = model.predict(X_open_customers)\n",
    "y_open_pred_proba = model.predict_proba(X_open_customers)[:, 1]  \n",
    "\n",
    "# Store prediction results in unencoded data\n",
    "open_customers_without_encoded['Predicted Status'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability'] = y_open_pred_proba\n",
    "\n",
    "print(f\"Predicted Renewed: {(y_open_pred == 0).sum()}\")\n",
    "print(f\"Predicted Not Renewed: {(y_open_pred == 1).sum()}\")\n",
    "\n",
    "# Evaluate model on training data\n",
    "y_pred = model.predict(X)\n",
    "y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "#Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y, y_pred)\n",
    "train_log_loss = log_loss(y, y_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "train_report = classification_report(y, y_pred)\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y, y_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "#Print the metrics\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=5,                  \n",
    "    learning_rate=0.05,            \n",
    "    n_estimators=200,              \n",
    "    subsample=0.8,                 \n",
    "    colsample_bytree=0.8,         \n",
    "    scale_pos_weight=len(y[y == 0]) / len(y[y == 1]),  \n",
    "    gamma=0.1,                    \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict using encoded data\n",
    "X_open_customers = open_customers[features]\n",
    "y_open_pred = model.predict(X_open_customers)\n",
    "y_open_pred_proba = model.predict_proba(X_open_customers)[:, 1]  \n",
    "\n",
    "# Store prediction results in unencoded data\n",
    "open_customers_without_encoded['Predicted Status'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability'] = y_open_pred_proba\n",
    "\n",
    "print(f\"Predicted Renewed: {(y_open_pred == 0).sum()}\")\n",
    "print(f\"Predicted Not Renewed: {(y_open_pred == 1).sum()}\")\n",
    "\n",
    "# Evaluate model on training data\n",
    "y_pred = model.predict(X)\n",
    "y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "#Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y, y_pred)\n",
    "train_log_loss = log_loss(y, y_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "train_report = classification_report(y, y_pred)\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y, y_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "#Print the metrics\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# XGBoost model\n",
    "model = CatBoostClassifier(\n",
    "    depth=10,                    \n",
    "    learning_rate=0.1,            \n",
    "    iterations=500,               \n",
    "    random_seed=42,               \n",
    "    verbose=0                     \n",
    ")\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict using encoded data\n",
    "X_open_customers = open_customers[features]\n",
    "y_open_pred = model.predict(X_open_customers)\n",
    "y_open_pred_proba = model.predict_proba(X_open_customers)[:, 1]  \n",
    "\n",
    "# Store prediction results in unencoded data\n",
    "open_customers_without_encoded['Predicted Status'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability'] = y_open_pred_proba\n",
    "\n",
    "print(f\"Predicted Renewed: {(y_open_pred == 0).sum()}\")\n",
    "print(f\"Predicted Not Renewed: {(y_open_pred == 1).sum()}\")\n",
    "\n",
    "# Evaluate model on training data\n",
    "y_pred = model.predict(X)\n",
    "y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "#Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y, y_pred)\n",
    "train_log_loss = log_loss(y, y_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "train_report = classification_report(y, y_pred)\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y, y_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "#Print the metrics\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# XGBoost model\n",
    "model = RandomForestClassifier(random_state=42, max_depth=10)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict using encoded data\n",
    "X_open_customers = open_customers[features]\n",
    "y_open_pred = model.predict(X_open_customers)\n",
    "y_open_pred_proba = model.predict_proba(X_open_customers)[:, 1]  \n",
    "\n",
    "# Store prediction results in unencoded data\n",
    "open_customers_without_encoded['Predicted Status'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability'] = y_open_pred_proba\n",
    "\n",
    "print(f\"Predicted Renewed: {(y_open_pred == 0).sum()}\")\n",
    "print(f\"Predicted Not Renewed: {(y_open_pred == 1).sum()}\")\n",
    "\n",
    "# Evaluate model on training data\n",
    "y_pred = model.predict(X)\n",
    "y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "#Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y, y_pred)\n",
    "train_log_loss = log_loss(y, y_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "train_report = classification_report(y, y_pred)\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y, y_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "#Print the metrics\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# XGBoost model\n",
    "model = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict using encoded data\n",
    "X_open_customers = open_customers[features]\n",
    "y_open_pred = model.predict(X_open_customers)\n",
    "y_open_pred_proba = model.predict_proba(X_open_customers)[:, 1]  \n",
    "\n",
    "# Store prediction results in unencoded data\n",
    "open_customers_without_encoded['Predicted Status'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability'] = y_open_pred_proba\n",
    "\n",
    "print(f\"Predicted Renewed: {(y_open_pred == 0).sum()}\")\n",
    "print(f\"Predicted Not Renewed: {(y_open_pred == 1).sum()}\")\n",
    "\n",
    "# Evaluate model on training data\n",
    "y_pred = model.predict(X)\n",
    "y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "#Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y, y_pred)\n",
    "train_log_loss = log_loss(y, y_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "train_report = classification_report(y, y_pred)\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y, y_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "#Print the metrics\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
