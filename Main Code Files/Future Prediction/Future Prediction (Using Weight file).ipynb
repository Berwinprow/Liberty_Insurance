{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved in Open_predictions.csv\n",
      "Predicted Renewed: 124973\n",
      "Predicted Not Renewed: 233900\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Load saved model and label encoders\n",
    "model = joblib.load(\"gbm_model.pkl\")\n",
    "label_encoders = joblib.load(\"label_encoders_gbm.pkl\")\n",
    "features = joblib.load(\"model_features_gbm.pkl\") \n",
    "\n",
    "# Load Data from PostgreSQL\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'Liberty',\n",
    "    'user': 'postgres',\n",
    "    'password': 'abc',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query = 'SELECT * FROM public.policydata_with_fb_cc_pc_newfea_opti_correct;'\n",
    "data = pd.read_sql(query, con=engine)\n",
    "\n",
    "selected_columns = ['rto_risk_factor', 'ncb % previous year', 'state_risk_score', 'retention_rate_pct', 'total od premium_max', 'applicable discount with ncb', \n",
    "                    'policy_wise_purchase', 'manufacturer_risk_rate', 'days_between_renewals', 'retention_streak', 'total od premium_mean', 'total od premium', \n",
    "                    'firstpolicyyear', 'lag_1_tp_premium', 'total od premium_min', 'avg_premium_hist', 'lag_1_ncb', 'age', 'total tp premium_max', 'total tp premium_mean', \n",
    "                    'total tp premium', 'total tp premium_min', 'lag_1_premium', 'previous_year_premium_ratio', 'total premium payable', 'total_revenue', 'gst', \n",
    "                    'fuel_type_risk_factor', 'lag_1_od_premium', 'Customer_APV', 'segment_risk_score', 'vehicle idv', 'Policy Tenure', 'Number of claims', 'approved', \n",
    "                    'claim_approval_rate', 'Customer Tenure', 'before gst add-on gwp', 'od_tp_ratio', 'add_on_adoption', 'CLV', 'idv_premium_ratio', 'Customer_APF', \n",
    "                    'days_gap_prev_end_to_curr_start', 'customerid', 'Claim Happaned/Not', 'Cleaned Branch Name 2', 'Cleaned Chassis Number', 'Cleaned Engine Number', \n",
    "                    'Cleaned Reg no', 'Cleaned State2', 'Cleaned Zone 2', 'biztype', 'corrected_name', 'make_clean', 'model_clean', 'product name', 'policy no', \n",
    "                    'policy end date', 'policy start date', 'decline', 'tie up', 'variant', 'Policy Status']\n",
    "\n",
    "data = data[selected_columns]\n",
    "\n",
    "# Convert Policy End Date to datetime\n",
    "data['policy end date'] = pd.to_datetime(data['policy end date'], errors='coerce')\n",
    "\n",
    "# Filter open customers (Jan - March 2025)\n",
    "open_customers = data[\n",
    "    (data['Policy Status'] == 'Open') & \n",
    "    (data['policy end date'].dt.year == 2025) & \n",
    "    (data['policy end date'].dt.month.isin([1, 2, 3, 4, 5, 6]))\n",
    "].copy()\n",
    "\n",
    "# Extract date features\n",
    "for col in ['policy start date', 'policy end date']:\n",
    "    open_customers[col] = pd.to_datetime(open_customers[col], errors='coerce')\n",
    "\n",
    "open_customers_new_date_cols = {\n",
    "    f'{col}_YEAR': open_customers[col].dt.year for col in ['policy start date', 'policy end date']\n",
    "}\n",
    "open_customers_new_date_cols.update({\n",
    "    f'{col}_MONTH': open_customers[col].dt.month for col in ['policy start date', 'policy end date']\n",
    "})\n",
    "open_customers_new_date_cols.update({\n",
    "    f'{col}_DAY': open_customers[col].dt.day for col in ['policy start date', 'policy end date']\n",
    "})\n",
    "\n",
    "open_customers = pd.concat([open_customers, pd.DataFrame(open_customers_new_date_cols)], axis=1)\n",
    "open_customers = open_customers.drop(columns=['policy start date', 'policy end date'])\n",
    "\n",
    "# Handle missing values\n",
    "for column in open_customers.columns:\n",
    "    if open_customers[column].dtype == 'object':\n",
    "        open_customers[column] = open_customers[column].fillna('none')\n",
    "    else:\n",
    "        open_customers[column] = open_customers[column].fillna(0)\n",
    "\n",
    "# Label Encoding for open customers using dynamic mapping\n",
    "open_customers_encoded = open_customers.copy()\n",
    "\n",
    "for column in open_customers_encoded.columns:\n",
    "    if column in label_encoders:  \n",
    "        encoder = label_encoders[column]\n",
    "\n",
    "        # Get existing mapping from the trained encoder\n",
    "        mapping_dict = {label: i for i, label in enumerate(encoder.classes_)}\n",
    "        next_unique_value = [max(mapping_dict.values()) + 1]  \n",
    "\n",
    "        # Function to encode new values dynamically\n",
    "        def encode_test_value(value):\n",
    "            if value in mapping_dict:\n",
    "                return mapping_dict[value]\n",
    "            else:\n",
    "                mapping_dict[value] = next_unique_value[0]\n",
    "                next_unique_value[0] += 1\n",
    "                return mapping_dict[value]\n",
    "        \n",
    "        open_customers_encoded[column] = open_customers_encoded[column].apply(encode_test_value)\n",
    "\n",
    "# Predict\n",
    "X_open_customers = open_customers_encoded[features]\n",
    "y_open_pred = model.predict(X_open_customers)\n",
    "y_open_pred_proba = model.predict_proba(X_open_customers)[:, 1]\n",
    "\n",
    "open_customers['Predicted Status'] = ['Not Renewed' if pred == 1 else 'Renewed' for pred in y_open_pred]\n",
    "open_customers['Churn Probability'] = y_open_pred_proba\n",
    "\n",
    "# Save predictions\n",
    "open_customers.to_csv(\"GBM1_predictions_JFMAMJ(Final).csv\", index=False)\n",
    "print(\"Predictions saved in Open_predictions.csv\")\n",
    "\n",
    "print(f\"Predicted Renewed: {(y_open_pred == 0).sum()}\")\n",
    "print(f\"Predicted Not Renewed: {(y_open_pred == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved in Open_predictions.csv\n",
      "Predicted Renewed: 101376\n",
      "Predicted Not Renewed: 215032\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Load saved model and label encoders\n",
    "model = joblib.load(\"gbm_model.pkl\")\n",
    "label_encoders = joblib.load(\"label_encoders_gbm.pkl\")\n",
    "features = joblib.load(\"model_features_gbm.pkl\") \n",
    "\n",
    "# Load Data from PostgreSQL\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'Liberty',\n",
    "    'user': 'postgres',\n",
    "    'password': 'abc',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query = 'SELECT * FROM public.policydata_with_fb_cc_pc_newfea_opti_correct;'\n",
    "data = pd.read_sql(query, con=engine)\n",
    "\n",
    "selected_columns = ['rto_risk_factor', 'ncb % previous year', 'state_risk_score', 'retention_rate_pct', 'total od premium_max', 'applicable discount with ncb', \n",
    "                    'policy_wise_purchase', 'manufacturer_risk_rate', 'days_between_renewals', 'retention_streak', 'total od premium_mean', 'total od premium', \n",
    "                    'firstpolicyyear', 'lag_1_tp_premium', 'total od premium_min', 'avg_premium_hist', 'lag_1_ncb', 'age', 'total tp premium_max', 'total tp premium_mean', \n",
    "                    'total tp premium', 'total tp premium_min', 'lag_1_premium', 'previous_year_premium_ratio', 'total premium payable', 'total_revenue', 'gst', \n",
    "                    'fuel_type_risk_factor', 'lag_1_od_premium', 'Customer_APV', 'segment_risk_score', 'vehicle idv', 'Policy Tenure', 'Number of claims', 'approved', \n",
    "                    'claim_approval_rate', 'Customer Tenure', 'before gst add-on gwp', 'od_tp_ratio', 'add_on_adoption', 'CLV', 'idv_premium_ratio', 'Customer_APF', \n",
    "                    'days_gap_prev_end_to_curr_start', 'customerid', 'Claim Happaned/Not', 'Cleaned Branch Name 2', 'Cleaned Chassis Number', 'Cleaned Engine Number', \n",
    "                    'Cleaned Reg no', 'Cleaned State2', 'Cleaned Zone 2', 'biztype', 'corrected_name', 'make_clean', 'model_clean', 'product name', 'policy no', \n",
    "                    'policy end date', 'policy start date', 'decline', 'tie up', 'variant', 'Policy Status']\n",
    "\n",
    "data = data[selected_columns]\n",
    "\n",
    "# Convert Policy End Date to datetime\n",
    "data['policy end date'] = pd.to_datetime(data['policy end date'], errors='coerce')\n",
    "\n",
    "# Filter open customers (Jan - March 2025)\n",
    "open_customers = data[\n",
    "    (data['Policy Status'] == 'Open') & \n",
    "    (data['policy end date'].dt.year == 2025) & \n",
    "    (data['policy end date'].dt.month.isin([7, 8, 9, 10, 11, 12]))\n",
    "].copy()\n",
    "\n",
    "# Extract date features\n",
    "for col in ['policy start date', 'policy end date']:\n",
    "    open_customers[col] = pd.to_datetime(open_customers[col], errors='coerce')\n",
    "\n",
    "open_customers_new_date_cols = {\n",
    "    f'{col}_YEAR': open_customers[col].dt.year for col in ['policy start date', 'policy end date']\n",
    "}\n",
    "open_customers_new_date_cols.update({\n",
    "    f'{col}_MONTH': open_customers[col].dt.month for col in ['policy start date', 'policy end date']\n",
    "})\n",
    "open_customers_new_date_cols.update({\n",
    "    f'{col}_DAY': open_customers[col].dt.day for col in ['policy start date', 'policy end date']\n",
    "})\n",
    "\n",
    "open_customers = pd.concat([open_customers, pd.DataFrame(open_customers_new_date_cols)], axis=1)\n",
    "open_customers = open_customers.drop(columns=['policy start date', 'policy end date'])\n",
    "\n",
    "# Handle missing values\n",
    "for column in open_customers.columns:\n",
    "    if open_customers[column].dtype == 'object':\n",
    "        open_customers[column] = open_customers[column].fillna('none')\n",
    "    else:\n",
    "        open_customers[column] = open_customers[column].fillna(0)\n",
    "\n",
    "# Label Encoding for open customers using dynamic mapping\n",
    "open_customers_encoded = open_customers.copy()\n",
    "\n",
    "for column in open_customers_encoded.columns:\n",
    "    if column in label_encoders:  \n",
    "        encoder = label_encoders[column]\n",
    "\n",
    "        # Get existing mapping from the trained encoder\n",
    "        mapping_dict = {label: i for i, label in enumerate(encoder.classes_)}\n",
    "        next_unique_value = [max(mapping_dict.values()) + 1]  \n",
    "\n",
    "        # Function to encode new values dynamically\n",
    "        def encode_test_value(value):\n",
    "            if value in mapping_dict:\n",
    "                return mapping_dict[value]\n",
    "            else:\n",
    "                mapping_dict[value] = next_unique_value[0]\n",
    "                next_unique_value[0] += 1\n",
    "                return mapping_dict[value]\n",
    "        \n",
    "        open_customers_encoded[column] = open_customers_encoded[column].apply(encode_test_value)\n",
    "\n",
    "# Predict\n",
    "X_open_customers = open_customers_encoded[features]\n",
    "y_open_pred = model.predict(X_open_customers)\n",
    "y_open_pred_proba = model.predict_proba(X_open_customers)[:, 1]\n",
    "\n",
    "open_customers['Predicted Status'] = ['Not Renewed' if pred == 1 else 'Renewed' for pred in y_open_pred]\n",
    "open_customers['Churn Probability'] = y_open_pred_proba\n",
    "\n",
    "# Save predictions\n",
    "open_customers.to_csv(\"GBM1_predictions_JASOND(Final).csv\", index=False)\n",
    "print(\"Predictions saved in Open_predictions.csv\")\n",
    "\n",
    "print(f\"Predicted Renewed: {(y_open_pred == 0).sum()}\")\n",
    "print(f\"Predicted Not Renewed: {(y_open_pred == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
