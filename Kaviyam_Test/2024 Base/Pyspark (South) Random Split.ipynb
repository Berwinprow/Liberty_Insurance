{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------------+--------------------+---------------+----------------+---------------+--------------------+-------------------------------+-----------------+--------------------------+-------------+-----+-----------------+-----------------+-------------------+-------------------+-------------+-------------------+---------+--------------------+-----------+------------------+--------------+-----------+----------+----------------+----------------------+----------------+----------------+----------------+-----------------+--------------------+--------+---------------------+-----------------------+---------------------+----------------+----------------+-----------------------------+-------+----------------------+---------------------------+-------------------+---------------+----------------+-------------+------+------+------------------------+---------------------+----------------------------+-------------------------------+---------------------------+-----------------------------------------------+-------+------------------+---------------+----------------+-------+------------+---------+------+---------+------+-----------+----+----------+--------------------+--------------------+----------+-------------+-------------------+-------------+----------+--------+--------------------------+------------------+---------------+---------------+---------------+-------------+-----------+-------------------+----------------+\n",
      "|Policy Number|           Policy No|Renewal Type|       Product name |Product name  2|         biztype|Policy End Date|       Insured name |Renewal Notice generation date |Policy Start Date|Renewal Policy Start date |      Reg no |  age|Reg Year Bucket 2|     enginenumber|     CHASSIS NUMBER|  MANUFACTURER/Make|        model|            variant|Fuel Type|       RTO Location |Vehicle IDV|Claim in last year|Last Year NCB |Renewal NCB|NCB Amount|OD Prem Post NCB|Premium After Discount|Nil Depreciation|Passenger Assist|Consumable Cover|Engine Safe Cover|Road Side Assistance|Key Loss|Total Add-on with GST|Removing GST  in Add-on|Before GST Add-on GWP|Total OD Premium|Total TP Premium|Premium Before Applicable Tax|    gst|Total Premium Payable |Premium Payable without NCB|NCB % Previous Year|Vehicle Segment| New Branch Name| New Vertical|Zone 3|state3|Hyundai Discount Status |OEM Discount Category|Applicable Discount with NCB|Applicable Discount without NCB|Discount Category  with NCB|Add on Eligibilty (5th & 6th Renewals With NCB)|  Month|New Branch Name  2|Invited Premium|Renewed  Premium|decline|OEM Category|   Tie Up|Zone 2|   state2|booked|Booked Date|Type|null_count|Cleaned_Insured name|     CustomerID_Base|CustomerID|Policy Status|Policy Tenure Month|Policy Tenure|Start Year|End Year|Cumulative Tenure (Months)|    Tenure Decimal|Customer Tenure|FirstPolicyYear|New_Customer_ID|New Customers|Churn Label|Renewal Rate Status|Number of Claims|\n",
      "+-------------+--------------------+------------+--------------------+---------------+----------------+---------------+--------------------+-------------------------------+-----------------+--------------------------+-------------+-----+-----------------+-----------------+-------------------+-------------------+-------------+-------------------+---------+--------------------+-----------+------------------+--------------+-----------+----------+----------------+----------------------+----------------+----------------+----------------+-----------------+--------------------+--------+---------------------+-----------------------+---------------------+----------------+----------------+-----------------------------+-------+----------------------+---------------------------+-------------------+---------------+----------------+-------------+------+------+------------------------+---------------------+----------------------------+-------------------------------+---------------------------+-----------------------------------------------+-------+------------------+---------------+----------------+-------+------------+---------+------+---------+------+-----------+----+----------+--------------------+--------------------+----------+-------------+-------------------+-------------+----------+--------+--------------------------+------------------+---------------+---------------+---------------+-------------+-----------+-------------------+----------------+\n",
      "|         NULL|'2025500204218001...|          FY|PrivateCarStandal...|            SOD|Renewal Business|     2024-03-16|      MAHADEVA D K .|                           NULL|       2023-03-17|                      NULL|KA-09-MF-8555|  2.0|             NULL|     G4LALM708457| 'MALFC81BLMM189772|            HYUNDAI|        VENUE|              1.2 S|     NULL|         MYSORE WEST|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|         2656.85|            NULL|            NULL|             NULL|                NULL|   98.94|                 NULL|                   NULL|              2954.78|          5625.0|             0.0|                         NULL| 1012.5|                6638.0|                       NULL|               20.0|          SUV 1|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        79.0|                           NULL|                       NULL|                                           NULL| Mar'23|            MYSORE|           NULL|            NULL|     No|        NULL|  HYUNDAI| SOUTH|KARNATAKA|     0|       NULL|   B|      NULL|          mahadevadk|   mahadevadk_MYSORE|   1363545|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|         No|           Increase|               0|\n",
      "|         NULL|'2025500204228000...|  SY onwards|    PrivateCarPolicy|        Package|Renewal Business|     2024-09-20|      SOWMYA SHREE B|                           NULL|       2023-09-21|                      NULL|KA-09-MF-3022|  3.0|             NULL|     G4HGLM070160| 'MALAF51CLLM124529|            HYUNDAI|       SANTRO|             SPORTZ|     NULL|         MYSORE WEST|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|            NULL|            NULL|            NULL|             NULL|                NULL|    99.0|                 NULL|                   NULL|                298.0|          2370.0|          3941.0|                         NULL|1135.98|                7447.0|                       NULL|               25.0|        COMPACT|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        70.0|                           NULL|                       NULL|                                           NULL| Sep'23|            MYSORE|           NULL|            NULL|     No|        NULL|  HYUNDAI| SOUTH|KARNATAKA|     0|       NULL|   B|      NULL|        sowmyashreeb| sowmyashreeb_MYSORE|   1724912|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|         No|           Increase|               0|\n",
      "|         NULL|'2025500204228000...|          FY|PrivateCarStandal...|            SOD|Renewal Business|     2024-10-21|            RAVI M B|                           NULL|       2023-10-22|                      NULL|KA-12-MB-1211|  2.0|             NULL|REVTRN11JYXK86716| 'MAT627226MLK74789|        TATA MOTORS|        NEXON|     1.2 PETROL XMA|     NULL|            MADIKERI|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|         3501.19|            NULL|            NULL|             NULL|                NULL|   300.0|                 NULL|                   NULL|              4001.19|          7716.0|             0.0|                         NULL|1388.88|                9105.0|                       NULL|               20.0|          SUV 1|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        75.0|                           NULL|                       NULL|                                           NULL| Sep'23|            MYSORE|           NULL|            NULL|     No|        NULL|  TATA PV| SOUTH|KARNATAKA|     0|       NULL|   B|      NULL|              ravimb|       ravimb_MYSORE|   1599190|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|         No|           Increase|               0|\n",
      "|         NULL|'2025500204228000...|  SY onwards|    PrivateCarPolicy|        Package|Renewal Business|     2024-10-16|         KUMAR J A .|                           NULL|       2023-10-17|                      NULL|KA-09-MF-3819| 2.99|             NULL|     G4FLLV079738| 'MALPA812LLM076638|            HYUNDAI|        CRETA|       E 1.5 PETROL|     NULL|         MYSORE WEST|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|         3149.96|            NULL|            NULL|             NULL|                NULL|    99.0|                 NULL|                   NULL|              3447.96|          6741.0|          3941.0|                         NULL|1922.76|               12605.0|                       NULL|                0.0|          SUV 1|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        79.0|                           NULL|                       NULL|                                           NULL| Oct'23|            MYSORE|           NULL|            NULL|     No|        NULL|  HYUNDAI| SOUTH|KARNATAKA|     0|       NULL|   B|      NULL|             kumarja|      kumarja_MYSORE|   1340797|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|         No|           Increase|               0|\n",
      "|         NULL|'2011500203228000...|          FY|PrivateCarStandal...|            SOD|Renewal Business|     2024-04-22|AUSTIN PHILIP D S...|                           NULL|       2023-04-23|                      NULL|KA-20-ME-2097|  1.0|             NULL|REVTRN10DXXM57979| 'MAT634012NPDL2260|        TATA MOTORS|        PUNCH|       CREATIVE AMT|     NULL|               UDUPI|       NULL|               Yes|          NULL|       NULL|      NULL|            NULL|                  NULL|         2548.99|           250.0|          873.94|             NULL|                NULL|   300.0|                 NULL|                   NULL|              3972.93|         15593.0|             0.0|                         NULL|2806.74|               18400.0|                       NULL|                0.0|          SUV 1|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        50.0|                           NULL|                       NULL|                                           NULL| Apr'23|         MANGALORE|           NULL|            NULL|     No|        NULL|  TATA PV| SOUTH|KARNATAKA|     0|       NULL|   B|      NULL|  austinphilipdsilva|austinphilipdsilv...|   1087497|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|        Yes|           Increase|               1|\n",
      "|         NULL|'2011500206227000...|          FY|    PrivateCarPolicy|        Package|       Roll Over|     2024-10-26|           BASAVARAJ|                           NULL|       2023-10-27|                      NULL| KA-36-N-7070| 6.94|             NULL|      D13A2925265| 'MA3NYFB1SGK161206|             MARUTI|VITARA BREZZA|       ZDI PLUS AMT|     NULL|             RAICHUR|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|            NULL|            NULL|            NULL|             NULL|               249.0|    NULL|                 NULL|                   NULL|                249.0|          4546.0|          4141.0|                         NULL|1563.66|               10251.0|                       NULL|                0.0|          SUV 1|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        67.0|                           NULL|                       NULL|                                           NULL| Oct'23|          GULBARGA|           NULL|            NULL|     No|        NULL|EM Agency| SOUTH|KARNATAKA|     0|       NULL|   B|      NULL|           basavaraj|  basavaraj_GULBARGA|   1102355|  Not Renewed|                 12|          1.0|      2023|    2024|                        43|3.5833333333333335|            4.0|           2022|           NULL|           No|         No|           Decrease|               0|\n",
      "|         NULL|'2011500302218002...|          FY|PrivateCarStandal...|            SOD|Renewal Business|     2024-01-10|  B RATHEESH KUMAR .|                           NULL|       2023-01-11|                      NULL|  KL-81--9575|  1.0|             NULL|     G4LAMM087884|  MALFC81BLNM290935|            HYUNDAI|        VENUE|         1.2 S PLUS|   Petrol|VARKALA THIRUVANA...|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|         3112.68|            NULL|          741.11|             NULL|                NULL|   175.5|                 NULL|                   NULL|              4204.19|         10826.0|             0.0|                         NULL|1948.68|               12775.0|                       NULL|                0.0|          SUV 1|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        65.0|                           NULL|                       NULL|                                           NULL| Jan'23|        TRIVANDRUM|           NULL|            NULL|     No|        NULL|  HYUNDAI| SOUTH|   KERALA|     0|       NULL|   B|      NULL|      bratheeshkumar|bratheeshkumar_TR...|   1129902|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|         No|           Increase|               0|\n",
      "|         NULL|'2011500303217003...|  SY onwards|    PrivateCarPolicy|        Package|Renewal Business|     2024-02-12| ASWIN NARAYANAN A.K|                           NULL|       2023-02-13|                      NULL|KL-11-BN-8777| 3.96|             NULL|     K12MN4447395| 'MA3NFG81SJH217474|             MARUTI|        IGNIS|      DELTA 1.2 AMT|     NULL|           KOZHIKODE|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|         2580.98|           250.0|          737.42|             NULL|                NULL|    NULL|                 NULL|                   NULL|               3568.4|          4863.0|          3841.0|                         NULL|1566.72|               10271.0|                       NULL|               35.0|        COMPACT|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        80.0|                           NULL|                       NULL|                                           NULL| Feb'23|           CALICUT|           NULL|            NULL|     No|        NULL|EM Agency| SOUTH|   KERALA|     0|       NULL|   B|      NULL|    aswinnarayananak|aswinnarayananak_...|   1085132|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|        Yes|           Increase|               0|\n",
      "|         NULL|'2011500101211001...|  SY onwards|    PrivateCarPolicy|        Package|Renewal Business|     2024-03-27|BALINA CHANDRA MI...|                           NULL|       2023-03-28|                      NULL|TS-16-EH-6671| 6.96|             NULL|     D4FCGM032589|'MALBM51RLGM217310A|            HYUNDAI|          I20|         1.4 SPORTZ|     NULL|           NIZAMABAD|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|         3720.09|           250.0|            NULL|             NULL|                NULL|    NULL|                 NULL|                   NULL|              3970.09|          7235.0|          3966.0|                         NULL|2016.18|               13217.0|                       NULL|               50.0|        COMPACT|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        45.0|                           NULL|                       NULL|                                           NULL| Mar'23|         HYDERABAD|           NULL|            NULL|     No|        NULL|  Non-OEM| SOUTH|TELANGANA|     0|       NULL|   B|      NULL| balinachandramiohan|balinachandramioh...|   1097747|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|        Yes|           Increase|               0|\n",
      "|         NULL|'2011500101217017...|  SY onwards|    PrivateCarPolicy|        Package|Renewal Business|     2024-03-30|ACE PRO INDIA PVT...|                           NULL|       2023-03-31|                      NULL|AP-09-CJ-8699|10.95|             NULL|        CLN189518| 'WVWB12608CT031069|         VOLKSWAGEN|        VENTO|1.6 DIESEL HIGHLINE|     NULL|          KHAIRTABAD|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|            NULL|            NULL|            NULL|             NULL|                NULL|    NULL|                 NULL|                   NULL|                  0.0|          1406.0|          7947.0|                         NULL|1683.54|               11037.0|                       NULL|               20.0|       MID SIZE|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        77.5|                           NULL|                       NULL|                                           NULL| Mar'23|         HYDERABAD|           NULL|            NULL|     No|        NULL|  Non-OEM| SOUTH|TELANGANA|     0|       NULL|   B|      NULL|   aceproindiapvtltd|aceproindiapvtltd...|   1010920|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|        Yes|          No Change|               0|\n",
      "|         NULL|'2011500101227012...|          FY|PrivateCarStandal...|            SOD|Renewal Business|     2024-09-20|KONDA REDDY MALAPATI|                           NULL|       2023-09-21|                      NULL|TS-08-JF-7902|  1.0|             NULL|       EUNZF19653| 'MA1NM2EU4N2F78402|MAHINDRA & MAHINDRA|      XUV 300|         1.5 W6 AMT|     NULL|          RANGAREDDY|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|         3243.13|           250.0|         1111.93|          1111.93|               249.0|   300.0|                 NULL|                   NULL|              6265.99|         10997.0|             0.0|                         NULL|1979.46|               12976.0|                       NULL|                0.0|          SUV 1|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        80.0|                           NULL|                       NULL|                                           NULL| Sep'23|         HYDERABAD|           NULL|            NULL|     No|        NULL|  Non-OEM| SOUTH|TELANGANA|     0|       NULL|   B|      NULL|  kondareddymalapati|kondareddymalapat...|   1330278|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|        Yes|           Increase|               0|\n",
      "|         NULL|'2011500101227016...|  SY onwards|    PrivateCarPolicy|        Package|Renewal Business|     2024-12-21|  CHALUMURI YERNAIDU|                           NULL|       2023-12-22|                      NULL|TS-07-FM-5868| 6.87|             NULL|        CLS538705| 'TMBBDMNA0GG018960|              SKODA|        RAPID|   1.6 MPI STYLE AT|     NULL|          RANGAREDDY|       NULL|               Yes|          NULL|       NULL|      NULL|            NULL|                  NULL|            NULL|            NULL|            NULL|             NULL|               249.0|    NULL|                 NULL|                   NULL|                249.0|          5039.0|          8322.0|                         NULL|2404.98|               15766.0|                       NULL|                0.0|       MID SIZE|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        72.5|                           NULL|                       NULL|                                           NULL| Dec'23|         HYDERABAD|           NULL|            NULL|     No|        NULL|  Non-OEM| SOUTH|TELANGANA|     -|       NULL|   B|      NULL|   chalumuriyernaidu|chalumuriyernaidu...|   1134981|         Open|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|         No|           Increase|               1|\n",
      "|         NULL|'2011500101228000...|          FY|    PrivateCarPolicy|        Package|Renewal Business|     2024-04-14|    GANTI ANURADHA .|                           NULL|       2023-04-15|                      NULL|AP-29-BM-1474|11.87|             NULL|     G4HGBM248093| 'MALAM51BLBM891139|            HYUNDAI|          I10|            1.1 ERA|     NULL|          RANGAREDDY|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|            NULL|            NULL|            NULL|             NULL|                NULL|    NULL|                 NULL|                   NULL|                  0.0|          2268.0|          3841.0|                         NULL|1099.62|                7209.0|                       NULL|                0.0|        COMPACT|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        30.0|                           NULL|                       NULL|                                           NULL| Apr'23|         HYDERABAD|           NULL|            NULL|     No|        NULL|  HYUNDAI| SOUTH|TELANGANA|     0|       NULL|   B|      NULL|       gantianuradha|gantianuradha_HYD...|   1206556|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|         No|          No Change|               0|\n",
      "|         NULL|'2025500207218500...|  SY onwards|PrivateCarStandal...|            SOD|Renewal Business|     2024-03-11|         PHANIRAJU N|                           NULL|       2023-03-12|                      NULL| KA-06-Z-9079|  2.0|             NULL|        6476171.0| 'MA3EUA61S00H28791|             MARUTI|     ALTO 800|                VXI|   Petrol|              TUMKUR|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|         1911.24|            NULL|            NULL|           546.07|                NULL|    NULL|                 NULL|                   NULL|               3139.9|          4394.0|             0.0|                         NULL| 790.92|                5185.0|                       NULL|               20.0|        COMPACT|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                      79.326|                           NULL|                       NULL|                                           NULL| Feb'23|            TUMKUR|           NULL|            NULL|     No|        NULL|   MARUTI| SOUTH|KARNATAKA|     0|       NULL|   B|      NULL|          phanirajun|   phanirajun_TUMKUR|   1506321|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|        Yes|           Increase|               0|\n",
      "|         NULL|'2011500201227002...|  SY onwards|    PrivateCarPolicy|        Package|Renewal Business|     2024-06-20|RAJEEV KUMAR ANNA...|                           NULL|       2023-06-21|                      NULL|KA-04-MT-4083| 5.92|             NULL|       13114177.0|         'EH4004233|              HONDA|          BRV|           V PETROL|     NULL|           BENGALURU|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|         5946.82|           350.0|            NULL|             NULL|               249.0|    NULL|                 NULL|                   NULL|              6545.82|          8596.0|          3841.0|                         NULL|2238.66|               14676.0|                       NULL|               50.0|          SUV 1|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        80.0|                           NULL|                       NULL|                                           NULL|June'23|         BANGALORE|           NULL|            NULL|     No|        NULL|  Non-OEM| SOUTH|KARNATAKA|     0|       NULL|   B|      NULL| rajeevkumarannaluru|rajeevkumarannalu...|   1559542|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|         No|           Increase|               0|\n",
      "|         NULL|'2011500201227011...|  SY onwards|    PrivateCarPolicy|        Package|Renewal Business|     2024-10-26|             RAMYA R|                           NULL|       2023-10-27|                      NULL|KA-05-MJ-1810|13.03|             NULL|     HR012603928A|           '8002424|             NISSAN|        MICRA|                 XL|     NULL|           BENGALURU|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|            NULL|            NULL|            NULL|             NULL|                NULL|    NULL|                 NULL|                   NULL|                  0.0|          1273.0|          3841.0|                         NULL| 920.52|                6035.0|                       NULL|               35.0|        COMPACT|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        40.0|                           NULL|                       NULL|                                           NULL| Oct'23|         BANGALORE|           NULL|            NULL|     No|        NULL|  Non-OEM| SOUTH|KARNATAKA|     0|       NULL|   B|      NULL|              ramyar|    ramyar_BANGALORE|   1589783|  Not Renewed|                 12|          1.0|      2023|    2024|                        25|2.0833333333333335|            2.0|           2022|           NULL|           No|         No|          No Change|               0|\n",
      "|         NULL|'2025500207228500...|          FY|PrivateCarStandal...|            SOD|Renewal Business|     2024-10-12|            LOKESH K|                           NULL|       2023-10-13|                      NULL| KA-13-Z-3483|  2.0|             NULL|        1083623.0| 'MBHCZCB3SMF831530|             MARUTI|        SWIFT|            1.2 VXI|   Petrol|              HASSAN|       NULL|               Yes|          NULL|       NULL|      NULL|            NULL|                  NULL|         3253.35|            NULL|            NULL|           929.53|                NULL|    NULL|                 NULL|                   NULL|              4182.88|          7957.0|             0.0|                         NULL|1432.26|                9389.0|                       NULL|                0.0|        COMPACT|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        73.9|                           NULL|                       NULL|                                           NULL| Oct'23|            TUMKUR|           NULL|            NULL|     No|        NULL|   MARUTI| SOUTH|KARNATAKA|     0|       NULL|   B|      NULL|             lokeshk|      lokeshk_TUMKUR|   1356640|  Not Renewed|                 12|          1.0|      2023|    2024|                        38|3.1666666666666665|            3.0|           2022|           NULL|           No|        Yes|           Increase|               1|\n",
      "|         NULL|'2011500202227003...|          FY|    PrivateCarPolicy|        Package|Renewal Business|     2024-12-27|   RAHUL DAULAT RANE|                           NULL|       2023-12-28|                      NULL|KA-22-MB-6535| 3.94|             NULL|        5082170.0|            '240045|             MARUTI|      WAGON R|            VXI (O)|     NULL|            BELAGAVI|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|          2394.0|           250.0|            NULL|             NULL|                NULL|    NULL|                 NULL|                   NULL|               2644.0|          5073.0|          2769.0|                         NULL|1411.56|                9254.0|                       NULL|               35.0|        COMPACT|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        57.5|                           NULL|                       NULL|                                           NULL| Dec'23|             HUBLI|           NULL|            NULL|     No|        NULL|EM Agency| SOUTH|KARNATAKA|     -|       NULL|   B|      NULL|     rahuldaulatrane|rahuldaulatrane_H...|   1552760|         Open|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|         No|           Increase|               0|\n",
      "|         NULL|'2011500208217002...|          FY|    PrivateCarPolicy|        Package|Renewal Business|     2024-01-24|             BALARAM|                           NULL|       2023-01-25|                      NULL| KA-32-P-1916| 4.91|             NULL|       WJH6M90051|  MA1XK2WJXH6M46842|MAHINDRA & MAHINDRA|       BOLERO|     POWER PLUS ZLX|     NULL|          KALABURAGI|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|            NULL|            NULL|            NULL|             NULL|                NULL|    NULL|                 NULL|                   NULL|                  0.0|          3561.0|          4191.0|                         NULL|1395.36|                9147.0|                       NULL|                0.0|          SUV 1|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        75.0|                           NULL|                       NULL|                                           NULL| Jan'23|           BELLARY|           NULL|            NULL|     No|        NULL|EM Agency| SOUTH|KARNATAKA|     0|       NULL|   B|      NULL|             balaram|     balaram_BELLARY|   1096554|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|         No|          No Change|               0|\n",
      "|         NULL|'2011500301227006...|  SY onwards|    PrivateCarPolicy|        Package|Renewal Business|     2024-07-14|         JITHU P D .|                           NULL|       2023-07-15|                      NULL|KL-04-AJ-4050| 7.22|             NULL|      F8DN5592773|          '826009AG|             MARUTI|     ALTO 800|                LXI|     NULL|           ALAPPUZHA|       NULL|                No|          NULL|       NULL|      NULL|            NULL|                  NULL|            NULL|            NULL|            NULL|             NULL|                NULL|    NULL|                 NULL|                   NULL|                  0.0|          1059.0|          2519.0|                         NULL| 644.04|                4222.0|                       NULL|               35.0|        COMPACT|            NULL|         NULL|  NULL|  NULL|                    NULL|                 NULL|                        60.0|                           NULL|                       NULL|                                           NULL|July'23|             KOCHI|           NULL|            NULL|     No|        NULL|  Non-OEM| SOUTH|   KERALA|     0|       NULL|   B|      NULL|             jithupd|       jithupd_KOCHI|   1287136|  Not Renewed|                 12|          1.0|      2023|    2024|                        24|               2.0|            2.0|           2022|           NULL|           No|         No|          No Change|               0|\n",
      "+-------------+--------------------+------------+--------------------+---------------+----------------+---------------+--------------------+-------------------------------+-----------------+--------------------------+-------------+-----+-----------------+-----------------+-------------------+-------------------+-------------+-------------------+---------+--------------------+-----------+------------------+--------------+-----------+----------+----------------+----------------------+----------------+----------------+----------------+-----------------+--------------------+--------+---------------------+-----------------------+---------------------+----------------+----------------+-----------------------------+-------+----------------------+---------------------------+-------------------+---------------+----------------+-------------+------+------+------------------------+---------------------+----------------------------+-------------------------------+---------------------------+-----------------------------------------------+-------+------------------+---------------+----------------+-------+------------+---------+------+---------+------+-----------+----+----------+--------------------+--------------------+----------+-------------+-------------------+-------------+----------+--------+--------------------------+------------------+---------------+---------------+---------------+-------------+-----------+-------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, col, year, month, dayofmonth\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CSV file directly with PySpark\n",
    "file_path = \"D:/Liberty 2024 Base/Actual_Data_South.csv\"\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CSVToSpark\").getOrCreate()\n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:735)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:270)\r\n\tat org.apache.hadoop.fs.FileUtil.chmod(FileUtil.java:1139)\r\n\tat org.apache.hadoop.fs.FileUtil.chmod(FileUtil.java:1125)\r\n\tat org.apache.spark.util.Utils$.fetchFile(Utils.scala:489)\r\n\tat org.apache.spark.SparkContext.addFile(SparkContext.scala:1790)\r\n\tat org.apache.spark.SparkContext.$anonfun$new$16(SparkContext.scala:528)\r\n\tat org.apache.spark.SparkContext.$anonfun$new$16$adapted(SparkContext.scala:528)\r\n\tat scala.collection.immutable.List.foreach(List.scala:431)\r\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:528)\r\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:238)\r\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:547)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:568)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1907)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1867)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:181)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:50)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:48)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<init>(ShutdownHookManager.scala:58)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:242)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:94)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:372)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:467)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:438)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:515)\r\n\t... 25 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLContext\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize SparkContext and SQLContext\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mApp Name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m sql \u001b[38;5;241m=\u001b[39m SQLContext(sc)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Step 2: Use Pandas to read the Excel file\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\context.py:203\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    201\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\context.py:296\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTHONHASHSEED\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTHONHASHSEED\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# Create the Java SparkContext through Py4J\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc \u001b[38;5;241m=\u001b[39m jsc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;66;03m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf \u001b[38;5;241m=\u001b[39m SparkConf(_jconf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39msc()\u001b[38;5;241m.\u001b[39mconf())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\context.py:421\u001b[0m, in \u001b[0;36mSparkContext._initialize_context\u001b[1;34m(self, jconf)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03mInitialize SparkContext in function to allow subclass specific initialization\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJavaSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjconf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\java_gateway.py:1587\u001b[0m, in \u001b[0;36mJavaClass.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1581\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCONSTRUCTOR_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1582\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1583\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1584\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1586\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1587\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fqn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1590\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1591\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:735)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:270)\r\n\tat org.apache.hadoop.fs.FileUtil.chmod(FileUtil.java:1139)\r\n\tat org.apache.hadoop.fs.FileUtil.chmod(FileUtil.java:1125)\r\n\tat org.apache.spark.util.Utils$.fetchFile(Utils.scala:489)\r\n\tat org.apache.spark.SparkContext.addFile(SparkContext.scala:1790)\r\n\tat org.apache.spark.SparkContext.$anonfun$new$16(SparkContext.scala:528)\r\n\tat org.apache.spark.SparkContext.$anonfun$new$16$adapted(SparkContext.scala:528)\r\n\tat scala.collection.immutable.List.foreach(List.scala:431)\r\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:528)\r\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:238)\r\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:750)\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:547)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:568)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1907)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1867)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:181)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:50)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:48)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<init>(ShutdownHookManager.scala:58)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:242)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:94)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:372)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:467)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:438)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:515)\r\n\t... 25 more\r\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary modules and setup Spark/SQLContext\n",
    "import pandas as pd\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# Initialize SparkContext and SQLContext\n",
    "sc = SparkContext(\"local\", \"App Name\")\n",
    "sql = SQLContext(sc)\n",
    "\n",
    "# Step 2: Use Pandas to read the Excel file\n",
    "excel_file_path = \"D:/Liberty 2024 Base/Actual_Data_South.xlsx\"  # Update with your file path\n",
    "sheet_name = \"Actual_Data_South\"  # Update with your sheet name if applicable\n",
    "df2 = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "\n",
    "# Optional: Display the Pandas DataFrame\n",
    "print(df2.head())\n",
    "\n",
    "# Step 3: Convert Pandas DataFrame to PySpark DataFrame\n",
    "spark_df = sql.createDataFrame(df2)\n",
    "\n",
    "# Show the PySpark DataFrame\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Program Files\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Selected columns\n",
    "selected_columns = ['Policy No', 'Renewal Type', 'Product name ', 'Product name  2', 'biztype', 'Policy End Date', \n",
    "                    'Policy Start Date', 'Reg no ', 'age', 'MANUFACTURER/Make', 'model', 'variant', 'Fuel Type', \n",
    "                    'RTO Location ', 'Before GST Add-on GWP', 'Total OD Premium', 'Total TP Premium', 'gst', \n",
    "                    'Total Premium Payable ', 'NCB % Previous Year', 'Vehicle Segment', 'Applicable Discount with NCB', \n",
    "                    'New Branch Name  2', 'decline', 'Tie Up', 'Zone 2', 'state2', 'Cleaned_Insured name', \n",
    "                    'CustomerID', 'Policy Status', 'Policy Tenure', 'Customer Tenure', 'New Customers', \n",
    "                    'Renewal Rate Status', 'Claim in last year', 'Number of Claims']\n",
    "\n",
    "data = data.select(*selected_columns)\n",
    "\n",
    "# Remove rows where 'Policy Status' contains 'Open'\n",
    "data = data.filter(data[\"Policy Status\"].isin([\"Renewed\", \"Not Renewed\"]))\n",
    "\n",
    "# Convert 'Policy Status' to binary\n",
    "data = data.withColumn(\"Policy Status\", F.when(F.col(\"Policy Status\") == \"Not Renewed\", 1).otherwise(0))\n",
    "\n",
    "# Handle missing values\n",
    "data = data.fillna(\"missing\", subset=[col for col in data.columns if data.schema[col].dataType == StringType()])\n",
    "data = data.fillna(0, subset=[col for col in data.columns if data.schema[col].dataType != StringType()])\n",
    "\n",
    "# Extract year, month, and day from date columns\n",
    "data = data.withColumn(\"Policy Start Date_YEAR\", F.year(F.col(\"Policy Start Date\"))) \\\n",
    "           .withColumn(\"Policy Start Date_MONTH\", F.month(F.col(\"Policy Start Date\"))) \\\n",
    "           .withColumn(\"Policy Start Date_DAY\", F.dayofmonth(F.col(\"Policy Start Date\"))) \\\n",
    "           .withColumn(\"Policy End Date_YEAR\", F.year(F.col(\"Policy End Date\"))) \\\n",
    "           .withColumn(\"Policy End Date_MONTH\", F.month(F.col(\"Policy End Date\"))) \\\n",
    "           .withColumn(\"Policy End Date_DAY\", F.dayofmonth(F.col(\"Policy End Date\")))\n",
    "\n",
    "# Drop original date columns\n",
    "data = data.drop(\"Policy Start Date\", \"Policy End Date\")\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = [col for col in data.columns if data.schema[col].dataType == StringType()]\n",
    "numerical_cols = [col for col in data.columns if col not in categorical_cols and col != \"Policy Status\"]\n",
    "\n",
    "# StringIndexers for categorical columns\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\") for col in categorical_cols]\n",
    "\n",
    "# Assemble features into a single vector\n",
    "feature_cols = [f\"{col}_index\" for col in categorical_cols] + numerical_cols\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# Build a pipeline for transformations\n",
    "pipeline = Pipeline(stages=indexers + [assembler])\n",
    "\n",
    "# Transform the data\n",
    "data = pipeline.fit(data).transform(data).select(\"features\", \"Policy Status\")\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Decision Tree model\n",
    "dt = DecisionTreeClassifier(labelCol=\"Policy Status\", featuresCol=\"features\", maxDepth=5)\n",
    "model = dt.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions_test = model.transform(test_data)\n",
    "predictions_train = model.transform(train_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Policy Status\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "roc_auc_test = evaluator.evaluate(predictions_test)\n",
    "roc_auc_train = evaluator.evaluate(predictions_train)\n",
    "print(f\"Test ROC AUC: {roc_auc_test}\")\n",
    "print(f\"Train ROC AUC: {roc_auc_train}\")\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_test = predictions_test.filter(predictions_test[\"Policy Status\"] == predictions_test[\"prediction\"]).count() / predictions_test.count()\n",
    "accuracy_train = predictions_train.filter(predictions_train[\"Policy Status\"] == predictions_train[\"prediction\"]).count() / predictions_train.count()\n",
    "print(f\"Test Accuracy: {accuracy_test}\")\n",
    "print(f\"Train Accuracy: {accuracy_train}\")\n",
    "\n",
    "# Evaluate class-specific accuracy\n",
    "def compute_class_accuracy(predictions, label):\n",
    "    class_predictions = predictions.filter(predictions[\"Policy Status\"] == label)\n",
    "    correct_predictions = class_predictions.filter(class_predictions[\"Policy Status\"] == class_predictions[\"prediction\"]).count()\n",
    "    return correct_predictions / class_predictions.count() if class_predictions.count() > 0 else 0\n",
    "\n",
    "class_0_test_accuracy = compute_class_accuracy(predictions_test, 0)\n",
    "class_1_test_accuracy = compute_class_accuracy(predictions_test, 1)\n",
    "class_0_train_accuracy = compute_class_accuracy(predictions_train, 0)\n",
    "class_1_train_accuracy = compute_class_accuracy(predictions_train, 1)\n",
    "\n",
    "print(f\"Class 0 Test Accuracy: {class_0_test_accuracy}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_test_accuracy}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_train_accuracy}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_train_accuracy}\")\n",
    "\n",
    "# Generate classification reports\n",
    "def classification_report_spark(predictions):\n",
    "    from pyspark.sql.functions import expr\n",
    "\n",
    "    tp = predictions.filter((predictions[\"Policy Status\"] == 1) & (predictions[\"prediction\"] == 1)).count()\n",
    "    tn = predictions.filter((predictions[\"Policy Status\"] == 0) & (predictions[\"prediction\"] == 0)).count()\n",
    "    fp = predictions.filter((predictions[\"Policy Status\"] == 0) & (predictions[\"prediction\"] == 1)).count()\n",
    "    fn = predictions.filter((predictions[\"Policy Status\"] == 1) & (predictions[\"prediction\"] == 0)).count()\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1_score,\n",
    "        \"Support\": tp + fn\n",
    "    }\n",
    "\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report_spark(predictions_test))\n",
    "\n",
    "print(\"Train Classification Report:\")\n",
    "print(classification_report_spark(predictions_train))\n",
    "\n",
    "# Plot ROC curve\n",
    "roc_curve_data = predictions_test.select(\"Policy Status\", \"probability\").rdd.map(lambda row: (float(row[1][1]), float(row[0])))\n",
    "roc_curve_data = roc_curve_data.toDF([\"score\", \"label\"])\n",
    "\n",
    "# Sort by score\n",
    "roc_curve_data = roc_curve_data.orderBy(\"score\", ascending=False).toPandas()\n",
    "\n",
    "# Calculate TPR and FPR\n",
    "fpr, tpr, thresholds = roc_curve(roc_curve_data[\"label\"], roc_curve_data[\"score\"])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc_test:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\errors\\exceptions\\captured.py\", line 179, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <exception str() failed>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"c:\\Program Files\\Python39\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "py4j does not exist in the JVM",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(10061, 'No connection could be made because the target machine actively refused it', None, 10061, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Train the Decision Tree model\u001b[39;00m\n\u001b[0;32m     26\u001b[0m dt \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(labelCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolicy Status\u001b[39m\u001b[38;5;124m\"\u001b[39m, featuresCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m, maxDepth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     30\u001b[0m predictions_test \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(test_data)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\ml\\base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[0;32m    210\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\ml\\wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[1;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\ml\\wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\errors\\exceptions\\captured.py:181\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 181\u001b[0m     converted \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\errors\\exceptions\\captured.py:134\u001b[0m, in \u001b[0;36mconvert_exception\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_instance_of(gw, e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark.sql.AnalysisException\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AnalysisException(origin\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mis_instance_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morg.apache.spark.sql.streaming.StreamingQueryException\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StreamingQueryException(origin\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_instance_of(gw, e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark.sql.execution.QueryExecutionException\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\java_gateway.py:464\u001b[0m, in \u001b[0;36mis_instance_of\u001b[1;34m(gateway, java_object, java_class)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjava_class must be a string, a JavaClass, or a JavaObject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgateway\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpy4j\u001b[49m\u001b[38;5;241m.\u001b[39mreflection\u001b[38;5;241m.\u001b[39mTypeUtil\u001b[38;5;241m.\u001b[39misInstanceOf(\n\u001b[0;32m    465\u001b[0m     param, java_object)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\java_gateway.py:1725\u001b[0m, in \u001b[0;36mJVMView.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1722\u001b[0m _, error_message \u001b[38;5;241m=\u001b[39m get_error_message(answer)\n\u001b[0;32m   1723\u001b[0m message \u001b[38;5;241m=\u001b[39m compute_exception_message(\n\u001b[0;32m   1724\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m does not exist in the JVM\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name), error_message)\n\u001b[1;32m-> 1725\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(message)\n",
      "\u001b[1;31mPy4JError\u001b[0m: py4j does not exist in the JVM"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Start SparkSession with memory configuration\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DecisionTreeClassifier\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Prepare data as before\n",
    "# (Load data, handle missing values, encode categorical features, etc.)\n",
    "\n",
    "# Repartition data to manage memory usage\n",
    "train_data = train_data.repartition(200)\n",
    "test_data = test_data.repartition(200)\n",
    "\n",
    "# Train the Decision Tree model\n",
    "dt = DecisionTreeClassifier(labelCol=\"Policy Status\", featuresCol=\"features\", maxDepth=5)\n",
    "model = dt.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions_test = model.transform(test_data)\n",
    "predictions_train = model.transform(train_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Policy Status\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "roc_auc_test = evaluator.evaluate(predictions_test)\n",
    "roc_auc_train = evaluator.evaluate(predictions_train)\n",
    "print(f\"Test ROC AUC: {roc_auc_test}\")\n",
    "print(f\"Train ROC AUC: {roc_auc_train}\")\n",
    "\n",
    "# Accuracy metrics as before\n",
    "accuracy_test = predictions_test.filter(predictions_test[\"Policy Status\"] == predictions_test[\"prediction\"]).count() / predictions_test.count()\n",
    "accuracy_train = predictions_train.filter(predictions_train[\"Policy Status\"] == predictions_train[\"prediction\"]).count() / predictions_train.count()\n",
    "print(f\"Test Accuracy: {accuracy_test}\")\n",
    "print(f\"Train Accuracy: {accuracy_train}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report_spark(predictions_test))\n",
    "\n",
    "print(\"Train Classification Report:\")\n",
    "print(classification_report_spark(predictions_train))\n",
    "\n",
    "# Plot ROC curve (convert Spark predictions to Pandas for plotting)\n",
    "roc_curve_data = predictions_test.select(\"Policy Status\", \"probability\").rdd.map(lambda row: (float(row[1][1]), float(row[0]))).toDF([\"score\", \"label\"]).toPandas()\n",
    "fpr, tpr, thresholds = roc_curve(roc_curve_data[\"label\"], roc_curve_data[\"score\"])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc_test:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySparkTest\") \\\n",
    "    .config(\"spark.master\", \"local[1]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = [(1, \"Alice\"), (2, \"Bob\"), (3, \"Charlie\")]\n",
    "df = spark.createDataFrame(data, [\"ID\", \"Name\"])\n",
    "df.show()\n",
    "\n",
    "# Stop SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "os.environ[\"JAVA_HOME\"] = \"C:/Program Files/Java/jdk1.8.0_341\"\n",
    "os.environ[\"SPARK_HOME\"] = \"C:/Spark/spark-3.5.3-bin-hadoop3\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"C:/Program Files/Python39/python.exe\"\n",
    "\n",
    "# Initialize Findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark Test\") \\\n",
    "    .config(\"spark.master\", \"local[1]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample DataFrame\n",
    "data = [(1, \"Alice\"), (2, \"Bob\"), (3, \"Charlie\")]\n",
    "df = spark.createDataFrame(data, [\"ID\", \"Name\"])\n",
    "df.show()\n",
    "\n",
    "# Stop Spark Session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
