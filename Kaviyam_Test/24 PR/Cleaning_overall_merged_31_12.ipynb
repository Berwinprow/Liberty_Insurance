{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Step 1: Load data\n",
    "query = \"SELECT * FROM overall_merged_data_31_12;\"\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Convert dates to datetime\n",
    "df['Policy Start Date'] = pd.to_datetime(df['Policy Start Date'], errors='coerce')\n",
    "df['Policy End Date'] = pd.to_datetime(df['Policy End Date'], errors='coerce')\n",
    "\n",
    "# Step 2: Remove invalid rows in 'Total Premium Payable'\n",
    "df = df[~df['Total Premium Payable '].isnull()]  # Remove null values\n",
    "df = df[~df['Total Premium Payable '].astype(str).str.isalpha()]  # Remove categorical values\n",
    "df = df[df['Total Premium Payable '] != 0]  # Remove rows with 0\n",
    "\n",
    "# Step 3: Handle NULL values in BOOKED column\n",
    "today = pd.Timestamp(datetime.now().date())  # Current date\n",
    "\n",
    "def update_booked(row):\n",
    "    if pd.isnull(row['booked']):\n",
    "        if row['Type'] == 'C':\n",
    "            if pd.notnull(row['Policy End Date']):\n",
    "                return 1 if row['Policy End Date'] <= today else '-'\n",
    "        elif row['Type'] in ['A', 'B']:\n",
    "            if pd.notnull(row['Policy End Date']):\n",
    "                return 0 if row['Policy End Date'] <= today else '-'\n",
    "    return row['booked']\n",
    "\n",
    "df['booked'] = df.apply(update_booked, axis=1)\n",
    "\n",
    "# Step 4: Deduplication and prioritization\n",
    "duplicates = df[df.duplicated(subset=['Policy No', 'Policy Start Date', 'Policy End Date'], keep=False)]\n",
    "\n",
    "def prioritize_rows(group):\n",
    "    group = group.assign(null_count=group.isnull().sum(axis=1))\n",
    "    group = group.sort_values(by=['null_count', 'booked'], ascending=[True, False])\n",
    "    return group.iloc[0]\n",
    "\n",
    "cleaned_duplicates = (\n",
    "    duplicates.groupby(['Policy No', 'Policy Start Date', 'Policy End Date'])\n",
    "    .apply(prioritize_rows)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_cleaned = pd.concat([df, cleaned_duplicates]).drop_duplicates(subset=['Policy No', 'Policy Start Date', 'Policy End Date'], keep='last')\n",
    "\n",
    "# Step 5: Correct BOOKED values based on Type\n",
    "correction_count = 0\n",
    "\n",
    "def correct_booked(group):\n",
    "    global correction_count\n",
    "    type_a = group[group['Type'] == 'A']\n",
    "    type_b = group[group['Type'] == 'B']\n",
    "    \n",
    "    # Check if both Type A and Type B exist for the same Policy No\n",
    "    if not type_a.empty and not type_b.empty:\n",
    "        # Check if BOOKED is 0 for Type A\n",
    "        if type_a.iloc[0]['booked'] == 0:\n",
    "            correction_count += 1\n",
    "            # Update BOOKED to 1 for Type A\n",
    "            group.loc[group['Type'] == 'A', 'booked'] = 1\n",
    "    return group\n",
    "\n",
    "type_a_b = df_cleaned[df_cleaned['Type'].isin(['A', 'B'])]\n",
    "type_a_b_grouped = type_a_b.groupby('Policy No')\n",
    "\n",
    "df_cleaned = type_a_b_grouped.apply(correct_booked).reset_index(drop=True)\n",
    "\n",
    "# Output the number of corrections made\n",
    "print(f\"Number of corrections made: {correction_count}\")\n",
    "\n",
    "# Save the cleaned dataset back to the database\n",
    "df_cleaned.to_sql('cleaned_overall_merged_data_31_12', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Step 1: Load data\n",
    "query = \"SELECT * FROM overall_merged_data_31_12;\"\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Convert dates to datetime\n",
    "df['Policy Start Date'] = pd.to_datetime(df['Policy Start Date'], errors='coerce')\n",
    "df['Policy End Date'] = pd.to_datetime(df['Policy End Date'], errors='coerce')\n",
    "\n",
    "# Step 2: Remove invalid rows in 'Total Premium Payable'\n",
    "df = df[~df['Total Premium Payable '].isnull()]  # Remove null values\n",
    "df = df[~df['Total Premium Payable '].astype(str).str.isalpha()]  # Remove categorical values\n",
    "df = df[df['Total Premium Payable '] != 0]  # Remove rows with 0\n",
    "\n",
    "# Ensure the 'booked' column is explicitly cast to a string type\n",
    "if 'booked' not in df.columns or df['booked'].isnull().all():\n",
    "    df['booked'] = None  # If the column doesn't exist or is completely null, initialize it\n",
    "df['booked'] = df['booked'].astype('str')  # Convert to string to handle assignments of '0', '1', '-'\n",
    "\n",
    "today = pd.Timestamp.now().normalize()\n",
    "\n",
    "def update_booked(group):\n",
    "    # Sort policies by start date within the group\n",
    "    group = group.sort_values(by='Policy Start Date')\n",
    "    \n",
    "    for i in range(len(group) - 1):\n",
    "        current_policy = group.iloc[i]\n",
    "        next_policy = group.iloc[i + 1]\n",
    "        \n",
    "        # Only process rows where booked is NULL or 'None'\n",
    "        if pd.isnull(current_policy['booked']) or current_policy['booked'] == 'None':\n",
    "            # Check if the next policy starts the day after the current one ends\n",
    "            if next_policy['Policy Start Date'] == current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                if next_policy['Policy Start Date'] > today:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "                else:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "            elif next_policy['Policy Start Date'] > current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                group.loc[current_policy.name, 'booked'] = '1'\n",
    "    \n",
    "    # Handle the last policy for the customer\n",
    "    last_policy = group.iloc[-1]\n",
    "    if pd.isnull(last_policy['booked']) or last_policy['booked'] == 'None':\n",
    "        if last_policy['Policy End Date'] >= today:\n",
    "            group.loc[last_policy.name, 'booked'] = '-'\n",
    "        else:\n",
    "            group.loc[last_policy.name, 'booked'] = '0'\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the function to each group of policies\n",
    "df = df.groupby('Policy No').apply(update_booked).reset_index(drop=True)\n",
    "\n",
    "# Step 4: Handle duplicates and prioritize\n",
    "duplicates = df[df.duplicated(subset=['Policy No', 'Policy Start Date', 'Policy End Date'], keep=False)]\n",
    "\n",
    "def prioritize_rows(group):\n",
    "    group = group.assign(null_count=group.isnull().sum(axis=1))\n",
    "    group = group.sort_values(by=['null_count', 'booked'], ascending=[True, False])\n",
    "    return group.iloc[0]\n",
    "\n",
    "cleaned_duplicates = (\n",
    "    duplicates.groupby(['Policy No', 'Policy Start Date', 'Policy End Date'])\n",
    "    .apply(prioritize_rows)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_cleaned = pd.concat([df, cleaned_duplicates]).drop_duplicates(subset=['Policy No', 'Policy Start Date', 'Policy End Date'], keep='last')\n",
    "\n",
    "def correct_booked(group):\n",
    "    group = group.sort_values(by='Policy Start Date')\n",
    "    for i in range(len(group) - 1):\n",
    "        current_policy = group.iloc[i]\n",
    "        next_policy = group.iloc[i + 1]\n",
    "        \n",
    "        # Check if the current policy is marked as '0' but satisfies the condition\n",
    "        if current_policy['booked'] == '0':\n",
    "            # Check if the next policy starts the day after the current one ends\n",
    "            if next_policy['Policy Start Date'] == current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                if next_policy['Policy Start Date'] > today:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "                else:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "            # Check if the next policy starts after a gap\n",
    "            elif next_policy['Policy Start Date'] > current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                if next_policy['Policy Start Date'] > today:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the correction to each group of policies\n",
    "df_cleaned = df_cleaned.groupby('Policy No').apply(correct_booked).reset_index(drop=True)\n",
    "\n",
    "# Save the cleaned dataset back to the database\n",
    "df_cleaned.to_sql('cleaned_overall_merged_base_pr_data', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Step 1: Load data\n",
    "query = \"SELECT * FROM overall_merged_data_31_12;\"\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Convert dates to datetime\n",
    "df['Policy Start Date'] = pd.to_datetime(df['Policy Start Date'], errors='coerce')\n",
    "df['Policy End Date'] = pd.to_datetime(df['Policy End Date'], errors='coerce')\n",
    "\n",
    "# Step 2: Remove invalid rows in 'Total Premium Payable'\n",
    "df = df[~df['Total Premium Payable '].isnull()]  # Remove null values\n",
    "df = df[~df['Total Premium Payable '].astype(str).str.isalpha()]  # Remove categorical values\n",
    "df = df[df['Total Premium Payable '] != 0]  # Remove rows with 0\n",
    "\n",
    "# Ensure the 'booked' column is explicitly cast to a string type\n",
    "if 'booked' not in df.columns or df['booked'].isnull().all():\n",
    "    df['booked'] = None  # If the column doesn't exist or is completely null, initialize it\n",
    "df['booked'] = df['booked'].astype('str')  # Convert to string to handle assignments of '0', '1', '-'\n",
    "\n",
    "today = pd.Timestamp.now().normalize()\n",
    "\n",
    "def update_booked(group):\n",
    "    # Sort policies by start date within the group\n",
    "    group = group.sort_values(by='Policy Start Date')\n",
    "    \n",
    "    for i in range(len(group) - 1):\n",
    "        current_policy = group.iloc[i]\n",
    "        next_policy = group.iloc[i + 1]\n",
    "        \n",
    "        # Only process rows where booked is NULL or 'None'\n",
    "        if pd.isnull(current_policy['booked']) or current_policy['booked'] == 'None':\n",
    "            # Check if the next policy starts the day after the current one ends\n",
    "            if next_policy['Policy Start Date'] == current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                if next_policy['Policy Start Date'] > today:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "                else:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "            elif next_policy['Policy Start Date'] > current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                group.loc[current_policy.name, 'booked'] = '1'\n",
    "    \n",
    "    # Handle the last policy for the customer\n",
    "    last_policy = group.iloc[-1]\n",
    "    if pd.isnull(last_policy['booked']) or last_policy['booked'] == 'None':\n",
    "        if last_policy['Policy End Date'] >= today:\n",
    "            group.loc[last_policy.name, 'booked'] = '-'\n",
    "        else:\n",
    "            group.loc[last_policy.name, 'booked'] = '0'\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Initialize an empty list to store processed groups\n",
    "processed_groups = []\n",
    "\n",
    "# Group by 'Policy No' and process each group manually\n",
    "for policy_no, group in df.groupby('Policy No'):\n",
    "    processed_group = update_booked(group)\n",
    "    processed_groups.append(processed_group)\n",
    "\n",
    "# Combine all processed groups back into a single DataFrame\n",
    "df = pd.concat(processed_groups).reset_index(drop=True)\n",
    "\n",
    "# Step 4: Handle duplicates and prioritize\n",
    "duplicates = df[df.duplicated(subset=['Policy No', 'Policy Start Date', 'Policy End Date'], keep=False)]\n",
    "\n",
    "def prioritize_rows(group):\n",
    "    group = group.assign(null_count=group.isnull().sum(axis=1))\n",
    "    group = group.sort_values(by=['null_count', 'booked'], ascending=[True, False])\n",
    "    return group.iloc[0]\n",
    "\n",
    "cleaned_duplicates = (\n",
    "    duplicates.groupby(['Policy No', 'Policy Start Date', 'Policy End Date'])\n",
    "    .apply(prioritize_rows)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_cleaned = pd.concat([df, cleaned_duplicates]).drop_duplicates(subset=['Policy No', 'Policy Start Date', 'Policy End Date'], keep='last')\n",
    "\n",
    "def correct_booked(group):\n",
    "    group = group.sort_values(by='Policy Start Date')\n",
    "    for i in range(len(group) - 1):\n",
    "        current_policy = group.iloc[i]\n",
    "        next_policy = group.iloc[i + 1]\n",
    "        \n",
    "        # Check if the current policy is marked as '0' but satisfies the condition\n",
    "        if current_policy['booked'] == '0':\n",
    "            # Check if the next policy starts the day after the current one ends\n",
    "            if next_policy['Policy Start Date'] == current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                if next_policy['Policy Start Date'] > today:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "                else:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "            # Check if the next policy starts after a gap\n",
    "            elif next_policy['Policy Start Date'] > current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                if next_policy['Policy Start Date'] > today:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the correction to each group of policies\n",
    "df_cleaned = df_cleaned.groupby('Policy No').apply(correct_booked).reset_index(drop=True)\n",
    "\n",
    "# Save the cleaned dataset back to the database\n",
    "df_cleaned.to_sql('cleaned_overall_merged_base_pr_data', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
