{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': '10.10.10.71',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Step 1: Load data\n",
    "query = \"SELECT * FROM backup_overall_merged_data_31_12;\"\n",
    "df = pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to datetime\n",
    "df['Policy Start Date'] = pd.to_datetime(df['Policy Start Date'], errors='coerce')\n",
    "df['Policy End Date'] = pd.to_datetime(df['Policy End Date'], errors='coerce')\n",
    "\n",
    "# Step 2: Remove invalid rows in 'Total Premium Payable'\n",
    "df = df[~df['Total Premium Payable '].isnull()]  # Remove null values\n",
    "df = df[~df['Total Premium Payable '].astype(str).str.isalpha()]  # Remove categorical values\n",
    "df = df[df['Total Premium Payable '] != 0]  # Remove rows with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'booked' column is explicitly cast to a string type\n",
    "if 'booked' not in df.columns or df['booked'].isnull().all():\n",
    "    df['booked'] = None  # If the column doesn't exist or is completely null, initialize it\n",
    "df['booked'] = df['booked'].astype('str')  # Convert to string to handle assignments of '0', '1', '-'\n",
    "\n",
    "today = pd.Timestamp.now().normalize()\n",
    "\n",
    "def update_booked(group):\n",
    "    # Sort policies by start date within the group\n",
    "    group = group.sort_values(by='Policy Start Date')\n",
    "    \n",
    "    for i in range(len(group) - 1):\n",
    "        current_policy = group.iloc[i]\n",
    "        next_policy = group.iloc[i + 1]\n",
    "        \n",
    "        # Only process rows where booked is NULL or 'None'\n",
    "        if pd.isnull(current_policy['booked']) or current_policy['booked'] == 'None':\n",
    "            # Check if the next policy starts the day after the current one ends\n",
    "            if next_policy['Policy Start Date'] == current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                if next_policy['Policy Start Date'] > today:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "                else:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "            elif next_policy['Policy Start Date'] > current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                group.loc[current_policy.name, 'booked'] = '1'\n",
    "    \n",
    "    # Handle the last policy for the customer\n",
    "    last_policy = group.iloc[-1]\n",
    "    if pd.isnull(last_policy['booked']) or last_policy['booked'] == 'None':\n",
    "        if last_policy['Policy End Date'] >= today:\n",
    "            group.loc[last_policy.name, 'booked'] = '-'\n",
    "        else:\n",
    "            group.loc[last_policy.name, 'booked'] = '0'\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the function to each group of policies\n",
    "df = df.groupby('Policy No').apply(update_booked).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Handle duplicates and prioritize\n",
    "duplicates = df[df.duplicated(subset=['Policy No', 'Policy Start Date', 'Policy End Date'], keep=False)]\n",
    "\n",
    "def prioritize_rows(group):\n",
    "    group = group.assign(null_count=group.isnull().sum(axis=1))\n",
    "    group = group.sort_values(by=['null_count', 'booked'], ascending=[True, False])\n",
    "    return group.iloc[0]\n",
    "\n",
    "cleaned_duplicates = (\n",
    "    duplicates.groupby(['Policy No', 'Policy Start Date', 'Policy End Date'])\n",
    "    .apply(prioritize_rows)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_cleaned = pd.concat([df, cleaned_duplicates]).drop_duplicates(subset=['Policy No', 'Policy Start Date', 'Policy End Date'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_booked(group):\n",
    "    group = group.sort_values(by='Policy Start Date')\n",
    "    for i in range(len(group) - 1):\n",
    "        current_policy = group.iloc[i]\n",
    "        next_policy = group.iloc[i + 1]\n",
    "        \n",
    "        # Check if the current policy is marked as '0' but satisfies the condition\n",
    "        if current_policy['booked'] == '0':\n",
    "            # Check if the next policy starts the day after the current one ends\n",
    "            if next_policy['Policy Start Date'] == current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                if next_policy['Policy Start Date'] > today:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "                else:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "            # Check if the next policy starts after a gap\n",
    "            elif next_policy['Policy Start Date'] > current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                if next_policy['Policy Start Date'] > today:\n",
    "                    group.loc[current_policy.name, 'booked'] = '1'\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the correction to each group of policies\n",
    "df_cleaned = df_cleaned.groupby('Policy No').apply(correct_booked).reset_index(drop=True)\n",
    "\n",
    "# Save the cleaned dataset back to the database\n",
    "df_cleaned.to_sql('cleaned_overall_merged_base_pr_data', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10204\\254601383.py:63: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('Policy No').apply(update_booked).reset_index(drop=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10204\\254601383.py:74: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(prioritize_rows)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10204\\254601383.py:97: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_cleaned = df_cleaned.groupby('Policy No').apply(correct_booked).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': '10.10.10.71',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Step 1: Load data\n",
    "query = \"SELECT * FROM backup_overall_merged_data_31_12;\"\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Convert dates to datetime\n",
    "df['Policy Start Date'] = pd.to_datetime(df['Policy Start Date'], errors='coerce')\n",
    "df['Policy End Date'] = pd.to_datetime(df['Policy End Date'], errors='coerce')\n",
    "\n",
    "# Step 2: Remove invalid rows in 'Total Premium Payable'\n",
    "df['Total Premium Payable '] = pd.to_numeric(df['Total Premium Payable '].astype(str).str.strip(), errors='coerce')\n",
    "df = df[df['Total Premium Payable '].notnull() & (df['Total Premium Payable '] != 0)]\n",
    "\n",
    "# Initialize 'booked' column\n",
    "if 'booked' not in df.columns:\n",
    "    df['booked'] = None\n",
    "df['booked'] = df['booked'].fillna('').astype(str)\n",
    "\n",
    "today = pd.Timestamp.now().normalize()\n",
    "\n",
    "def update_booked(group):\n",
    "    # Sort policies by start date within the group\n",
    "    group = group.sort_values(by='Policy Start Date')\n",
    "\n",
    "    for i in range(len(group) - 1):\n",
    "        current_policy = group.iloc[i]\n",
    "        next_policy = group.iloc[i + 1]\n",
    "\n",
    "        # Only process rows where booked is empty\n",
    "        if current_policy['booked'] in ['', 'None']:\n",
    "            # Check if the next policy starts the day after the current one ends\n",
    "            if next_policy['Policy Start Date'] == current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                group.loc[current_policy.name, 'booked'] = '1'\n",
    "            elif next_policy['Policy Start Date'] > current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                group.loc[current_policy.name, 'booked'] = '1'\n",
    "\n",
    "    # Handle the last policy for the customer\n",
    "    last_policy = group.iloc[-1]\n",
    "    if last_policy['booked'] in ['', 'None']:\n",
    "        if last_policy['Policy End Date'] >= today:\n",
    "            group.loc[last_policy.name, 'booked'] = '-'\n",
    "        else:\n",
    "            group.loc[last_policy.name, 'booked'] = '0'\n",
    "\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group of policies\n",
    "df = df.groupby('Policy No').apply(update_booked).reset_index(drop=True)\n",
    "\n",
    "# Step 4: Handle duplicates and prioritize\n",
    "def prioritize_rows(group):\n",
    "    group = group.assign(null_count=group.isnull().sum(axis=1))\n",
    "    group = group.sort_values(by=['null_count', 'booked', 'Policy Start Date'], ascending=[True, False, True])\n",
    "    return group.iloc[0]\n",
    "\n",
    "duplicates = df[df.duplicated(subset=['Policy No', 'Policy Start Date', 'Policy End Date'], keep=False)]\n",
    "cleaned_duplicates = (\n",
    "    duplicates.groupby(['Policy No', 'Policy Start Date', 'Policy End Date'])\n",
    "    .apply(prioritize_rows)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_cleaned = df.drop_duplicates(subset=['Policy No', 'Policy Start Date', 'Policy End Date'], keep=False)\n",
    "df_cleaned = pd.concat([df_cleaned, cleaned_duplicates], ignore_index=True)\n",
    "\n",
    "def correct_booked(group):\n",
    "    group = group.sort_values(by='Policy Start Date')\n",
    "    for i in range(len(group) - 1):\n",
    "        current_policy = group.iloc[i]\n",
    "        next_policy = group.iloc[i + 1]\n",
    "\n",
    "        # Check if the current policy is marked as '0' but satisfies the condition\n",
    "        if current_policy['booked'] == '0':\n",
    "            if next_policy['Policy Start Date'] == current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                group.loc[current_policy.name, 'booked'] = '1'\n",
    "            elif next_policy['Policy Start Date'] > current_policy['Policy End Date'] + timedelta(days=1):\n",
    "                group.loc[current_policy.name, 'booked'] = '1'\n",
    "\n",
    "    return group\n",
    "\n",
    "# Apply the correction to each group of policies\n",
    "df_cleaned = df_cleaned.groupby('Policy No').apply(correct_booked).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1498"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.to_sql(\n",
    "    'cleaned_overall_merged_base_pr_data',\n",
    "    con=engine,\n",
    "    if_exists='replace',\n",
    "    index=False,\n",
    "    chunksize=100000  # Adjust chunk size based on performance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset back to the database\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"DROP TABLE IF EXISTS cleaned_overall_merged_base_pr_data;\"))\n",
    "    df_cleaned.to_sql('cleaned_overall_merged_base_pr_data', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
