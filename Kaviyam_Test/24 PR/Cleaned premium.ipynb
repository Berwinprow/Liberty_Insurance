{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Step 1: Load data from PostgreSQL\n",
    "query = \"SELECT * FROM cleaned_test_data_06_12;\"\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Step 2: Create a `Match` column for all rows in the dataset\n",
    "policy_no_with_b = df[df['Type'] == 'B']['Policy No'].unique()\n",
    "df['Match'] = df['Policy No'].isin(policy_no_with_b).apply(lambda x: 'Matches B' if x else None)\n",
    "\n",
    "# Step 3: Clean column names\n",
    "df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "# Step 4: Separate Numeric and Non-Numeric Rows in `Total Premium Payable`\n",
    "# Fill nulls with empty strings for processing\n",
    "df['Total Premium Payable'] = df['Total Premium Payable'].fillna('').astype(str)\n",
    "\n",
    "# Identify non-numeric rows\n",
    "non_numeric_mask = ~df['Total Premium Payable'].str.replace('.', '', 1).str.isdigit()\n",
    "\n",
    "# Create separate DataFrames for numeric and non-numeric rows\n",
    "non_numeric_df = df[non_numeric_mask]\n",
    "numeric_df = df[~non_numeric_mask]\n",
    "\n",
    "# Step 5: Save Numeric and Non-Numeric Data Separately\n",
    "numeric_df.to_sql('cleanedprem_test_data_06_12', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "non_numeric_df.to_csv('non_numeric_total_premium_with_match.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating DataFrame\n",
    "df = pd.read_csv('non_numeric_total_premium_with_match.csv')\n",
    "\n",
    "# Step 1: Remove rows where all three (Total OD Premium, Total TP Premium, gst) are zero or null\n",
    "df = df[~((df[\"Total OD Premium\"].fillna(0) == 0) &\n",
    "          (df[\"Total TP Premium\"].fillna(0) == 0) &\n",
    "          (df[\"gst\"].fillna(0) == 0))]\n",
    "\n",
    "# Step 2: Calculate gst if it is zero and round the value\n",
    "df[\"gst\"] = df[\"gst\"].fillna(0)  \n",
    "df.loc[df[\"gst\"] == 0, \"gst\"] = ((df[\"Total OD Premium\"].fillna(0) + df[\"Total TP Premium\"].fillna(0)) * 0.18).round()\n",
    "\n",
    "# Step 3: Calculate Total Premium Payable as the sum of Total OD Premium, Total TP Premium, and gst\n",
    "df[\"Total Premium Payable\"] = (\n",
    "    df[\"Total OD Premium\"].fillna(0) + df[\"Total TP Premium\"].fillna(0) + df[\"gst\"]\n",
    ").round()\n",
    "\n",
    "df.to_csv('cleaned_non_numeric_total_premium.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Step 1: Load data from PostgreSQL (existing table)\n",
    "existing_data_query = \"SELECT * FROM cleanedprem_test_data_06_12;\"\n",
    "existing_data = pd.read_sql(existing_data_query, con=engine)\n",
    "\n",
    "# Step 2: Load cleaned data from CSV\n",
    "cleaned_data = pd.read_csv('cleaned_non_numeric_total_premium.csv')\n",
    "\n",
    "# Step 3: Ensure columns match\n",
    "# Add missing columns to cleaned_data\n",
    "for column in existing_data.columns:\n",
    "    if column not in cleaned_data.columns:\n",
    "        cleaned_data[column] = None\n",
    "\n",
    "# Align column order to match the existing table\n",
    "cleaned_data = cleaned_data[existing_data.columns]\n",
    "\n",
    "# Step 4: Append the cleaned data to the existing table\n",
    "merged_data = pd.concat([existing_data, cleaned_data], ignore_index=True)\n",
    "\n",
    "# Step 5: Save the merged data back to PostgreSQL\n",
    "merged_data.to_sql('overall_cleaned_policy_level_data', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Step 1: Load data from PostgreSQL\n",
    "query = \"SELECT * FROM overall_cleaned_policy_level_data;\"\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Step 2: Ensure relevant columns are numeric\n",
    "numeric_columns = [\"Total OD Premium\", \"Total TP Premium\", \"gst\", \"Total Premium Payable\"]\n",
    "for col in numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert to numeric, set errors to NaN\n",
    "\n",
    "# Step 3: Remove rows where all specified columns are zero or null\n",
    "df = df[~((df[\"Total OD Premium\"].fillna(0) == 0) &\n",
    "          (df[\"Total TP Premium\"].fillna(0) == 0) &\n",
    "          (df[\"gst\"].fillna(0) == 0) &\n",
    "          (df[\"Total Premium Payable\"].fillna(0) == 0))]\n",
    "\n",
    "# Step 4: Identify rows where Total Premium Payable is 0\n",
    "rows_with_zero_premium = df[\"Total Premium Payable\"].fillna(0) == 0\n",
    "\n",
    "# Step 5: Check and calculate gst for those rows where gst is also 0\n",
    "df.loc[rows_with_zero_premium & (df[\"gst\"].fillna(0) == 0), \"gst\"] = (\n",
    "    (df[\"Total OD Premium\"].fillna(0) + df[\"Total TP Premium\"].fillna(0)) * 0.18\n",
    ").round()\n",
    "\n",
    "# Step 6: Calculate Total Premium Payable for rows where Total Premium Payable is 0\n",
    "df.loc[rows_with_zero_premium, \"Total Premium Payable\"] = (\n",
    "    df[\"Total OD Premium\"].fillna(0) +\n",
    "    df[\"Total TP Premium\"].fillna(0) +\n",
    "    df[\"gst\"]\n",
    ").round()\n",
    "\n",
    "# Step 7: Save the cleaned DataFrame to PostgreSQL\n",
    "table_name = \"overall_cleaned_policy_level_data(with prem)\"  # Specify the table name where you want to save the data\n",
    "df.to_sql(table_name, con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of matching Policy Nos between both sources is: 156406\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Step 1: Retrieve Policy No from PostgreSQL\n",
    "sql_query = 'SELECT DISTINCT \"Policy No\" FROM cleanedprem_merged_base_data;'\n",
    "sql_data = pd.read_sql(sql_query, con=engine)\n",
    "\n",
    "# Step 2: Read the Excel file\n",
    "excel_data = pd.read_excel(\"cleaned_PR dataset - Copy.xlsx\", usecols=[\"Policy No\"])\n",
    "\n",
    "# Step 3: Find matching policies\n",
    "# Convert to sets for easy comparison\n",
    "sql_policy_set = set(sql_data[\"Policy No\"])\n",
    "excel_policy_set = set(excel_data[\"Policy No\"])\n",
    "\n",
    "# Find intersection (matching policies)\n",
    "matching_policies = sql_policy_set.intersection(excel_policy_set)\n",
    "\n",
    "# Step 4: Count matches\n",
    "matching_count = len(matching_policies)\n",
    "\n",
    "# Display the result\n",
    "print(f\"The number of matching Policy Nos between both sources is: {matching_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of matching Policy Nos (including duplicates) is: 156406\n",
      "The total number of data points after accounting for matching rows would be: 1307854\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Step 1: Retrieve all Policy No from PostgreSQL\n",
    "sql_query = 'SELECT \"Policy No\" FROM cleanedprem_merged_base_data;'\n",
    "sql_data = pd.read_sql(sql_query, con=engine)\n",
    "\n",
    "# Step 2: Read the Excel file\n",
    "excel_data = pd.read_excel(\"cleaned_PR dataset - Copy.xlsx\", usecols=[\"Policy No\"])\n",
    "\n",
    "# Step 3: Find matching policies (including duplicates)\n",
    "# Convert to sets for matching unique Policy No\n",
    "sql_policy_set = set(sql_data[\"Policy No\"])\n",
    "excel_policy_set = set(excel_data[\"Policy No\"])\n",
    "\n",
    "# Find intersection (matching Policy Nos)\n",
    "matching_policies = sql_policy_set.intersection(excel_policy_set)\n",
    "\n",
    "# Filter rows from Excel data that match the Policy Nos\n",
    "matching_rows = excel_data[excel_data[\"Policy No\"].isin(matching_policies)]\n",
    "\n",
    "# Get the total count of matching rows (including duplicates)\n",
    "matching_count = matching_rows.shape[0]\n",
    "\n",
    "# Step 4: Retrieve the total row count in the cleanedprem_merged_base_data table\n",
    "total_row_query = 'SELECT COUNT(*) FROM cleanedprem_merged_base_data;'\n",
    "existing_row_count = pd.read_sql(total_row_query, con=engine).iloc[0, 0]\n",
    "\n",
    "# Step 5: Calculate the total data points (existing + matching count)\n",
    "total_data_points = existing_row_count + matching_count\n",
    "\n",
    "# Display the results\n",
    "print(f\"The total number of matching Policy Nos (including duplicates) is: {matching_count}\")\n",
    "print(f\"The total number of data points after accounting for matching rows would be: {total_data_points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Policy No for Type B are present in Type A\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Load the data from PostgreSQL table\n",
    "query = 'SELECT \"Policy No\", \"Type\" FROM test_data_12_12;'\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Filter Policy No by Type\n",
    "type_a_policies = set(df.loc[df[\"Type\"] == 'A', \"Policy No\"])\n",
    "type_b_policies = set(df.loc[df[\"Type\"] == 'B', \"Policy No\"])\n",
    "\n",
    "# Check if any Policy No for Type B is missing in Type A\n",
    "if type_b_policies - type_a_policies:\n",
    "    result = 'Some Policy No for Type B are missing in Type A'\n",
    "else:\n",
    "    result = 'All Policy No for Type B are present in Type A'\n",
    "\n",
    "# Display the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of matching Policy Nos between both sources is: 11455\n",
      "Matched policy data from the database saved to 'matched_policies_from_db.csv'.\n",
      "Matched policy data from the Excel file saved to 'matched_policies_from_excel.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Step 1: Retrieve Policy No from PostgreSQL\n",
    "# Query all data and store it in a DataFrame\n",
    "sql_query = 'SELECT * FROM \"overall_policy_level_data_EF\";'\n",
    "sql_data = pd.read_sql(sql_query, con=engine)\n",
    "\n",
    "# Step 2: Read the Excel file\n",
    "# Read all data from the Excel file\n",
    "excel_data = pd.read_excel(\"2024 PR.xlsx\")\n",
    "\n",
    "# Step 3: Find matching policies\n",
    "# Convert Policy No columns to sets for easy comparison\n",
    "sql_policy_set = set(sql_data[\"Policy No\"])\n",
    "excel_policy_set = set(excel_data[\"Policy No\"])\n",
    "\n",
    "# Find intersection (matching policies)\n",
    "matching_policies = sql_policy_set.intersection(excel_policy_set)\n",
    "\n",
    "# Filter matching data from both sources\n",
    "matched_sql_data = sql_data[sql_data[\"Policy No\"].isin(matching_policies)]\n",
    "matched_excel_data = excel_data[excel_data[\"Policy No\"].isin(matching_policies)]\n",
    "\n",
    "# Step 4: Save matched data to separate CSV files\n",
    "matched_sql_data.to_csv(\"matched_policies_from_db.csv\", index=False)\n",
    "matched_excel_data.to_csv(\"matched_policies_from_excel.csv\", index=False)\n",
    "\n",
    "# Step 5: Count matches\n",
    "matching_count = len(matching_policies)\n",
    "\n",
    "# Display the result\n",
    "print(f\"The number of matching Policy Nos between both sources is: {matching_count}\")\n",
    "print(\"Matched policy data from the database saved to 'matched_policies_from_db.csv'.\")\n",
    "print(\"Matched policy data from the Excel file saved to 'matched_policies_from_excel.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2568\\918554132.py:20: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  excel_data = pd.read_csv(\"unique_rows(claim).csv\")\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2568\\918554132.py:29: UserWarning: Parsing dates in %d-%m-%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  excel_data[\"Policy Start Date\"] = pd.to_datetime(excel_data[\"Policy Start Date\"], errors='coerce').dt.strftime('%Y-%m-%d')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2568\\918554132.py:30: UserWarning: Parsing dates in %d-%m-%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  excel_data[\"Policy End Date\"] = pd.to_datetime(excel_data[\"Policy End Date\"], errors='coerce').dt.strftime('%Y-%m-%d')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of exact matches (Policy No, Policy Start Date, and Policy End Date) between both sources is: 183737\n",
      "Matched policy data from the database saved to 'matched_policies_from_db_claim.csv'.\n",
      "Matched policy data from the Excel file saved to 'matched_policies_from_excel_claim.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Step 1: Retrieve Policy Data from PostgreSQL\n",
    "sql_query = 'SELECT * FROM \"overall_policy_level_data_EF\";'\n",
    "sql_data = pd.read_sql(sql_query, con=engine)\n",
    "\n",
    "# Step 2: Read the Excel File\n",
    "excel_data = pd.read_csv(\"unique_rows(claim).csv\")\n",
    "\n",
    "# Step 3: Ensure Column Consistency\n",
    "sql_data.columns = sql_data.columns.str.strip()\n",
    "excel_data.columns = excel_data.columns.str.strip()\n",
    "\n",
    "# Step 4: Standardize Date Formats to 'YYYY-MM-DD'\n",
    "sql_data[\"Policy Start Date\"] = pd.to_datetime(sql_data[\"Policy Start Date\"], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "sql_data[\"Policy End Date\"] = pd.to_datetime(sql_data[\"Policy End Date\"], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "excel_data[\"Policy Start Date\"] = pd.to_datetime(excel_data[\"Policy Start Date\"], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "excel_data[\"Policy End Date\"] = pd.to_datetime(excel_data[\"Policy End Date\"], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Step 5: Concatenate Columns for Matching\n",
    "sql_data[\"Policy_Key\"] = sql_data[\"Policy No\"] + \"_\" + sql_data[\"Policy Start Date\"] + \"_\" + sql_data[\"Policy End Date\"]\n",
    "excel_data[\"Policy_Key\"] = excel_data[\"Policy No\"] + \"_\" + excel_data[\"Policy Start Date\"] + \"_\" + excel_data[\"Policy End Date\"]\n",
    "\n",
    "# Step 6: Find Matches\n",
    "matched_keys = set(sql_data[\"Policy_Key\"]).intersection(set(excel_data[\"Policy_Key\"]))\n",
    "\n",
    "# Step 7: Filter Matched Rows\n",
    "matched_sql_data = sql_data[sql_data[\"Policy_Key\"].isin(matched_keys)].drop(columns=[\"Policy_Key\"])\n",
    "matched_excel_data = excel_data[excel_data[\"Policy_Key\"].isin(matched_keys)].drop(columns=[\"Policy_Key\"])\n",
    "\n",
    "# Step 8: Save Matched Data to Separate CSV Files\n",
    "matched_sql_data.to_csv(\"matched_policies_from_db_claim.csv\", index=False)\n",
    "matched_excel_data.to_csv(\"matched_policies_from_excel_claim.csv\", index=False)\n",
    "\n",
    "# Step 9: Count Matches\n",
    "matching_count = len(matched_sql_data)\n",
    "\n",
    "# Display the Result\n",
    "print(f\"The number of exact matches (Policy No, Policy Start Date, and Policy End Date) between both sources is: {matching_count}\")\n",
    "print(\"Matched policy data from the database saved to 'matched_policies_from_db_claim.csv'.\")\n",
    "print(\"Matched policy data from the Excel file saved to 'matched_policies_from_excel_claim.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "sql_data = pd.read_excel(\" \")\n",
    "\n",
    "# Step 2: Read the Excel file\n",
    "excel_data = pd.read_excel(\"cleaned_PR dataset - Copy.xlsx\", usecols=[\"Policy No\"])\n",
    "\n",
    "# Step 3: Find matching policies\n",
    "# Convert to sets for easy comparison\n",
    "sql_policy_set = set(sql_data[\"Policy No\"])\n",
    "excel_policy_set = set(excel_data[\"Policy No\"])\n",
    "\n",
    "# Find intersection (matching policies)\n",
    "matching_policies = sql_policy_set.intersection(excel_policy_set)\n",
    "\n",
    "# Step 4: Count matches\n",
    "matching_count = len(matching_policies)\n",
    "\n",
    "# Display the result\n",
    "print(f\"The number of matching Policy Nos between both sources is: {matching_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
