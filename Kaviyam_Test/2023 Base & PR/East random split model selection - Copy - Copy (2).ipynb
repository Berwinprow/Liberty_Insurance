{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:19: SyntaxWarning: invalid escape sequence '\\L'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\L'\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7200\\1512353736.py:19: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  data = pd.read_excel('D:\\Liberty (Base data work)\\Actual data (East).xlsx')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after outlier removal: 26408 training samples and 6603 testing samples.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, classification_report, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "selected_columns = ['CustomerID', 'Cleaned_Insured name', 'Policy Start Date', 'Policy End Date', 'Reg no ',\n",
    "       'MANUFACTURER/Make', 'model', 'variant', 'Fuel Type', 'RTO Location ',\n",
    "       'Product name ', 'Product name  2', 'biztype', 'Renewal Type', 'age',\n",
    "       'Vehicle Segment', 'Number of Vehicles', 'Number of Policies',\n",
    "       'Total Premium Payable (Overall)', 'Total OD Premium (Overall)',\n",
    "       'Total TP Premium (Overall)', 'Total Add on Premium (Overall)', 'Average Discount (Overall)',\n",
    "       'Average NCB % Previous Year (Overall)', 'Total GST (Overall)', 'Number of Claims',\n",
    "       'Number of Declines', 'New Branch Name  2', 'Policy Status', 'Churn Label', 'New Customer', 'Customer Tenure ']\n",
    "\n",
    "data = pd.read_excel('D:\\Liberty (Base data work)\\Actual data (East).xlsx')\n",
    "data = data[selected_columns]\n",
    "\n",
    "# Remove rows where 'Status' contains 'Open'\n",
    "data = data[~data['Policy Status'].str.contains('Open', case=False, na=False)]\n",
    "\n",
    "data = data[data['Policy Status'].str.contains('Renewed|Not Renewed', case=False, na=False)]\n",
    "\n",
    "data['Churn Label'] = data['Churn Label'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        data[column] = data[column].fillna('missing')\n",
    "    else:\n",
    "        data[column] = data[column].fillna(0)\n",
    "\n",
    "date_columns = ['Policy Start Date', 'Policy End Date']\n",
    "\n",
    "for col in date_columns:\n",
    "    data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "\n",
    "# Extract year, month, and day as separate features for all date columns\n",
    "new_date_cols = {}\n",
    "for col in date_columns:\n",
    "    new_date_cols[f'{col}_YEAR'] = data[col].dt.year\n",
    "    new_date_cols[f'{col}_MONTH'] = data[col].dt.month\n",
    "    new_date_cols[f'{col}_DAY'] = data[col].dt.day\n",
    "\n",
    "data = pd.concat([data, pd.DataFrame(new_date_cols)], axis=1)\n",
    "\n",
    "data = data.drop(columns=date_columns)\n",
    "\n",
    "# Detect and handle outliers using the IQR method\n",
    "def remove_outliers(df):\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        # Remove rows with outliers\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Apply outlier removal on the entire dataset before defining X and y\n",
    "data = remove_outliers(data)\n",
    "\n",
    "# Define leaking features to exclude\n",
    "leaking_features = ['Policy Status']\n",
    "\n",
    "# Define features for training\n",
    "features = [col for col in data.columns if col not in leaking_features + ['Churn Label']]\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = data[features]\n",
    "y = data['Churn Label']\n",
    "\n",
    "# Split the data into train and test sets (80% train, 20% test split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(f\"Data after outlier removal: {X_train.shape[0]} training samples and {X_test.shape[0]} testing samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Counts:\n",
      "CustomerID  Cleaned_Insured name                Reg no      MANUFACTURER/Make    model       variant                           Fuel Type  RTO Location      Product name                                  Product name  2  biztype           Renewal Type  age        Vehicle Segment  Number of Vehicles  Number of Policies  Total Premium Payable (Overall)  Total OD Premium (Overall)  Total TP Premium (Overall)  Total Add on Premium (Overall)  Average Discount (Overall)  Average NCB % Previous Year (Overall)  Total GST (Overall)  Number of Claims  Number of Declines  New Branch Name  2  New Customer  Customer Tenure   Policy Start Date_YEAR  Policy Start Date_MONTH  Policy Start Date_DAY  Policy End Date_YEAR  Policy End Date_MONTH  Policy End Date_DAY\n",
      "C00103      aaccb2108dbrajeshautomobilespvtltd  NEW         MAHINDRA & MAHINDRA  THAR        THAR LX 4 STR HARD TOP DIESEL MT  Diesel     PURNEA            Private Car Policy - Bundled Cover            SOD              New Business      FY            1.005479   SUV 2            1                   1                   13335                            11301                       0                           8878.813559                     60.0                        0.0                                    2034.0               0                 0                   PURNEA              Yes           1                 2023                    3                        28                     2024                  3                      27                     1\n",
      "C489336     sanjoysarkar                        NEW         MAHINDRA & MAHINDRA  BOLERO      BOLERO B6 OPT                     Diesel     BALURGHAT         Private Car Policy - Bundled Cover            SOD              New Business      FY            1.002740   SUV 1            1                   1                   6242                             5290                        0                           5790.677966                     75.0                        0.0                                    952.0                0                 0                   MALDAH              Yes           1                 2022                    9                        30                     2023                  9                      29                     1\n",
      "C489382     sanjuktabehera                      OD02J6745   MAHINDRA & MAHINDRA  BOLERO      BOLERO ZLX BS-III                 Diesel     BHUBANESWAR       Private Car Package Policy                    Package          Roll Over         FY            10.265608  SUV 1            1                   1                   13981                            3901                        7947                        0.000000                        30.0                        0.0                                    2133.0               0                 0                   BHUBANESHWAR        No            1                 2023                    1                        25                     2024                  1                      24                     1\n",
      "                                                OD02AY7355  MARUTI               DZIRE       DZIRE VXI                         Petrol     BHUBANESWAR       Private Car Package Policy                    Package          Renewal Business  SY onwards    5.002738   COMPACT          1                   1                   7556                             2562                        3841                        448.305085                      45.0                        45.0                                   1153.0               0                 0                   BHUBANESHWAR        Yes           1                 2022                    10                       12                     2023                  10                     11                     1\n",
      "C489381     sanjukta                            BR01ET6244  HYUNDAI              SANTRO      SANTRO SPORTZ                     Petrol     PATNA             Standalone Own Damage Policy for Private Car  Package          Renewal Business  SY onwards    3.001095   COMPACT          1                   1                   9116                             3884                        3841                        4547.457627                     45.0                        25.0                                   1391.0               0                 0                   PATNA               Yes           1                 2022                    6                        9                      2023                  6                      8                      1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ..\n",
      "C293972     marcusmartinhomascarenhas           GA09D6706   MARUTI               S-PRESSO    S-PRESSO VXI                      Petrol     QUEEPEM           Standalone Own Damage Policy for Private Car  Package          Roll Over         FY            3.024658   COMPACT          1                   1                   4506                             1300                        2519                        448.305085                      77.5                        25.0                                   687.0                0                 0                   BEGUSARAI           Yes           1                 2023                    3                        11                     2024                  3                      10                     1\n",
      "C293954     marbomete                           NEW         MAHINDRA & MAHINDRA  BOLERO NEO  BOLERO NEO N10                    Diesel     PASIGHAT          Private Car Policy - Bundled Cover            SOD              New Business      FY            1.002740   SUV 1            1                   1                   8108                             6871                        0                           6194.067797                     70.0                        0.0                                    1237.0               0                 0                   Jorhat              Yes           1                 2022                    10                       3                      2023                  10                     2                      1\n",
      "C293953     marbomdirchi                        NEW         MARUTI               ALTO 800    ALTO 800 LXI (O)                  Petrol     ITANAGAR          Private Car Policy - Bundled Cover            SOD              New Business      FY            1.002740   COMPACT          1                   1                   5387                             4565                        0                           3302.542373                     43.0                        0.0                                    822.0                0                 0                   Jorhat              Yes           1                 2022                    11                       26                     2023                  11                     25                     1\n",
      "C293951     marbinbmarak                        NEW         MAHINDRA & MAHINDRA  BOLERO NEO  BOLERO NEO N10 (O)                Diesel     EAST KHASI HILLS  Private Car Policy - Bundled Cover            SOD              New Business      FY            1.002740   SUV 1            1                   1                   9479                             8033                        0                           6611.864407                     67.5                        0.0                                    1446.0               0                 0                   SHILLONG            Yes           1                 2023                    1                        18                     2024                  1                      17                     1\n",
      "C99881      caneandbamboohandicraftsociety      NEW         MAHINDRA & MAHINDRA  BOLERO NEO  BOLERO NEO N10                    Diesel     IMPHAL            Private Car Policy - Bundled Cover            SOD              New Business      FY            1.002740   SUV 1            1                   1                   8180                             6932                        0                           6240.677966                     70.0                        0.0                                    1248.0               0                 0                   GUWAHATI            Yes           1                 2022                    10                       31                     2023                  10                     30                     1\n",
      "Name: count, Length: 26408, dtype: int64\n",
      "\n",
      "Testing Data Counts:\n",
      "CustomerID  Cleaned_Insured name       Reg no      MANUFACTURER/Make    model    variant                 Fuel Type  RTO Location   Product name                                  Product name  2  biztype           Renewal Type  age       Vehicle Segment  Number of Vehicles  Number of Policies  Total Premium Payable (Overall)  Total OD Premium (Overall)  Total TP Premium (Overall)  Total Add on Premium (Overall)  Average Discount (Overall)  Average NCB % Previous Year (Overall)  Total GST (Overall)  Number of Claims  Number of Declines  New Branch Name  2  New Customer  Customer Tenure   Policy Start Date_YEAR  Policy Start Date_MONTH  Policy Start Date_DAY  Policy End Date_YEAR  Policy End Date_MONTH  Policy End Date_DAY\n",
      "C00381      aakashkumar                BR01FG5915  TATA MOTORS          NEXON    NEXON 1.2 XZ PLUS       Petrol     PATNA          Standalone Own Damage Policy for Private Car  SOD              Renewal Business  SY onwards    2.002740  SUV 1            1                   1                   10836                            9183                        0                           6939.830508                     50.0                        20.0                                   1653.0               0                 0                   PATNA               Yes           1                 2022                    8                        10                     2023                  8                      9                      1\n",
      "C496074     sarojkumarmohanty          JH05CK2679  MARUTI               DZIRE    DZIRE VXI               Petrol     JAMSHEDPUR     Private Car Package Policy                    Package          Roll Over         FY            4.006024  COMPACT          1                   1                   8747                             3572                        3841                        448.305085                      57.5                        0.0                                    1334.0               0                 0                   BHUBANESHWAR        Yes           1                 2022                    5                        19                     2023                  5                      18                     1\n",
      "C496724     sasadharjana               NEW         TATA MOTORS          ALTROZ   ALTROZ XZ PLUS PETROL   Petrol     JHARGRAM       Private Car Policy - Bundled Cover            SOD              New Business      FY            1.005479  COMPACT          1                   1                   13192                            11180                       0                           6465.254237                     40.0                        0.0                                    2012.0               0                 0                   KHARAGPUR           Yes           1                 2023                    7                        26                     2024                  7                      25                     1\n",
      "C49643      arjunlal                   JH05BY7424  MARUTI               BALENO   BALENO DELTA 1.2        Petrol     JAMSHEDPUR     Private Car Package Policy                    Package          Roll Over         FY            6.002191  COMPACT          1                   1                   6010                             1252                        3841                        448.305085                      70.0                        45.0                                   917.0                0                 0                   JAMSHEDPUR          Yes           1                 2023                    1                        15                     2024                  1                      14                     1\n",
      "C496393     sarungbamusharanidevi      NEW         MAHINDRA & MAHINDRA  XUV 300  XUV 300 1.2 W6          Petrol     IMPHAL         Private Car Policy - Bundled Cover            SOD              New Business      FY            1.002740  SUV 1            1                   1                   7297                             6184                        0                           5564.406780                     70.0                        0.0                                    1113.0               0                 0                   IMPHAL              Yes           1                 2022                    1                        20                     2023                  1                      19                     1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ..\n",
      "C298480     mdjawedalam                WB38AL2731  MAHINDRA & MAHINDRA  BOLERO   BOLERO PLUS AC 9STR     Diesel     ASANSOL        Private Car Package Policy                    Package          Renewal Business  SY onwards    6.119934  SUV 1            1                   1                   13205                            2369                        8822                        549.152542                      70.0                        50.0                                   2014.0               0                 0                   DURGAPUR            Yes           1                 2022                    8                        3                      2023                  8                      2                      1\n",
      "C298472     mdjaved                    NEW         MAHINDRA & MAHINDRA  SCORPIO  SCORPIO CLASSIC S11 MT  Diesel     LAKHISARAI     Private Car Policy - Bundled Cover            SOD              New Business      FY            1.002740  SUV 1            1                   1                   15425                            13072                       0                           8590.677966                     62.5                        0.0                                    2353.0               0                 0                   GAYA                Yes           1                 2023                    2                        25                     2024                  2                      24                     1\n",
      "C298446     mdistiyakali               NEW         MAHINDRA & MAHINDRA  SCORPIO  SCORPIO CLASSIC S 9STR  Diesel     PATNA          Private Car Policy - Bundled Cover            SOD              New Business      FY            1.005479  SUV 1            1                   1                   9460                             8017                        0                           7316.101695                     72.0                        0.0                                    1443.0               0                 0                   PATNA               Yes           1                 2023                    4                        30                     2024                  4                      29                     1\n",
      "C298445     mdistiyakahmad             JH01CS6437  MARUTI               DZIRE    DZIRE ZXI PLUS AMT      Petrol     RANCHI         Private Car Package Policy                    Package          Roll Over         FY            5.821468  COMPACT          1                   1                   7082                             2161                        3841                        448.305085                      80.0                        20.0                                   1080.0               0                 0                   RANCHI              Yes           1                 2022                    10                       13                     2023                  10                     12                     1\n",
      "C99917      capitalmarblesandgranites  OD02BJ9540  HYUNDAI              VENUE    VENUE 1.4 SX CRDI (O)   Diesel     BHUBANESWAR    Standalone Own Damage Policy for Private Car  Package          Roll Over         FY            2.990142  SUV 1            1                   1                   9822                             4608                        3716                        7505.932203                     73.5                        25.0                                   1498.0               0                 0                   BHUBANESHWAR        Yes           1                 2022                    3                        21                     2023                  3                      20                     1\n",
      "Name: count, Length: 6603, dtype: int64\n",
      "Training Data Status Counts:\n",
      "Churn Label\n",
      "1    26408\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Testing Data Status Counts:\n",
      "Churn Label\n",
      "1    6603\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Count the occurrences of 0 and 1 in the 'Status' column for train and test data\n",
    "train_count = X_train.value_counts()\n",
    "test_count = X_test.value_counts()\n",
    "\n",
    "train_status_count = y_train.value_counts()\n",
    "test_status_count = y_test.value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(\"Training Data Counts:\")\n",
    "print(train_count)\n",
    "\n",
    "print(\"\\nTesting Data Counts:\")\n",
    "print(test_count)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training Data Status Counts:\")\n",
    "print(train_status_count)\n",
    "\n",
    "print(\"\\nTesting Data Status Counts:\")\n",
    "print(test_status_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to categorical features for both train and test sets\n",
    "for column in X_train.columns:\n",
    "    if X_train[column].dtype == 'object':\n",
    "        # Initialize and fit the LabelEncoder on the training data\n",
    "        label_encoder = LabelEncoder()\n",
    "        X_train[column] = label_encoder.fit_transform(X_train[column].astype(str))\n",
    "\n",
    "        # Create a mapping dictionary from the LabelEncoder\n",
    "        mapping_dict = {label: i for i, label in enumerate(label_encoder.classes_)}\n",
    "        \n",
    "        # Track the next unique integer for unseen values in the test set\n",
    "        next_unique_value = [max(mapping_dict.values()) + 1]  \n",
    "\n",
    "        # Encode the test data\n",
    "        def encode_test_value(value):\n",
    "            if value in mapping_dict:\n",
    "                return mapping_dict[value]\n",
    "            else:\n",
    "                # Update the mapping_dict with a new unique value for unseen categories\n",
    "                mapping_dict[value] = next_unique_value[0]\n",
    "                next_unique_value[0] += 1\n",
    "                return mapping_dict[value]\n",
    "\n",
    "        # Apply the encoding to the test set\n",
    "        X_test[column] = X_test[column].apply(encode_test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Make predictions on test and training data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 11\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     13\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m     14\u001b[0m y_train_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_train)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Initialize and train the Decision Tree classifier\n",
    "model = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# Initialize and train the Decision Tree classifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=8,                \n",
    "    min_samples_split=20,       \n",
    "    min_samples_leaf=10,        \n",
    "    max_leaf_nodes=50,          \n",
    "    ccp_alpha=0.01              \n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    max_leaf_nodes=50,\n",
    "    class_weight={0: 10, 1: 1},  \n",
    "    random_state=42\n",
    ")\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the Decision Tree classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    max_leaf_nodes=50,\n",
    "    class_weight={0: 5, 1: 1},  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,             \n",
    "    max_depth=8,                  \n",
    "    min_samples_split=20,         \n",
    "    min_samples_leaf=10,          \n",
    "    max_leaf_nodes=50,            \n",
    "    class_weight='balanced',      \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=50,  \n",
    "    max_depth=6,     \n",
    "    min_samples_split=50,\n",
    "    min_samples_leaf=20,\n",
    "    max_leaf_nodes=30,\n",
    "    class_weight={0: 5, 1: 1},\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, classification_report, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,   \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, classification_report, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "model = SVC(probability=True, kernel='linear', max_iter=1000)  \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, classification_report, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize and train the KNN model\n",
    "model = KNeighborsClassifier(n_neighbors=5)  \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, classification_report, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "model = GaussianNB() \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,                  \n",
    "    learning_rate=0.1,            \n",
    "    n_estimators=100,            \n",
    "    scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]), \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "    max_depth=5,                   # Slightly shallower trees\n",
    "    learning_rate=0.05,            # Slower learning rate\n",
    "    n_estimators=200,              # More boosting rounds\n",
    "    subsample=0.8,                 # Use 80% of data for each tree\n",
    "    colsample_bytree=0.8,          # Use 80% of features for each tree\n",
    "    scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),  # Handle class imbalance\n",
    "    gamma=0.1,                     # Regularization to prevent overfitting\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,  # L1 regularization\n",
    "    reg_lambda=1.0,  # L2 regularization\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, classification_report, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GBM model\n",
    "model = GradientBoostingClassifier(\n",
    "    max_depth=5,                    # Same depth as XGBoost for comparison\n",
    "    learning_rate=0.05,             # Learning rate\n",
    "    n_estimators=200,               # Number of boosting rounds\n",
    "    subsample=0.8,                  # Use 80% of data for each tree\n",
    "    random_state=42                 # Random state for reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=200,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    warm_start=False,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10,\n",
    "    tol=1e-4\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, classification_report, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GBM model\n",
    "model = GradientBoostingClassifier(\n",
    "    max_depth=6,                    \n",
    "    learning_rate=0.1,              \n",
    "    n_estimators=100,              \n",
    "    random_state=42                 \n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, classification_report, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GBM model\n",
    "model = GradientBoostingClassifier(\n",
    "    max_depth=6,                    \n",
    "    learning_rate=0.1,              \n",
    "    n_estimators=100,              \n",
    "    random_state=42                 \n",
    ")\n",
    "\n",
    "# Assign higher weight to Class 0 samples\n",
    "sample_weights = [2 if y == 0 else 1 for y in y_train]\n",
    "model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, classification_report, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# AdaBoost model with a DecisionTreeClassifier as the base estimator\n",
    "model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=6),  \n",
    "    learning_rate=0.1,                              \n",
    "    n_estimators=100,                               \n",
    "    random_state=42                                 \n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, classification_report, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CatBoost model\n",
    "model = CatBoostClassifier(\n",
    "    depth=6,                      \n",
    "    learning_rate=0.1,            \n",
    "    iterations=100,               \n",
    "    random_seed=42,               \n",
    "    verbose=0                     \n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, classification_report, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# LightGBM model\n",
    "model = LGBMClassifier(\n",
    "    max_depth=6,                     # Equivalent to max_depth in AdaBoost\n",
    "    learning_rate=0.1,               # Same learning rate as AdaBoost\n",
    "    n_estimators=100,                # Equivalent to n_estimators\n",
    "    random_state=42                  # Random state for reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test and training data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Evaluate the model on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_log_loss = log_loss(y_train, y_train_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "\n",
    "# Calculate confusion matrix for test data and compute class-specific accuracy\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred)\n",
    "class_0_accuracy_test = conf_matrix_test[0, 0] / conf_matrix_test[0].sum()\n",
    "class_1_accuracy_test = conf_matrix_test[1, 1] / conf_matrix_test[1].sum()\n",
    "\n",
    "# Calculate confusion matrix for training data and compute class-specific accuracy\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print evaluation metrics for test and training data\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "print(f\"Class 0 Test Accuracy: {class_0_accuracy_test}\")\n",
    "print(f\"Class 1 Test Accuracy: {class_1_accuracy_test}\")\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n",
    "\n",
    "# Plot ROC curve for test data\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (test) (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for training data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='green', lw=2, label=f'ROC curve (train) (area = {train_roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Training Data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_curve, roc_auc_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert data to numeric types\n",
    "X_train_numeric = np.array(X_train, dtype=np.float32)  \n",
    "X_test_numeric = np.array(X_test, dtype=np.float32)    \n",
    "y_train_numeric = np.array(y_train, dtype=np.float32)  \n",
    "y_test_numeric = np.array(y_test, dtype=np.float32)    \n",
    "\n",
    "# Reshape X_train and X_test to have a time step dimension (convert to 3D for RNN input)\n",
    "X_train_reshaped = np.expand_dims(X_train_numeric, axis=1)  \n",
    "X_test_reshaped = np.expand_dims(X_test_numeric, axis=1)\n",
    "\n",
    "# Define the Simple RNN model\n",
    "model = Sequential([\n",
    "    SimpleRNN(32, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), activation='relu', return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model and store history\n",
    "history = model.fit(X_train_reshaped, y_train_numeric, epochs=20, batch_size=32, validation_data=(X_test_reshaped, y_test_numeric))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = model.predict(X_test_reshaped).ravel()\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Check for NaN values in y_pred_proba or y_test_numeric\n",
    "if np.isnan(y_pred_proba).any() or np.isnan(y_test_numeric).any():\n",
    "    print(\"NaN values found in predictions or test labels.\")\n",
    "    y_pred_proba = np.nan_to_num(y_pred_proba)  \n",
    "    y_test_numeric = np.nan_to_num(y_test_numeric)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_numeric, y_pred)\n",
    "log_loss_value = log_loss(y_test_numeric, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test_numeric, y_pred_proba)\n",
    "report = classification_report(y_test_numeric, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "\n",
    "# Training accuracy and loss\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "train_loss = history.history['loss'][-1]\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Training Loss: {train_loss}\")\n",
    "\n",
    "# Plot training & validation accuracy over epochs\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss over epochs\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test_numeric, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_curve, roc_auc_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(32, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), activation='relu', return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model and store history\n",
    "history = model.fit(X_train_reshaped, y_train_numeric, epochs=20, batch_size=32, validation_data=(X_test_reshaped, y_test_numeric))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = model.predict(X_test_reshaped).ravel()\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Check for NaN values in y_pred_proba or y_test_numeric\n",
    "if np.isnan(y_pred_proba).any() or np.isnan(y_test_numeric).any():\n",
    "    print(\"NaN values found in predictions or test labels.\")\n",
    "    y_pred_proba = np.nan_to_num(y_pred_proba) \n",
    "    y_test_numeric = np.nan_to_num(y_test_numeric)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_numeric, y_pred)\n",
    "log_loss_value = log_loss(y_test_numeric, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test_numeric, y_pred_proba)\n",
    "report = classification_report(y_test_numeric, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "\n",
    "# Training accuracy and loss\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "train_loss = history.history['loss'][-1]\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Training Loss: {train_loss}\")\n",
    "\n",
    "# Plot training & validation accuracy over epochs\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss over epochs\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test_numeric, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_curve, roc_auc_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define the GRU model\n",
    "model = Sequential([\n",
    "    GRU(32, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), activation='relu', return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model and store history\n",
    "history = model.fit(X_train_reshaped, y_train_numeric, epochs=20, batch_size=32, validation_data=(X_test_reshaped, y_test_numeric))\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = model.predict(X_test_reshaped).ravel()\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Check for NaN values in y_pred_proba or y_test_numeric\n",
    "if np.isnan(y_pred_proba).any() or np.isnan(y_test_numeric).any():\n",
    "    print(\"NaN values found in predictions or test labels.\")\n",
    "    y_pred_proba = np.nan_to_num(y_pred_proba)  \n",
    "    y_test_numeric = np.nan_to_num(y_test_numeric)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_numeric, y_pred)\n",
    "log_loss_value = log_loss(y_test_numeric, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test_numeric, y_pred_proba)\n",
    "report = classification_report(y_test_numeric, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Log Loss: {log_loss_value}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "print(f\"Test Classification Report:\\n{report}\")\n",
    "\n",
    "# Training accuracy and loss\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "train_loss = history.history['loss'][-1]\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Training Loss: {train_loss}\")\n",
    "\n",
    "# Plot training & validation accuracy over epochs\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss over epochs\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test_numeric, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
