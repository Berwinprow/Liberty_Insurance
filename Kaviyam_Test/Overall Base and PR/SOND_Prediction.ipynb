{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# Database connection setup\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Load data from PostgreSQL\n",
    "query = 'SELECT * FROM public.overall_cleaned_base_and_pr_ef_policyef;'\n",
    "data = pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['policy no', 'renewal type', 'product name', 'product name 2',  'biztype', 'policy end date', 'policy start date', \n",
    " 'age', 'manufacturer/make', 'model', 'variant', 'vehicle segment', 'fuel type', 'rto location', 'vehicle idv', 'ncb amount', 'Cleaned Reg no', \n",
    " 'before gst add-on gwp', 'total od premium', 'total tp premium', 'gst', 'total premium payable', \n",
    " 'ncb % previous year', 'applicable discount with ncb', 'Cleaned Branch Name 2', 'Cleaned State2', 'Cleaned Zone 2', 'tie up',\n",
    " 'Number of claims', 'approved', 'denied', 'corrected_name', 'customerid', 'Policy Status', 'Policy Tenure', 'Customer Tenure', 'New Customers', 'Claim Happaned/Not', \n",
    " 'Renewal Rate Status', 'withdrawn', 'chassis_engine_key', 'policy_wise_purchase']\n",
    "\n",
    "data = data[selected_columns]\n",
    "\n",
    "# Convert Policy End Date to datetime\n",
    "data['policy end date'] = pd.to_datetime(data['policy end date'], errors='coerce')\n",
    "\n",
    "# Separate Open Customers (August to October 2024)\n",
    "open_customers = data[\n",
    "    (data['Policy Status'].isin(['Renewed', 'Not Renewed'])) &\n",
    "    (data['policy end date'].dt.year == 2024) &\n",
    "    (data['policy end date'].dt.month.isin([9, 10, 11, 12]))\n",
    "].copy()\n",
    "\n",
    "# Filter the main dataset for customers whose Policy End Date is <= July 2024\n",
    "data = data[\n",
    "    (data['Policy Status'].isin(['Renewed', 'Not Renewed'])) &\n",
    "    (data['policy end date'] <= pd.to_datetime('2024-08-31'))\n",
    "]\n",
    "\n",
    "# Map Policy Status to binary\n",
    "data['Policy Status'] = data['Policy Status'].apply(lambda x: 1 if x == 'Not Renewed' else 0)\n",
    "\n",
    "# Handle missing values\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        data[column] = data[column].fillna('missing')\n",
    "    else:\n",
    "        data[column] = data[column].fillna(0)\n",
    "\n",
    "# Extract year, month, and day from date columns\n",
    "date_columns = ['policy start date', 'policy end date']\n",
    "for col in date_columns:\n",
    "    data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "\n",
    "# Extract date features\n",
    "for col in date_columns:\n",
    "    data[f'{col}_YEAR'] = data[col].dt.year\n",
    "    data[f'{col}_MONTH'] = data[col].dt.month\n",
    "    data[f'{col}_DAY'] = data[col].dt.day\n",
    "\n",
    "# Drop original date columns\n",
    "data.drop(columns=date_columns, inplace=True)\n",
    "\n",
    "# Separate features and target variable for training\n",
    "features = [col for col in data.columns if col != 'Policy Status']\n",
    "X = data[features]\n",
    "y = data['Policy Status']\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, log_loss, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Apply Random Oversampling to the training data\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Apply the same transformations to open_customers\n",
    "for col in date_columns:\n",
    "    open_customers[col] = pd.to_datetime(open_customers[col], errors='coerce')\n",
    "\n",
    "for col in date_columns:\n",
    "    open_customers[f'{col}_YEAR'] = open_customers[col].dt.year\n",
    "    open_customers[f'{col}_MONTH'] = open_customers[col].dt.month\n",
    "    open_customers[f'{col}_DAY'] = open_customers[col].dt.day\n",
    "\n",
    "open_customers.drop(columns=date_columns, inplace=True)\n",
    "\n",
    "for column in open_customers.columns:\n",
    "    if open_customers[column].dtype == 'object':\n",
    "        open_customers[column] = open_customers[column].fillna('missing')\n",
    "    else:\n",
    "        open_customers[column] = open_customers[column].fillna(0)\n",
    "\n",
    "open_customers_without_encoded = open_customers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to categorical features\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        label_encoder = LabelEncoder()\n",
    "        X[column] = label_encoder.fit_transform(X[column].astype(str))\n",
    "        label_encoders[column] = label_encoder\n",
    "        \n",
    "        mapping_dict = {label: i for i, label in enumerate(label_encoder.classes_)}\n",
    "        next_unique_value = max(mapping_dict.values()) + 1  \n",
    "\n",
    "        def encode_test_value(value):\n",
    "            return mapping_dict.get(value, next_unique_value)\n",
    "\n",
    "        open_customers[column] = open_customers[column].apply(encode_test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Renewed: 48642\n",
      "Predicted Not Renewed: 217079\n",
      "Train Accuracy: 0.7523645565972796\n",
      "Train Log Loss: 0.501083515447137\n",
      "Train ROC AUC: 0.8329782910106387\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76    749612\n",
      "           1       0.77      0.72      0.74    749612\n",
      "\n",
      "    accuracy                           0.75   1499224\n",
      "   macro avg       0.75      0.75      0.75   1499224\n",
      "weighted avg       0.75      0.75      0.75   1499224\n",
      "\n",
      "Class 0 Train Accuracy: 0.7871058627663378\n",
      "Class 1 Train Accuracy: 0.7176232504282215\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    depth=10,                    \n",
    "    learning_rate=0.1,            \n",
    "    iterations=500,               \n",
    "    random_seed=42,               \n",
    "    verbose=0                     \n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict using encoded data\n",
    "X_open_customers = open_customers[features]\n",
    "y_open_pred = model.predict(X_open_customers)\n",
    "y_open_pred_proba = model.predict_proba(X_open_customers)[:, 1]  \n",
    "\n",
    "# Store prediction results in unencoded data\n",
    "open_customers_without_encoded['Predicted Status'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability'] = y_open_pred_proba\n",
    "\n",
    "print(f\"Predicted Renewed: {(y_open_pred == 0).sum()}\")\n",
    "print(f\"Predicted Not Renewed: {(y_open_pred == 1).sum()}\")\n",
    "\n",
    "# Evaluate model on training data\n",
    "y_pred = model.predict(X)\n",
    "y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "#Evaluate the model on training data\n",
    "train_accuracy = accuracy_score(y, y_pred)\n",
    "train_log_loss = log_loss(y, y_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "train_report = classification_report(y, y_pred)\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y, y_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "#Print the metrics\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "open_customers_without_encoded.to_csv('SOND_predictions_cat_check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Renewed: 97472\n",
      "Predicted Not Renewed: 168249\n",
      "Train Accuracy: 0.7471511928837852\n",
      "Train Log Loss: 0.800480203816853\n",
      "Train ROC AUC: 0.6157244358285027\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76    749612\n",
      "           1       0.77      0.70      0.74    749612\n",
      "\n",
      "    accuracy                           0.75   1499224\n",
      "   macro avg       0.75      0.75      0.75   1499224\n",
      "weighted avg       0.75      0.75      0.75   1499224\n",
      "\n",
      "Class 0 Train Accuracy: 0.7919843865893289\n",
      "Class 1 Train Accuracy: 0.7023179991782416\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, classification_report, confusion_matrix, roc_curve\n",
    "\n",
    "# Define the models\n",
    "model_1 = CatBoostClassifier(\n",
    "    depth=6, learning_rate=0.1, iterations=100, \n",
    "    random_seed=42, verbose=0)\n",
    "\n",
    "model_2 = CatBoostClassifier(\n",
    "    depth=10, learning_rate=0.1, iterations=500, \n",
    "    random_seed=42, verbose=0)\n",
    "\n",
    "# Fit both models\n",
    "model_1.fit(X, y)\n",
    "model_2.fit(X, y)\n",
    "\n",
    "# Predict probabilities\n",
    "proba_1 = model_1.predict_proba(X)\n",
    "proba_2 = model_2.predict_proba(X)\n",
    "\n",
    "# Adjust decision threshold to favor Class 0\n",
    "threshold_0 = 0.60  # Increase bias towards Class 0\n",
    "threshold_1 = 0.50  # Lower threshold for Class 1\n",
    "\n",
    "y_pred = np.where(proba_1[:, 0] > threshold_0, 0, \n",
    "                  np.where(proba_2[:, 1] > threshold_1, 1, 0))\n",
    "y_pred_proba = np.maximum(proba_1[:, 0], proba_2[:, 1])\n",
    "\n",
    "# Store prediction results in open customer data\n",
    "X_open_customers = open_customers[features]\n",
    "proba_open_1 = model_1.predict_proba(X_open_customers)\n",
    "proba_open_2 = model_2.predict_proba(X_open_customers)\n",
    "\n",
    "y_open_pred = np.where(proba_open_1[:, 0] > threshold_0, 0, \n",
    "                       np.where(proba_open_2[:, 1] > threshold_1, 1, 0))\n",
    "y_open_pred_proba = np.maximum(proba_open_1[:, 0], proba_open_2[:, 1])\n",
    "\n",
    "# Store prediction results in unencoded data\n",
    "open_customers_without_encoded['Predicted Status'] = np.where(y_open_pred == 1, 'Not Renewed', 'Renewed')\n",
    "open_customers_without_encoded['Churn Probability'] = y_open_pred_proba\n",
    "\n",
    "print(f\"Predicted Renewed: {(y_open_pred == 0).sum()}\")\n",
    "print(f\"Predicted Not Renewed: {(y_open_pred == 1).sum()}\")\n",
    "\n",
    "# Evaluate model on training data\n",
    "train_accuracy = accuracy_score(y, y_pred)\n",
    "train_log_loss = log_loss(y, y_pred_proba)\n",
    "train_roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "train_report = classification_report(y, y_pred)\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y, y_pred)\n",
    "class_0_accuracy_train = conf_matrix_train[0, 0] / conf_matrix_train[0].sum()\n",
    "class_1_accuracy_train = conf_matrix_train[1, 1] / conf_matrix_train[1].sum()\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Log Loss: {train_log_loss}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc}\")\n",
    "print(f\"Train Classification Report:\\n{train_report}\")\n",
    "print(f\"Class 0 Train Accuracy: {class_0_accuracy_train}\")\n",
    "print(f\"Class 1 Train Accuracy: {class_1_accuracy_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "open_customers_without_encoded.to_csv('SOND_predictions_cat_combined_check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
