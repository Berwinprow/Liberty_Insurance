{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Function to standardize column names (strip spaces, lowercase, remove extra spaces)\n",
    "def clean_columns(df):\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(r'\\s+', ' ', regex=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Load and Clean Base Datasets\n",
    "##############################\n",
    "\n",
    "# --- For Base 2022 ---\n",
    "base_2022 = pd.read_excel(\"Pvt Car Jan to Dec 22(22 Base).xlsx\")\n",
    "# Add the data column first\n",
    "base_2022[\"data\"] = \"2022_base\"\n",
    "# Now clean the columns (the added \"data\" column remains lower-case)\n",
    "base_2022 = clean_columns(base_2022)\n",
    "\n",
    "# --- For Base 2023 ---\n",
    "base_2023 = pd.read_excel(\"Pvt Car Jan'23 to  Dec 23 base Final.xlsx\")\n",
    "base_2023[\"data\"] = \"2023_base\"\n",
    "base_2023 = clean_columns(base_2023)\n",
    "\n",
    "# --- For Base 2024 ---\n",
    "base_2024 = pd.read_excel(\"cleaned_2024_Base_dataset.xlsx\")\n",
    "base_2024[\"data\"] = \"2024_base\"\n",
    "base_2024 = clean_columns(base_2024)\n",
    "\n",
    "# (Optional) Ensure that all Base dataframes include a \"data\" column\n",
    "for df in [base_2022, base_2023, base_2024]:\n",
    "    if \"data\" not in df.columns:\n",
    "        df[\"data\"] = None\n",
    "\n",
    "# Find common columns across all Base datasets.\n",
    "# (Because we added the \"data\" column before cleaning, it is already part of the intersection.)\n",
    "common_base_columns = list(set(base_2022.columns) & set(base_2023.columns) & set(base_2024.columns))\n",
    "\n",
    "# Merge all Base datasets while keeping only the common columns.\n",
    "base_merged = pd.concat(\n",
    "    [df[common_base_columns] for df in [base_2022, base_2023, base_2024]], \n",
    "    ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14896\\3260659287.py:6: DtypeWarning: Columns (17,29,33,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pr_2022 = pd.read_csv(\"cleaned_2022_PR.csv\")\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14896\\3260659287.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_merged = pd.concat([base_merged, pr_merged], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# Load and Clean PR Datasets\n",
    "##############################\n",
    "\n",
    "# --- For PR 2022 ---\n",
    "pr_2022 = pd.read_csv(\"cleaned_2022_PR.csv\")\n",
    "pr_2022[\"data\"] = \"2022_pr\"\n",
    "pr_2022 = clean_columns(pr_2022)\n",
    "\n",
    "# --- For PR 2023 ---\n",
    "pr_2023 = pd.read_excel(\"cleaned_PR dataset.xlsx\")  # This file contains \"old policy no\"\n",
    "pr_2023[\"data\"] = \"2023_pr\"\n",
    "pr_2023 = clean_columns(pr_2023)\n",
    "\n",
    "# --- For PR 2024 ---\n",
    "pr_2024 = pd.read_excel(\"cleaned_2024_PR_tie_up.xlsx\")\n",
    "pr_2024[\"data\"] = \"2024_pr\"\n",
    "pr_2024 = clean_columns(pr_2024)\n",
    "\n",
    "# Find common columns across PR datasets.\n",
    "common_pr_columns = list(set(pr_2022.columns) & set(pr_2023.columns) & set(pr_2024.columns))\n",
    "\n",
    "# Merge all PR datasets while keeping only the common columns.\n",
    "pr_merged = pd.concat(\n",
    "    [df[common_pr_columns] for df in [pr_2022, pr_2023, pr_2024]],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Ensure the PR dataset follows the Base structure (add missing columns as NaN).\n",
    "for col in common_base_columns:\n",
    "    if col not in pr_merged.columns:\n",
    "        pr_merged[col] = None\n",
    "\n",
    "# If \"old policy no\" exists in the PR 2023 file and \"policy no\" exists in the merged PR,\n",
    "# merge it into pr_merged.\n",
    "if \"old policy no\" in pr_2023.columns and \"policy no\" in pr_merged.columns:\n",
    "    pr_merged = pr_merged.merge(\n",
    "        pr_2023[['policy no', 'old policy no']], \n",
    "        on='policy no', \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# Ensure the Base dataset has an \"old policy no\" column as well.\n",
    "if \"old policy no\" not in base_merged.columns:\n",
    "    base_merged[\"old policy no\"] = None\n",
    "\n",
    "# Merge Base and PR datasets.\n",
    "final_merged = pd.concat([base_merged, pr_merged], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data successfully written to PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# Write the Final Data to PostgreSQL\n",
    "##############################\n",
    "\n",
    "# Database connection details\n",
    "db_username = 'postgres'\n",
    "db_password = 'kaviyam123'\n",
    "db_host = 'localhost'  \n",
    "db_port = '5432'\n",
    "db_name = 'postgres'\n",
    "\n",
    "# Create a connection to PostgreSQL\n",
    "engine = create_engine(f'postgresql://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# Write the merged DataFrame to PostgreSQL\n",
    "final_merged.to_sql('appended_base_and_pr', engine, if_exists='replace', index=False, chunksize=100000)\n",
    "\n",
    "print(\"Merged data successfully written to PostgreSQL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
