{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Load Base datasets and add a \"Data\" column for tracking source\n",
    "base_2022 = pd.read_excel(\"Pvt Car Jan to Dec 22(22 Base).xlsx\")\n",
    "base_2022[\"Data\"] = \"2022_Base\"\n",
    "\n",
    "base_2023 = pd.read_excel(\"Pvt Car Jan'23 to  Dec 23 base Final.xlsx\")\n",
    "base_2023[\"Data\"] = \"2023_Base\"\n",
    "\n",
    "base_2024 = pd.read_excel(\"cleaned_2024_Base_dataset.xlsx\")\n",
    "base_2024[\"Data\"] = \"2024_Base\"\n",
    "\n",
    "# Find common columns across all Base datasets\n",
    "common_base_columns = list(set(base_2022.columns) & set(base_2023.columns) & set(base_2024.columns))\n",
    "\n",
    "# Merge all Base datasets while keeping only common columns\n",
    "base_merged = pd.concat([df[common_base_columns + [\"Data\"]] for df in [base_2022, base_2023, base_2024]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_1184\\568712456.py:2: DtypeWarning: Columns (17,29,33,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pr_2022 = pd.read_csv(\"cleaned_2022_PR.csv\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m pr_merged \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df[common_pr_columns \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m [pr_2022, pr_2023, pr_2024]], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Ensure PR dataset follows the Base structure (adds missing columns as NaN)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m pr_merged \u001b[38;5;241m=\u001b[39m \u001b[43mpr_merged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommon_base_columns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Add \"Old Policy No\" from PR 2023 (if it exists)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOld Policy No\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pr_2023\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolicy No\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pr_merged\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:5378\u001b[0m, in \u001b[0;36mDataFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5359\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   5360\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,\n\u001b[0;32m   5361\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5376\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5377\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 5378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5382\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5389\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:5610\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5609\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5611\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m   5612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:5633\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5630\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   5632\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[1;32m-> 5633\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m   5635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5637\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[0;32m   5638\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   5639\u001b[0m     {axis: [new_index, indexer]},\n\u001b[0;32m   5640\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5641\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5642\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5643\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:4429\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   4426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m   4428\u001b[0m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[1;32m-> 4429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4431\u001b[0m     indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "# Load PR datasets and add a \"Data\" column\n",
    "pr_2022 = pd.read_csv(\"cleaned_2022_PR.csv\")\n",
    "pr_2022[\"Data\"] = \"2022_PR\"\n",
    "\n",
    "pr_2023 = pd.read_excel(\"cleaned_PR dataset.xlsx\")  \n",
    "pr_2023[\"Data\"] = \"2023_PR\"\n",
    "\n",
    "pr_2024 = pd.read_excel(\"cleaned_2024_PR_tie_up.xlsx\")\n",
    "pr_2024[\"Data\"] = \"2024_PR\"\n",
    "\n",
    "# Find common columns in PR datasets (excluding \"Old Policy No\" for now)\n",
    "common_pr_columns = list(set(pr_2022.columns) & set(pr_2023.columns) & set(pr_2024.columns))\n",
    "\n",
    "# Merge all PR datasets while keeping only common PR columns\n",
    "pr_merged = pd.concat([df[common_pr_columns + [\"Data\"]] for df in [pr_2022, pr_2023, pr_2024]], ignore_index=True)\n",
    "\n",
    "# Ensure PR dataset follows the Base structure (adds missing columns as NaN)\n",
    "pr_merged = pr_merged.reindex(columns=common_base_columns + [\"Data\"])\n",
    "\n",
    "# Add \"Old Policy No\" from PR 2023 (if it exists)\n",
    "if \"Old Policy No\" in pr_2023.columns and \"Policy No\" in pr_merged.columns:\n",
    "    pr_merged = pr_merged.merge(pr_2023[['Policy No', 'Old Policy No']], on='Policy No', how='left')\n",
    "\n",
    "# Ensure \"Old Policy No\" column is present in Base dataset as well (Base doesn't have this column)\n",
    "base_merged[\"Old Policy No\"] = None \n",
    "\n",
    "# Merge PR with Base\n",
    "final_merged = pd.concat([base_merged, pr_merged], ignore_index=True)\n",
    "\n",
    "# Database connection details\n",
    "db_username = 'postgres'\n",
    "db_password = 'kaviyam123'\n",
    "db_host = 'localhost'  \n",
    "db_port = '5432'\n",
    "db_name = 'postgres'\n",
    "\n",
    "# Create a connection to PostgreSQL\n",
    "engine = create_engine(f'postgresql://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# Write to PostgreSQL\n",
    "final_merged.to_sql('appended_base_and_pr', engine, if_exists='replace', index=False, chunksize=100000)\n",
    "\n",
    "print(\"Merged data successfully written to PostgreSQL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11776\\3429173114.py:24: DtypeWarning: Columns (17,29,33,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pr_2022 = pd.read_csv(\"cleaned_2022_PR.csv\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m pr_merged \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df[common_pr_columns] \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m [pr_2022, pr_2023, pr_2024]], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Ensure PR dataset follows the Base structure (adds missing columns as NaN)\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m pr_merged \u001b[38;5;241m=\u001b[39m \u001b[43mpr_merged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommon_base_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Add \"Old Policy No\" from PR 2023 (if it exists)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOld Policy No\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pr_2023\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolicy No\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pr_merged\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:5378\u001b[0m, in \u001b[0;36mDataFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5359\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   5360\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,\n\u001b[0;32m   5361\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5376\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5377\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 5378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5382\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5389\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:5610\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5609\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5611\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m   5612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:5633\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5630\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   5632\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[1;32m-> 5633\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m   5635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5637\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[0;32m   5638\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   5639\u001b[0m     {axis: [new_index, indexer]},\n\u001b[0;32m   5640\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5641\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5642\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5643\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:4429\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   4426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m   4428\u001b[0m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[1;32m-> 4429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4431\u001b[0m     indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Load Base datasets and add \"Data\" column\n",
    "base_2022 = pd.read_excel(\"Pvt Car Jan to Dec 22(22 Base).xlsx\")\n",
    "base_2022[\"Data\"] = \"2022_Base\"\n",
    "\n",
    "base_2023 = pd.read_excel(\"Pvt Car Jan'23 to  Dec 23 base Final.xlsx\")\n",
    "base_2023[\"Data\"] = \"2023_Base\"\n",
    "\n",
    "base_2024 = pd.read_excel(\"cleaned_2024_Base_dataset.xlsx\")\n",
    "base_2024[\"Data\"] = \"2024_Base\"\n",
    "\n",
    "# Find common columns across all Base datasets\n",
    "common_base_columns = list(set(base_2022.columns) & set(base_2023.columns) & set(base_2024.columns))\n",
    "\n",
    "# Ensure \"Data\" column is included\n",
    "common_base_columns.append(\"Data\")\n",
    "\n",
    "# Merge all Base datasets while keeping only common columns\n",
    "base_merged = pd.concat([df[common_base_columns] for df in [base_2022, base_2023, base_2024]], ignore_index=True)\n",
    "\n",
    "# Load PR datasets and add \"Data\" column\n",
    "pr_2022 = pd.read_csv(\"cleaned_2022_PR.csv\")\n",
    "pr_2022[\"Data\"] = \"2022_PR\"\n",
    "\n",
    "pr_2023 = pd.read_excel(\"cleaned_PR dataset.xlsx\")  # Contains \"Old Policy No\"\n",
    "pr_2023[\"Data\"] = \"2023_PR\"\n",
    "\n",
    "pr_2024 = pd.read_excel(\"cleaned_2024_PR_tie_up.xlsx\")\n",
    "pr_2024[\"Data\"] = \"2024_PR\"\n",
    "\n",
    "# Find common columns in PR datasets\n",
    "common_pr_columns = list(set(pr_2022.columns) & set(pr_2023.columns) & set(pr_2024.columns))\n",
    "\n",
    "# Ensure \"Data\" column is included\n",
    "common_pr_columns.append(\"Data\")\n",
    "\n",
    "# Merge all PR datasets while keeping only common PR columns\n",
    "pr_merged = pd.concat([df[common_pr_columns] for df in [pr_2022, pr_2023, pr_2024]], ignore_index=True)\n",
    "\n",
    "# Ensure PR dataset follows the Base structure (adds missing columns as NaN)\n",
    "pr_merged = pr_merged.reindex(columns=common_base_columns, fill_value=None)\n",
    "\n",
    "# Add \"Old Policy No\" from PR 2023 (if it exists)\n",
    "if \"Old Policy No\" in pr_2023.columns and \"Policy No\" in pr_merged.columns:\n",
    "    pr_merged = pr_merged.merge(pr_2023[['Policy No', 'Old Policy No']], on='Policy No', how='left')\n",
    "\n",
    "# Ensure \"Old Policy No\" column is present in Base dataset as well\n",
    "base_merged[\"Old Policy No\"] = None  # Assign NaN to Base records\n",
    "\n",
    "# Merge PR with Base\n",
    "final_merged = pd.concat([base_merged, pr_merged], ignore_index=True)\n",
    "\n",
    "# Database connection details\n",
    "db_username = 'postgres'\n",
    "db_password = 'kaviyam123'\n",
    "db_host = 'localhost'  \n",
    "db_port = '5432'\n",
    "db_name = 'postgres'\n",
    "\n",
    "# Create a connection to PostgreSQL\n",
    "engine = create_engine(f'postgresql://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# Write to PostgreSQL\n",
    "final_merged.to_sql('appended_base_and_pr', engine, if_exists='replace', index=False, chunksize=100000)\n",
    "\n",
    "print(\" Merged data successfully written to PostgreSQL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11776\\1363414320.py:8: DtypeWarning: Columns (17,29,33,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pr_2022 = pd.read_csv(\"cleaned_2022_PR.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No duplicate columns in Base 2022\n",
      " No duplicate columns in Base 2023\n",
      " No duplicate columns in Base 2024\n",
      " No duplicate columns in PR 2022\n",
      " No duplicate columns in PR 2023\n",
      " No duplicate columns in PR 2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load all datasets\n",
    "base_2022 = pd.read_excel(\"Pvt Car Jan to Dec 22(22 Base).xlsx\")\n",
    "base_2023 = pd.read_excel(\"Pvt Car Jan'23 to  Dec 23 base Final.xlsx\")\n",
    "base_2024 = pd.read_excel(\"cleaned_2024_Base_dataset.xlsx\")\n",
    "\n",
    "pr_2022 = pd.read_csv(\"cleaned_2022_PR.csv\")\n",
    "pr_2023 = pd.read_excel(\"cleaned_PR dataset.xlsx\")  # Contains \"Old Policy No\"\n",
    "pr_2024 = pd.read_excel(\"cleaned_2024_PR_tie_up.xlsx\")\n",
    "\n",
    "# Function to check for duplicate column names\n",
    "def find_duplicate_columns(df, dataset_name):\n",
    "    duplicates = df.columns[df.columns.duplicated()].tolist()\n",
    "    if duplicates:\n",
    "        print(f\" Duplicate columns found in {dataset_name}: {duplicates}\")\n",
    "    else:\n",
    "        print(f\" No duplicate columns in {dataset_name}\")\n",
    "\n",
    "# Check for duplicates in each dataset\n",
    "find_duplicate_columns(base_2022, \"Base 2022\")\n",
    "find_duplicate_columns(base_2023, \"Base 2023\")\n",
    "find_duplicate_columns(base_2024, \"Base 2024\")\n",
    "find_duplicate_columns(pr_2022, \"PR 2022\")\n",
    "find_duplicate_columns(pr_2023, \"PR 2023\")\n",
    "find_duplicate_columns(pr_2024, \"PR 2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Warning: These columns exist in both Base and PR datasets: [' New Vertical', 'Fuel Type', 'GST', 'Vehicle IDV', 'MANUFACTURER/Make', 'Policy End Date', 'ENGINENUMBER', 'Applicable Discount with NCB', 'Total Premium Payable ', 'Before GST Add-on GWP', 'CHASSIS NUMBER', 'NCB % Previous Year', 'New Branch Name  2', 'Policy Start Date', 'Road Side Assistance', 'Product name ', 'Total TP Premium', 'Total OD Premium', 'Age', 'Policy No', 'Month', 'Reg no ']\n"
     ]
    }
   ],
   "source": [
    "# Find common columns across Base datasets\n",
    "common_base_columns = list(set(base_2022.columns) & set(base_2023.columns) & set(base_2024.columns))\n",
    "\n",
    "# Find common columns across PR datasets\n",
    "common_pr_columns = list(set(pr_2022.columns) & set(pr_2023.columns) & set(pr_2024.columns))\n",
    "\n",
    "# Check if any columns are repeated in both Base and PR datasets\n",
    "duplicate_columns_in_merged = list(set(common_base_columns) & set(common_pr_columns))\n",
    "\n",
    "if duplicate_columns_in_merged:\n",
    "    print(f\"⚠️ Warning: These columns exist in both Base and PR datasets: {duplicate_columns_in_merged}\")\n",
    "else:\n",
    "    print(\"✅ No duplicate columns found between Base and PR datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['data'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     common_base_columns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Merge all Base datasets while keeping only common columns\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m base_merged \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcommon_base_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mbase_2022\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_2023\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_2024\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Load PR datasets and clean column names\u001b[39;00m\n\u001b[0;32m     30\u001b[0m pr_2022 \u001b[38;5;241m=\u001b[39m clean_columns(pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaned_2022_PR.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     24\u001b[0m     common_base_columns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Merge all Base datasets while keeping only common columns\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m base_merged \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcommon_base_columns\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m [base_2022, base_2023, base_2024]], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Load PR datasets and clean column names\u001b[39;00m\n\u001b[0;32m     30\u001b[0m pr_2022 \u001b[38;5;241m=\u001b[39m clean_columns(pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaned_2022_PR.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['data'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Function to standardize column names (strip spaces, lowercase, remove double spaces)\n",
    "def clean_columns(df):\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(r'\\s+', ' ', regex=True)\n",
    "    return df\n",
    "\n",
    "# Load Base datasets and clean column names\n",
    "base_2022 = clean_columns(pd.read_excel(\"Pvt Car Jan to Dec 22(22 Base).xlsx\"))\n",
    "base_2022[\"Data\"] = \"2022_Base\"\n",
    "\n",
    "base_2023 = clean_columns(pd.read_excel(\"Pvt Car Jan'23 to  Dec 23 base Final.xlsx\"))\n",
    "base_2023[\"Data\"] = \"2023_Base\"\n",
    "\n",
    "base_2024 = clean_columns(pd.read_excel(\"cleaned_2024_Base_dataset.xlsx\"))\n",
    "base_2024[\"Data\"] = \"2024_Base\"\n",
    "\n",
    "# Find common columns across all Base datasets\n",
    "common_base_columns = list(set(base_2022.columns) & set(base_2023.columns) & set(base_2024.columns))\n",
    "\n",
    "# Ensure \"Data\" column is included\n",
    "if \"data\" not in common_base_columns:\n",
    "    common_base_columns.append(\"data\")\n",
    "\n",
    "# Merge all Base datasets while keeping only common columns\n",
    "base_merged = pd.concat([df[common_base_columns] for df in [base_2022, base_2023, base_2024]], ignore_index=True)\n",
    "\n",
    "# Load PR datasets and clean column names\n",
    "pr_2022 = clean_columns(pd.read_csv(\"cleaned_2022_PR.csv\"))\n",
    "pr_2022[\"Data\"] = \"2022_PR\"\n",
    "\n",
    "pr_2023 = clean_columns(pd.read_excel(\"cleaned_PR dataset.xlsx\"))  # Contains \"Old Policy No\"\n",
    "pr_2023[\"Data\"] = \"2023_PR\"\n",
    "\n",
    "pr_2024 = clean_columns(pd.read_excel(\"cleaned_2024_PR_tie_up.xlsx\"))\n",
    "pr_2024[\"Data\"] = \"2024_PR\"\n",
    "\n",
    "# Find common columns in PR datasets\n",
    "common_pr_columns = list(set(pr_2022.columns) & set(pr_2023.columns) & set(pr_2024.columns))\n",
    "\n",
    "# Ensure \"Data\" column is included\n",
    "if \"data\" not in common_pr_columns:\n",
    "    common_pr_columns.append(\"data\")\n",
    "\n",
    "# Handle conflicting columns: Keep only Base structure\n",
    "conflicting_columns = list(set(common_base_columns) & set(common_pr_columns))\n",
    "print(f\"Warning: These columns exist in both Base and PR datasets: {conflicting_columns}\")\n",
    "\n",
    "# Remove duplicates from PR dataset by keeping only common columns\n",
    "pr_merged = pd.concat([df[common_pr_columns] for df in [pr_2022, pr_2023, pr_2024]], ignore_index=True)\n",
    "\n",
    "# Ensure PR dataset follows the Base structure (adds missing columns as NaN)\n",
    "for col in common_base_columns:\n",
    "    if col not in pr_merged.columns:\n",
    "        pr_merged[col] = None  # Add missing columns with NaN\n",
    "\n",
    "# Add \"Old Policy No\" from PR 2023 (if it exists)\n",
    "if \"old policy no\" in pr_2023.columns and \"policy no\" in pr_merged.columns:\n",
    "    pr_merged = pr_merged.merge(pr_2023[['policy no', 'old policy no']], on='policy no', how='left')\n",
    "\n",
    "# Ensure \"Old Policy No\" column is present in Base dataset as well\n",
    "base_merged[\"old policy no\"] = None  # Assign NaN to Base records\n",
    "\n",
    "# Merge PR with Base\n",
    "final_merged = pd.concat([base_merged, pr_merged], ignore_index=True)\n",
    "\n",
    "# Database connection details\n",
    "db_username = 'postgres'\n",
    "db_password = 'kaviyam123'\n",
    "db_host = 'localhost'  \n",
    "db_port = '5432'\n",
    "db_name = 'postgres'\n",
    "\n",
    "# Create a connection to PostgreSQL\n",
    "engine = create_engine(f'postgresql://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# Write to PostgreSQL\n",
    "final_merged.to_sql('appended_base_and_pr', engine, if_exists='replace', index=False, chunksize=100000)\n",
    "\n",
    "print(\"Merged data successfully written to PostgreSQL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13100\\929413441.py:35: DtypeWarning: Columns (17,29,33,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pr_2022 = clean_columns(pd.read_csv(\"cleaned_2022_PR.csv\"))\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m base_merged[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mold policy no\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Assign NaN to Base records\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Merge PR with Base\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m final_merged \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbase_merged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpr_merged\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Database connection details\u001b[39;00m\n\u001b[0;32m     70\u001b[0m db_username \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpostgres\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[0;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[1;32m--> 680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m    684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    686\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Function to standardize column names (strip spaces, lowercase, remove extra spaces)\n",
    "def clean_columns(df):\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(r'\\s+', ' ', regex=True)\n",
    "    return df\n",
    "\n",
    "# Load Base datasets and clean column names\n",
    "base_2022 = clean_columns(pd.read_excel(\"Pvt Car Jan to Dec 22(22 Base).xlsx\"))\n",
    "base_2022[\"Data\"] = \"2022_Base\"\n",
    "\n",
    "base_2023 = clean_columns(pd.read_excel(\"Pvt Car Jan'23 to  Dec 23 base Final.xlsx\"))\n",
    "base_2023[\"Data\"] = \"2023_Base\"\n",
    "\n",
    "base_2024 = clean_columns(pd.read_excel(\"cleaned_2024_Base_dataset.xlsx\"))\n",
    "base_2024[\"Data\"] = \"2024_Base\"\n",
    "\n",
    "# Ensure \"Data\" column is properly included before finding common columns\n",
    "for df in [base_2022, base_2023, base_2024]:\n",
    "    if \"Data\" not in df.columns:\n",
    "        df[\"Data\"] = None  # Add missing \"Data\" column\n",
    "\n",
    "# Find common columns across all Base datasets\n",
    "common_base_columns = list(set(base_2022.columns) & set(base_2023.columns) & set(base_2024.columns))\n",
    "\n",
    "# Ensure \"Data\" column is included correctly\n",
    "if \"Data\" in base_2022.columns:\n",
    "    common_base_columns.append(\"Data\")  # Add \"Data\" column explicitly\n",
    "\n",
    "# Merge all Base datasets while keeping only common columns\n",
    "base_merged = pd.concat([df[common_base_columns] for df in [base_2022, base_2023, base_2024]], ignore_index=True)\n",
    "\n",
    "# Load PR datasets and clean column names\n",
    "pr_2022 = clean_columns(pd.read_csv(\"cleaned_2022_PR.csv\"))\n",
    "pr_2022[\"Data\"] = \"2022_PR\"\n",
    "\n",
    "pr_2023 = clean_columns(pd.read_excel(\"cleaned_PR dataset.xlsx\"))  # Contains \"Old Policy No\"\n",
    "pr_2023[\"Data\"] = \"2023_PR\"\n",
    "\n",
    "pr_2024 = clean_columns(pd.read_excel(\"cleaned_2024_PR_tie_up.xlsx\"))\n",
    "pr_2024[\"Data\"] = \"2024_PR\"\n",
    "\n",
    "# Find common columns in PR datasets\n",
    "common_pr_columns = list(set(pr_2022.columns) & set(pr_2023.columns) & set(pr_2024.columns))\n",
    "\n",
    "# Ensure \"Data\" column is included correctly\n",
    "if \"Data\" in pr_2022.columns:\n",
    "    common_pr_columns.append(\"Data\")\n",
    "\n",
    "# Merge all PR datasets while keeping only common PR columns\n",
    "pr_merged = pd.concat([df[common_pr_columns] for df in [pr_2022, pr_2023, pr_2024]], ignore_index=True)\n",
    "\n",
    "# Ensure PR dataset follows the Base structure (adds missing columns as NaN)\n",
    "for col in common_base_columns:\n",
    "    if col not in pr_merged.columns:\n",
    "        pr_merged[col] = None  # Add missing columns with NaN\n",
    "\n",
    "# Add \"Old Policy No\" from PR 2023 (if it exists)\n",
    "if \"old policy no\" in pr_2023.columns and \"policy no\" in pr_merged.columns:\n",
    "    pr_merged = pr_merged.merge(pr_2023[['policy no', 'old policy no']], on='policy no', how='left')\n",
    "\n",
    "# Ensure \"Old Policy No\" column is present in Base dataset as well\n",
    "base_merged[\"old policy no\"] = None  # Assign NaN to Base records\n",
    "\n",
    "# Merge PR with Base\n",
    "final_merged = pd.concat([base_merged, pr_merged], ignore_index=True)\n",
    "\n",
    "# Database connection details\n",
    "db_username = 'postgres'\n",
    "db_password = 'kaviyam123'\n",
    "db_host = 'localhost'  \n",
    "db_port = '5432'\n",
    "db_name = 'postgres'\n",
    "\n",
    "# Create a connection to PostgreSQL\n",
    "engine = create_engine(f'postgresql://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# Write to PostgreSQL\n",
    "final_merged.to_sql('appended_base_and_pr', engine, if_exists='replace', index=False, chunksize=100000)\n",
    "\n",
    "print(\"Merged data successfully written to PostgreSQL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
