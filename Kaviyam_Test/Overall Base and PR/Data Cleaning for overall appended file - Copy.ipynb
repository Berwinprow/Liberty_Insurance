{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3230310"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# ---------------------------\n",
    "# Step 0: Database Connection\n",
    "# ---------------------------\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': 'kaviyam123',\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Load Data\n",
    "# ---------------------------\n",
    "query = \"SELECT * FROM appended_base_and_pr;\"\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "len(df)\n",
    "\n",
    "# Create a DataFrame of column names and their types\n",
    "#df_info = pd.DataFrame({'Column Name': df.columns, 'Data Type': df.dtypes.astype(str)})\n",
    "\n",
    "# Display the DataFrame\n",
    "#print(df_info)\n",
    "\n",
    "# If you want to save it as a CSV file for easier viewing:\n",
    "#df_info.to_csv(\"column_data_types.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3229882"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert date columns to datetime using the names in your dataset\n",
    "df['policy start date'] = pd.to_datetime(df['policy start date'], errors='coerce')\n",
    "df['policy end date'] = pd.to_datetime(df['policy end date'], errors='coerce')\n",
    "df = df.dropna(subset=['policy start date', 'policy end date'])\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaT in 'policy start date': 2759256\n",
      "Rows with NaT in 'policy end date': 2759256\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Step 3: Convert Date Columns Properly\n",
    "# ---------------------------\n",
    "# Remove leading/trailing spaces (sometimes SQL data has spaces)\n",
    "df['policy start date'] = df['policy start date'].astype(str).str.strip()\n",
    "df['policy end date'] = df['policy end date'].astype(str).str.strip()\n",
    "\n",
    "# Convert using multiple possible formats\n",
    "def parse_dates(date_col):\n",
    "    return pd.to_datetime(date_col, errors='coerce', format='%d-%m-%Y')  # Adjust if necessary\n",
    "\n",
    "df['policy start date'] = df['policy start date'].apply(parse_dates)\n",
    "df['policy end date'] = df['policy end date'].apply(parse_dates)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 4: Debug NaT Values (Check Invalid Dates)\n",
    "# ---------------------------\n",
    "print(\"Rows with NaT in 'policy start date':\", df['policy start date'].isna().sum())\n",
    "print(\"Rows with NaT in 'policy end date':\", df['policy end date'].isna().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        policy start date policy end date\n",
      "665                   NaT             NaT\n",
      "666                   NaT             NaT\n",
      "669                   NaT             NaT\n",
      "671                   NaT             NaT\n",
      "672                   NaT             NaT\n",
      "...                   ...             ...\n",
      "3230305               NaT             NaT\n",
      "3230306               NaT             NaT\n",
      "3230307               NaT             NaT\n",
      "3230308               NaT             NaT\n",
      "3230309               NaT             NaT\n",
      "\n",
      "[2759256 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select only 'policy start date' and 'policy end date' where values are NaT\n",
    "missing_dates_df = df[df['policy start date'].isna() | df['policy end date'].isna()][['policy start date', 'policy end date']]\n",
    "\n",
    "# Display the result\n",
    "print(missing_dates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize dates: Convert using `dayfirst=True` to handle both `-` and `/` separators\n",
    "df['policy start date'] = pd.to_datetime(df['policy start date'], dayfirst=True, errors='coerce')\n",
    "df['policy end date'] = pd.to_datetime(df['policy end date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "df = df.dropna(subset=['policy start date', 'policy end date'])\n",
    "\n",
    "#df = df[~df[['policy start date', 'policy end date']].isnull().all(axis=1)]\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 2: Filter Premium Values\n",
    "# ---------------------------\n",
    "# Use the column \"total premium payable\" as provided in your column list\n",
    "df['total premium payable'] = pd.to_numeric(df['total premium payable'].astype(str).str.strip(), errors='coerce')\n",
    "df = df[df['total premium payable'].notnull() & (df['total premium payable'] > 0)]\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Calculate Policy Tenure & Filter\n",
    "# ---------------------------\n",
    "def calculate_tenure_exact(start_date, end_date):\n",
    "    diff = relativedelta(end_date, start_date)\n",
    "    return diff.years * 12 + diff.months + (diff.days >= 0)\n",
    "\n",
    "df['Policy Tenure(check)'] = df.apply(lambda row: calculate_tenure_exact(row['policy start date'], row['policy end date']), axis=1)\n",
    "df = df[df['Policy Tenure(check)'] > 10]\n",
    "\n",
    "# ---------------------------\n",
    "# Step 4: Handle Duplicates and Prioritize\n",
    "# ---------------------------\n",
    "def prioritize_rows(group):\n",
    "    # Count null values in each row to help with prioritization\n",
    "    group['null_count'] = group.isnull().sum(axis=1)\n",
    "    group = group.sort_values(by=['null_count', 'booked', 'policy start date'], ascending=[True, False, True])\n",
    "    return group.iloc[0]\n",
    "\n",
    "# Identify duplicate rows based on 'policy no', 'policy start date', and 'policy end date'\n",
    "duplicates = df[df.duplicated(subset=['policy no', 'policy start date', 'policy end date'], keep=False)]\n",
    "cleaned_duplicates = (\n",
    "    duplicates.groupby(['policy no', 'policy start date', 'policy end date'])\n",
    "    .apply(prioritize_rows)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_cleaned = df.drop_duplicates(subset=['policy no', 'policy start date', 'policy end date'], keep=False)\n",
    "df_cleaned = pd.concat([df_cleaned, cleaned_duplicates], ignore_index=True)\n",
    "\n",
    "len(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 5: Handle Duplicates based on 'Trim Policy No', 'policy start date', and 'policy end date'\n",
    "# ---------------------------\n",
    "def prioritize_trim_group(group):\n",
    "    base_values = ['2022_base', '2023_base', '2024_base']\n",
    "    base_rows = group[group['data'].isin(base_values)]\n",
    "    if not base_rows.empty:\n",
    "        selected = base_rows.sort_values(by='total premium payable', ascending=False).iloc[0]\n",
    "    else:\n",
    "        selected = group.sort_values(by=['policy issue date', 'total premium payable'], ascending=[False, False]).iloc[0]\n",
    "    return selected\n",
    "def assign_trim_group(group):\n",
    "    if len(group) > 1:\n",
    "        selected_row = prioritize_trim_group(group)\n",
    "    else:\n",
    "        selected_row = group.iloc[0]\n",
    "    return selected_row\n",
    "df_final = df_cleaned.groupby(['Trim Policy No', 'policy start date', 'policy end date'], group_keys=False).apply(assign_trim_group).reset_index(drop=True)\n",
    "\n",
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# ---------------------------\n",
    "# Step 6: Clean Specified Name Columns\n",
    "# ---------------------------\n",
    "def clean_name(name):\n",
    "    return re.sub(r'[^a-zA-Z0-9]', '', str(name)).lower()\n",
    "columns_to_clean = {\n",
    "    \"insured name\": \"Cleaned insured name\",\n",
    "    \"new branch name 2\": \"Cleaned Branch Name 2\",\n",
    "    \"state2\": \"Cleaned State2\",\n",
    "    \"zone 2\": \"Cleaned Zone 2\",\n",
    "    \"chassis number\": \"Cleaned Chassis Number\",\n",
    "    \"enginenumber\": \"Cleaned Engine Number\",\n",
    "    \"reg no\": \"Cleaned Reg no\"\n",
    "}\n",
    "for orig_col, new_col in columns_to_clean.items():\n",
    "    if orig_col in df_final.columns:\n",
    "        df_final[new_col] = df_final[orig_col].apply(clean_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Final DataFrame ready for analysis or export\n",
    "# ---------------------------\n",
    "df_final.to_sql('cleaned_appended_base_and_pr', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 6: Update 'final old policy no' for Groups (Duplicates and Non-Duplicates)\n",
    "#         (Only update rows where 'old policy no' is null)\n",
    "# ---------------------------\n",
    "def select_policy_no_for_duplicates(group):\n",
    "    base_values = ['2022_base', '2023_base', '2024_base']\n",
    "    base_rows = group[group['data'].isin(base_values)]\n",
    "    if not base_rows.empty:\n",
    "        selected = base_rows.sort_values(by='total premium payable', ascending=False).iloc[0]\n",
    "    else:\n",
    "        selected = group.sort_values(by='total premium payable', ascending=False).iloc[0]\n",
    "    return selected['policy no']\n",
    "\n",
    "def assign_final_old_policy_no(group):\n",
    "    # Compute the replacement value for rows with a null 'old policy no'\n",
    "    if len(group) > 1:\n",
    "        computed_policy_no = select_policy_no_for_duplicates(group)\n",
    "    else:\n",
    "        computed_policy_no = group.iloc[0]['policy no']\n",
    "    # For each row, if 'old policy no' is null, assign the computed value;\n",
    "    # otherwise, keep the existing 'old policy no'.\n",
    "    group['final old policy no'] = group.apply(\n",
    "        lambda row: row['old policy no'] if pd.notnull(row['old policy no']) else computed_policy_no,\n",
    "        axis=1\n",
    "    )\n",
    "    return group\n",
    "\n",
    "# Group by 'Trim Policy No' and 'policy start date' (duplicate groups)\n",
    "df_final = df_cleaned.groupby(['Trim Policy No', 'policy start date'], group_keys=False).apply(assign_final_old_policy_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Final DataFrame ready for analysis or export\n",
    "# ---------------------------\n",
    "df_final.to_sql('cleaned_appended_base_and_pr1', con=engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
